{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xleld-8o_8u",
        "outputId": "cdbe88d1-be16-40d1-e139-1631ab7cc6da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jkoui\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA GeForce RTX 4060 Ti\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Optional\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "if device == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "GLOBAL_SEED = 2\n",
        "\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # 让 cudnn 更可复现（会稍微慢一点）\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_global_seed(GLOBAL_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_imLH0qpEHN"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    GLOBAL_SEED\n",
        "except NameError:\n",
        "    GLOBAL_SEED = 42\n",
        "\n",
        "def get_dataset(dataset_name, data_dir=\"./data\", img_size=224):\n",
        "    name = dataset_name.lower()\n",
        "\n",
        "    if name == \"imagenet\":\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(img_size),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "        transform_val = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(img_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "        train_set = datasets.ImageFolder(f\"{data_dir}/train\", transform=transform_train)\n",
        "        val_set = datasets.ImageFolder(f\"{data_dir}/val\", transform=transform_val)\n",
        "        num_classes = len(train_set.classes)\n",
        "\n",
        "    elif name == \"cifar10\":\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=(0.5, 0.5, 0.5),\n",
        "                std=(0.5, 0.5, 0.5),\n",
        "            )\n",
        "        ])\n",
        "        train_set = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
        "        val_set = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n",
        "        num_classes = 10\n",
        "\n",
        "    elif name == \"cifar100\":\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=(0.5, 0.5, 0.5),\n",
        "                std=(0.5, 0.5, 0.5),\n",
        "            )\n",
        "        ])\n",
        "        train_set = datasets.CIFAR100(root=data_dir, train=True, download=True, transform=transform)\n",
        "        val_set = datasets.CIFAR100(root=data_dir, train=False, download=True, transform=transform)\n",
        "        num_classes = 100\n",
        "\n",
        "    elif name == \"svhn\":\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=(0.5, 0.5, 0.5),\n",
        "                std=(0.5, 0.5, 0.5),\n",
        "            )\n",
        "        ])\n",
        "        train_set = datasets.SVHN(root=data_dir, split='train', download=True, transform=transform)\n",
        "        val_set   = datasets.SVHN(root=data_dir, split='test',  download=True, transform=transform)\n",
        "        num_classes = 10\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
        "\n",
        "    return train_set, val_set, num_classes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_loaders(dataset_name, data_dir=\"./data\", batch_size=64, img_size=224, num_workers=8):\n",
        "    train_set, val_set, num_classes = get_dataset(dataset_name, data_dir, img_size)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=(device == \"cuda\"),\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=(device == \"cuda\"),\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, num_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device, epoch, epochs, scaler=None):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    use_amp = scaler is not None\n",
        "\n",
        "    loop = tqdm(loader, desc=f\"Train [{epoch+1}/{epochs}]\", ncols=100)\n",
        "    for images, labels in loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if use_amp:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    acc = correct / len(loader.dataset)\n",
        "    return avg_loss, acc\n",
        "\n",
        "\n",
        "def eval_one_epoch(model, loader, criterion, device, epoch, epochs):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    loop = tqdm(loader, desc=f\"Val   [{epoch+1}/{epochs}]\", ncols=100)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loop:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    acc = correct / len(loader.dataset)\n",
        "    return avg_loss, acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "#  1. 谱分析基础工具：svd + effective rank + 画图\n",
        "# ============================================================\n",
        "\n",
        "def to_numpy(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.detach().cpu().numpy()\n",
        "    return np.array(x)\n",
        "\n",
        "\n",
        "def compute_singular_values_from_qk(\n",
        "    q: torch.Tensor,\n",
        "    k: torch.Tensor,\n",
        "    scale: float = 1.0,\n",
        "    top_k: int = 32,\n",
        "    batch_agg: str = \"mean\",\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    给定某一层的 Q, K，计算每个 head 的 pre-softmax S = (Q * scale) @ K^T 的前 top_k 个奇异值。\n",
        "\n",
        "    参数：\n",
        "      q, k: 形状 (B, H, N, D_h)\n",
        "      scale: 一般 = 1/sqrt(D_h)\n",
        "      top_k: 只保留前 top_k 个最大奇异值\n",
        "      batch_agg:\n",
        "        - \"mean\": S = mean_b (Q_b K_b^T)\n",
        "        - \"first\": 只用第一个 batch\n",
        "\n",
        "    返回：\n",
        "      svals: (H, top_k)\n",
        "    \"\"\"\n",
        "    assert q.shape == k.shape, \"q, k 必须同形状 (B, H, N, D_h)\"\n",
        "    B, H, N, Dh = q.shape\n",
        "    top_k = min(top_k, N)\n",
        "\n",
        "    s_list = []\n",
        "\n",
        "    for h in range(H):\n",
        "        if batch_agg == \"first\":\n",
        "            q_h = q[0, h] * scale      # (N, D_h)\n",
        "            k_h = k[0, h]              # (N, D_h)\n",
        "            S = q_h @ k_h.transpose(0, 1)  # (N, N)\n",
        "        else:\n",
        "            S = None\n",
        "            for b in range(B):\n",
        "                q_bh = q[b, h] * scale\n",
        "                k_bh = k[b, h]\n",
        "                S_b = q_bh @ k_bh.transpose(0, 1)\n",
        "                if S is None:\n",
        "                    S = S_b\n",
        "                else:\n",
        "                    S = S + S_b\n",
        "            S = S / float(B)\n",
        "\n",
        "        svals_full = torch.linalg.svdvals(S)   # (N,)\n",
        "        svals_head = svals_full[:top_k]        # (top_k,)\n",
        "        s_list.append(svals_head)\n",
        "\n",
        "    svals = torch.stack(s_list, dim=0)  # (H, top_k)\n",
        "    return svals\n",
        "\n",
        "\n",
        "def normalize_singular_values(\n",
        "    svals: torch.Tensor,\n",
        "    mode: str = \"sum\",\n",
        "    eps: float = 1e-12,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    对奇异值做归一化，方便热力图看“谱形状”。\n",
        "\n",
        "    mode:\n",
        "      - \"sum\": 除以 sum(s_i) → 类似概率分布\n",
        "      - \"max\": 除以 max(s_i) → 最大值变 1\n",
        "      - \"none\": 不归一化\n",
        "    \"\"\"\n",
        "    if mode == \"none\":\n",
        "        return svals\n",
        "\n",
        "    if mode == \"sum\":\n",
        "        denom = svals.sum(dim=-1, keepdim=True) + eps\n",
        "    elif mode == \"max\":\n",
        "        denom = svals.max(dim=-1, keepdim=True).values + eps\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown normalize mode: {mode}\")\n",
        "\n",
        "    return svals / denom\n",
        "\n",
        "\n",
        "def compute_effective_rank(\n",
        "    svals: torch.Tensor,\n",
        "    eps: float = 1e-12,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    根据奇异值计算 effective rank：\n",
        "\n",
        "      p_i = s_i / sum_j s_j\n",
        "      H = - sum_i p_i log p_i\n",
        "      erank = exp(H)\n",
        "\n",
        "    参数：\n",
        "      svals: (..., K)\n",
        "    返回：\n",
        "      erank: (...,)\n",
        "    \"\"\"\n",
        "    svals = torch.clamp(svals, min=eps)\n",
        "    S = svals.sum(dim=-1, keepdim=True) + eps\n",
        "    p = svals / S\n",
        "    log_p = torch.log(p + eps)\n",
        "    H = -(p * log_p).sum(dim=-1)\n",
        "    erank = torch.exp(H)\n",
        "    return erank\n",
        "\n",
        "\n",
        "def stack_svals_over_epochs(svals_per_epoch):\n",
        "    \"\"\"\n",
        "    svals_per_epoch: list of (H, K)\n",
        "    返回: (E, H, K)\n",
        "    \"\"\"\n",
        "    assert len(svals_per_epoch) > 0\n",
        "    H, K = svals_per_epoch[0].shape\n",
        "    for sv in svals_per_epoch:\n",
        "        assert sv.shape == (H, K)\n",
        "    return torch.stack(svals_per_epoch, dim=0)  # (E,H,K)\n",
        "\n",
        "\n",
        "def plot_svals_heatmap_per_head(\n",
        "    svals_epochs: torch.Tensor,\n",
        "    head_idx: int,\n",
        "    epoch_indices=None,\n",
        "    normalize_mode: str = \"sum\",\n",
        "    cmap: str = \"viridis\",\n",
        "    save_path: str = None,\n",
        "    title: str = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    画某一个 head 的 singular value 热力图。\n",
        "\n",
        "    svals_epochs: (E, H, K)\n",
        "    \"\"\"\n",
        "    E, H, K = svals_epochs.shape\n",
        "    assert 0 <= head_idx < H\n",
        "\n",
        "    svals_head = svals_epochs[:, head_idx, :]  # (E, K)\n",
        "    svals_head = normalize_singular_values(svals_head, mode=normalize_mode)\n",
        "    data = to_numpy(svals_head).T  # (K, E)\n",
        "\n",
        "    if epoch_indices is None:\n",
        "        epoch_indices = list(range(1, E + 1))\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    im = plt.imshow(\n",
        "        data,\n",
        "        aspect=\"auto\",\n",
        "        origin=\"lower\",\n",
        "        interpolation=\"nearest\",\n",
        "        cmap=cmap,\n",
        "    )\n",
        "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Singular value index (1..K)\")\n",
        "    if title is None:\n",
        "        title = f\"Head {head_idx}: singular values heatmap\"\n",
        "    plt.title(title)\n",
        "\n",
        "    xticks_pos = np.linspace(0, E - 1, num=min(E, 6), dtype=int)\n",
        "    xticks_lbl = [str(epoch_indices[i]) for i in xticks_pos]\n",
        "    plt.xticks(ticks=xticks_pos, labels=xticks_lbl)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_svals_heatmap_head_mean(\n",
        "    svals_epochs: torch.Tensor,\n",
        "    epoch_indices=None,\n",
        "    normalize_mode: str = \"sum\",\n",
        "    cmap: str = \"viridis\",\n",
        "    save_path: str = None,\n",
        "    title: str = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    对所有 head 的奇异值先归一化 + 求均值，然后画 head-mean 热力图。\n",
        "\n",
        "    svals_epochs: (E, H, K)\n",
        "    \"\"\"\n",
        "    E, H, K = svals_epochs.shape\n",
        "\n",
        "    svals_norm = normalize_singular_values(svals_epochs, mode=normalize_mode)  # (E,H,K)\n",
        "    svals_mean = svals_norm.mean(dim=1)  # (E,K)\n",
        "    data = to_numpy(svals_mean).T  # (K,E)\n",
        "\n",
        "    if epoch_indices is None:\n",
        "        epoch_indices = list(range(1, E + 1))\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    im = plt.imshow(\n",
        "        data,\n",
        "        aspect=\"auto\",\n",
        "        origin=\"lower\",\n",
        "        interpolation=\"nearest\",\n",
        "        cmap=cmap,\n",
        "    )\n",
        "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Singular value index (1..K)\")\n",
        "    if title is None:\n",
        "        title = \"Head-mean singular values heatmap\"\n",
        "    plt.title(title)\n",
        "\n",
        "    xticks_pos = np.linspace(0, E - 1, num=min(E, 6), dtype=int)\n",
        "    xticks_lbl = [str(epoch_indices[i]) for i in xticks_pos]\n",
        "    plt.xticks(ticks=xticks_pos, labels=xticks_lbl)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_effective_rank_curves(\n",
        "    svals_epochs: torch.Tensor,\n",
        "    epoch_indices=None,\n",
        "    save_path: str = None,\n",
        "    title: str = None,\n",
        "    show_per_head: bool = True,\n",
        "    show_mean: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    画 effective rank 随 epoch 的变化曲线。\n",
        "\n",
        "    svals_epochs: (E,H,K)\n",
        "    \"\"\"\n",
        "    E, H, K = svals_epochs.shape\n",
        "\n",
        "    if epoch_indices is None:\n",
        "        epoch_indices = list(range(1, E + 1))\n",
        "\n",
        "    erank_epochs = compute_effective_rank(svals_epochs)  # (E,H)\n",
        "    erank_np = to_numpy(erank_epochs)  # (E,H)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "\n",
        "    if show_per_head:\n",
        "        for h in range(H):\n",
        "            # 只给第一条线加 label，避免 legend 太乱\n",
        "            lbl = f\"head {h}\" if h == 0 else None\n",
        "            plt.plot(epoch_indices, erank_np[:, h], alpha=0.3, linewidth=1.0, label=lbl)\n",
        "\n",
        "    if show_mean:\n",
        "        mean_erank = erank_np.mean(axis=1)\n",
        "        std_erank = erank_np.std(axis=1)\n",
        "        plt.plot(epoch_indices, mean_erank, color=\"black\", linewidth=2.0, label=\"mean erank\")\n",
        "        if H > 1:\n",
        "            plt.fill_between(\n",
        "                epoch_indices,\n",
        "                mean_erank - std_erank,\n",
        "                mean_erank + std_erank,\n",
        "                color=\"gray\",\n",
        "                alpha=0.2,\n",
        "                label=\"±1 std\",\n",
        "            )\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Effective rank\")\n",
        "    if title is None:\n",
        "        title = \"Effective rank over epochs\"\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "# ============================================================\n",
        "#  2. 从 ViT 指定 block 抓 Q/K → 奇异值\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  3. 训练 + 谱收集：单个实验 (MHA or TPA)\n",
        "# ============================================================\n",
        "def _collect_block_svals_one_epoch(\n",
        "    model,\n",
        "    val_loader,\n",
        "    block_idx: int,\n",
        "    top_k: int,\n",
        "    num_batches_spec: int,\n",
        "    device: str,\n",
        "):\n",
        "    \"\"\"\n",
        "    返回四个：(svals_qk, svals_q, svals_k, svals_v)\n",
        "      - svals_qk: pre-softmax logits (QK^T) 的奇异值 (H, Kqk)\n",
        "      - svals_q/k/v: Q/K/V (N x Dh) 的奇异值 (H, Kqkv)\n",
        "    说明：SVD 放 CPU 上算，避免训练时 GPU 内存紧张导致 OOM。\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    attn_mod = model.vit.blocks[block_idx].attn\n",
        "\n",
        "    cached_x = {}\n",
        "\n",
        "    def _hook(module, inputs, output):\n",
        "        cached_x[\"x\"] = inputs[0].detach()\n",
        "\n",
        "    handle = attn_mod.register_forward_hook(_hook)\n",
        "\n",
        "    qk_batches = []\n",
        "    q_batches  = []\n",
        "    k_batches  = []\n",
        "    v_batches  = []\n",
        "    batches_done = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _ in val_loader:\n",
        "            images = images.to(device)\n",
        "            cached_x.clear()\n",
        "\n",
        "            _ = model(images)\n",
        "\n",
        "            if \"x\" not in cached_x:\n",
        "                continue\n",
        "\n",
        "            x = cached_x[\"x\"]  # (B, N, C)\n",
        "            B, N, C = x.shape\n",
        "\n",
        "            # -------- 拿 q,k,v --------\n",
        "            if hasattr(attn_mod, \"qkv\"):\n",
        "                # timm MHA\n",
        "                qkv = attn_mod.qkv(x)  # (B, N, 3*C)\n",
        "                H = attn_mod.num_heads\n",
        "                Dh = C // H\n",
        "                qkv = qkv.reshape(B, N, 3, H, Dh).permute(2, 0, 3, 1, 4)  # (3, B, H, N, Dh)\n",
        "                q, k, v = qkv[0], qkv[1], qkv[2]  # (B,H,N,Dh)\n",
        "                scale = attn_mod.scale\n",
        "            else:\n",
        "                # TPA 系列\n",
        "                q, k, v = attn_mod._make_qkv(x)  # (B,H,N,Dh)\n",
        "                Dh = q.shape[-1]\n",
        "                scale = attn_mod.scale if hasattr(attn_mod, \"scale\") else (Dh ** -0.5)\n",
        "\n",
        "            H = q.shape[1]\n",
        "            K_qk  = min(top_k, N)          # QK^T 是 N×N\n",
        "            K_qkv = min(top_k, min(N, Dh)) # Q/K/V 是 N×Dh\n",
        "\n",
        "            # -------- 1) QK^T 的奇异值 --------\n",
        "            attn_logits = (q * scale) @ k.transpose(-2, -1)   # (B,H,N,N)\n",
        "            attn_mean = attn_logits.mean(dim=0)               # (H,N,N)\n",
        "\n",
        "            svals_qk = torch.zeros(H, K_qk, dtype=torch.float32)\n",
        "            for h in range(H):\n",
        "                A = attn_mean[h].float().cpu()\n",
        "                sv = torch.linalg.svdvals(A)\n",
        "                svals_qk[h] = sv[:K_qk]\n",
        "\n",
        "            # -------- 2) Q/K/V 本体的奇异值：对 batch 平均后做 SVD --------\n",
        "            q_mean = q.mean(dim=0)  # (H,N,Dh)\n",
        "            k_mean = k.mean(dim=0)\n",
        "            v_mean = v.mean(dim=0)\n",
        "\n",
        "            svals_q = torch.zeros(H, K_qkv, dtype=torch.float32)\n",
        "            svals_k = torch.zeros(H, K_qkv, dtype=torch.float32)\n",
        "            svals_v = torch.zeros(H, K_qkv, dtype=torch.float32)\n",
        "\n",
        "            for h in range(H):\n",
        "                svq = torch.linalg.svdvals(q_mean[h].float().cpu())\n",
        "                svk = torch.linalg.svdvals(k_mean[h].float().cpu())\n",
        "                svv = torch.linalg.svdvals(v_mean[h].float().cpu())\n",
        "                svals_q[h] = svq[:K_qkv]\n",
        "                svals_k[h] = svk[:K_qkv]\n",
        "                svals_v[h] = svv[:K_qkv]\n",
        "\n",
        "            qk_batches.append(svals_qk)\n",
        "            q_batches.append(svals_q)\n",
        "            k_batches.append(svals_k)\n",
        "            v_batches.append(svals_v)\n",
        "\n",
        "            batches_done += 1\n",
        "            if batches_done >= num_batches_spec:\n",
        "                break\n",
        "\n",
        "    handle.remove()\n",
        "\n",
        "    if len(qk_batches) == 0:\n",
        "        raise RuntimeError(\"在谱分析时没有拿到任何 batch 的 attention。\")\n",
        "\n",
        "    # 对 num_batches_spec 求平均：-> (H,K)\n",
        "    svals_qk_epoch = torch.stack(qk_batches, dim=0).mean(dim=0)\n",
        "    svals_q_epoch  = torch.stack(q_batches,  dim=0).mean(dim=0)\n",
        "    svals_k_epoch  = torch.stack(k_batches,  dim=0).mean(dim=0)\n",
        "    svals_v_epoch  = torch.stack(v_batches,  dim=0).mean(dim=0)\n",
        "\n",
        "    return svals_qk_epoch, svals_q_epoch, svals_k_epoch, svals_v_epoch\n",
        "\n",
        "def compute_singular_values_from_tokens(\n",
        "    x: torch.Tensor,\n",
        "    top_k: int = 32,\n",
        "    batch_agg: str = \"mean\",\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    x: (B, H, N, D_h)  -> 对每个 head 的 (N, D_h) 做 SVD，取 top_k\n",
        "    返回: (H, K)\n",
        "    \"\"\"\n",
        "    B, H, N, Dh = x.shape\n",
        "    K = min(top_k, N, Dh)\n",
        "\n",
        "    s_list = []\n",
        "    for h in range(H):\n",
        "        if batch_agg == \"first\":\n",
        "            X = x[0, h]  # (N, Dh)\n",
        "        else:\n",
        "            X = x[:, h].mean(dim=0)  # (N, Dh)\n",
        "\n",
        "        svals_full = torch.linalg.svdvals(X.to(torch.float32))  # (min(N,Dh),)\n",
        "        s_list.append(svals_full[:K])\n",
        "\n",
        "    return torch.stack(s_list, dim=0)  # (H, K)\n",
        "\n",
        "\n",
        "\n",
        "def _collect_block_qkv_svals_one_epoch(\n",
        "    model,\n",
        "    val_loader,\n",
        "    block_idx: int,\n",
        "    top_k: int,\n",
        "    num_batches_spec: int,\n",
        "    device: str,\n",
        "):\n",
        "    \"\"\"\n",
        "    返回四个谱：(H,K)\n",
        "      - svals_qk: SVD of pre-softmax logits (q*scale)@k^T\n",
        "      - svals_q : SVD of Q token matrix (N,Dh)\n",
        "      - svals_k : SVD of K token matrix (N,Dh)\n",
        "      - svals_v : SVD of V token matrix (N,Dh)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    attn_mod = model.vit.blocks[block_idx].attn\n",
        "    cached_x = {}\n",
        "\n",
        "    def _hook(module, inputs, output):\n",
        "        cached_x[\"x\"] = inputs[0].detach()\n",
        "\n",
        "    handle = attn_mod.register_forward_hook(_hook)\n",
        "\n",
        "    qk_list, q_list, k_list, v_list = [], [], [], []\n",
        "    batches_done = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _ in val_loader:\n",
        "            images = images.to(device)\n",
        "            cached_x.clear()\n",
        "            _ = model(images)\n",
        "\n",
        "            if \"x\" not in cached_x:\n",
        "                continue\n",
        "\n",
        "            x = cached_x[\"x\"]  # (B,N,C)\n",
        "            B, N, C = x.shape\n",
        "\n",
        "            # ---- 拿 q,k,v ----\n",
        "            if hasattr(attn_mod, \"qkv\"):\n",
        "                qkv = attn_mod.qkv(x)\n",
        "                H = attn_mod.num_heads\n",
        "                Dh = C // H\n",
        "                qkv = qkv.reshape(B, N, 3, H, Dh).permute(2, 0, 3, 1, 4)  # (3,B,H,N,Dh)\n",
        "                q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "                scale = attn_mod.scale\n",
        "            else:\n",
        "                q, k, v = attn_mod._make_qkv(x)  # (B,H,N,Dh)\n",
        "                Dh = q.shape[-1]\n",
        "                scale = attn_mod.scale if hasattr(attn_mod, \"scale\") else (Dh ** -0.5)\n",
        "\n",
        "            # ---- 统一 K：保证 Q/K/V 都输出同一个 K ----\n",
        "            Kkeep = min(top_k, N, Dh)\n",
        "\n",
        "            # 1) QK^T\n",
        "            attn_logits = (q * scale) @ k.transpose(-2, -1)     # (B,H,N,N)\n",
        "            attn_mean = attn_logits.mean(dim=0)                 # (H,N,N)\n",
        "            svals_qk = torch.zeros(q.shape[1], Kkeep, device=attn_mean.device)\n",
        "            for h in range(q.shape[1]):\n",
        "                sv = torch.linalg.svdvals(attn_mean[h].to(torch.float32))\n",
        "                svals_qk[h] = sv[:Kkeep]\n",
        "\n",
        "            # 2) Q/K/V token matrix\n",
        "            svals_q = compute_singular_values_from_tokens(q, top_k=Kkeep, batch_agg=\"mean\")  # (H,K)\n",
        "            svals_k = compute_singular_values_from_tokens(k, top_k=Kkeep, batch_agg=\"mean\")\n",
        "            svals_v = compute_singular_values_from_tokens(v, top_k=Kkeep, batch_agg=\"mean\")\n",
        "\n",
        "            qk_list.append(svals_qk)\n",
        "            q_list.append(svals_q)\n",
        "            k_list.append(svals_k)\n",
        "            v_list.append(svals_v)\n",
        "\n",
        "            batches_done += 1\n",
        "            if batches_done >= num_batches_spec:\n",
        "                break\n",
        "\n",
        "    handle.remove()\n",
        "\n",
        "    if len(qk_list) == 0:\n",
        "        raise RuntimeError(\"在谱分析时没有拿到任何 batch 的 attention。\")\n",
        "\n",
        "    # 平均多个 batch（如果 num_batches_spec>1）\n",
        "    s_qk = torch.stack(qk_list, dim=0).mean(dim=0)  # (H,K)\n",
        "    s_q  = torch.stack(q_list,  dim=0).mean(dim=0)\n",
        "    s_k  = torch.stack(k_list,  dim=0).mean(dim=0)\n",
        "    s_v  = torch.stack(v_list,  dim=0).mean(dim=0)\n",
        "\n",
        "    return s_qk, s_q, s_k, s_v\n",
        "\n",
        "def run_small_spectrum_experiment(\n",
        "    attn_type: str,\n",
        "    total_epochs: int,\n",
        "    block_idx: int,\n",
        "    top_k: int,\n",
        "    num_batches_spec: int,\n",
        "    dataset_name: str,\n",
        "    model_name: str,\n",
        "    data_dir: str,\n",
        "    img_size: int,\n",
        "    batch_size: int,\n",
        "    num_workers: int,\n",
        "    lr: float,\n",
        "    weight_decay: float,\n",
        "    rank_q: int,\n",
        "    rank_k: int,\n",
        "    rank_v: int,\n",
        "    device: str,\n",
        "    mlp_ratio: float = 2.0,\n",
        "    mlp_on: str=\"qkv\",\n",
        "    sinter_A: float = 5e-5,\n",
        "    sinter_omega: float = 1e4,\n",
        "):\n",
        "    \"\"\"\n",
        "    小规模训练 + 谱分析（每个 epoch 做一次）：\n",
        "\n",
        "      - attn_type:\n",
        "          \"mha\" / \"tpa\" / \"nonlinear_tpa\" / \"headwise_nonlinear_tpa\" / \"sinter_tpa\"\n",
        "\n",
        "      - 每个 epoch：\n",
        "          1) train_one_epoch\n",
        "          2) eval_one_epoch\n",
        "          3) 在指定 block 上做谱分析，拿到 top-K singular values\n",
        "\n",
        "      - 返回:\n",
        "          model, hist = {\n",
        "            \"train_loss_curve\": [...],\n",
        "            \"val_loss_curve\":   [...],\n",
        "            \"train_acc_curve\":  [...],\n",
        "            \"val_acc_curve\":    [...],\n",
        "            \"best_val_acc\":     float,\n",
        "\n",
        "            # 兼容旧逻辑：默认等同于 qk 的谱 (E,H,K)\n",
        "            \"svals_epochs\":     Tensor (E, H, K),\n",
        "\n",
        "            # 新增：分别对 qk / q / k / v 的谱 (E,H,K)\n",
        "            \"svals_qk_epochs\":  Tensor (E, H, K),\n",
        "            \"svals_q_epochs\":   Tensor (E, H, K) 或 None,\n",
        "            \"svals_k_epochs\":   Tensor (E, H, K) 或 None,\n",
        "            \"svals_v_epochs\":   Tensor (E, H, K) 或 None,\n",
        "\n",
        "            \"total_params\":     int,\n",
        "            \"kv_cost\":          float,\n",
        "            \"num_heads\":        int,\n",
        "            \"head_dim\":         int,\n",
        "            \"mlp_ratio_used\":   float 或 None,\n",
        "          }\n",
        "    \"\"\"\n",
        "    # ========= 数据 =========\n",
        "    train_loader, val_loader, num_classes = get_loaders(\n",
        "        dataset_name=dataset_name,\n",
        "        data_dir=data_dir,\n",
        "        batch_size=batch_size,\n",
        "        img_size=img_size,\n",
        "        num_workers=num_workers,\n",
        "    )\n",
        "\n",
        "    # ========= 构建模型 =========\n",
        "    pretrained = False\n",
        "\n",
        "    if attn_type == \"mha\":\n",
        "        model = ViTClassifier(\n",
        "            num_classes=num_classes,\n",
        "            model_name=model_name,\n",
        "            pretrained=pretrained,\n",
        "            attn_type=\"mha\",\n",
        "        ).to(device)\n",
        "\n",
        "    elif attn_type == \"tpa\":\n",
        "        model = ViTClassifier(\n",
        "            num_classes=num_classes,\n",
        "            model_name=model_name,\n",
        "            pretrained=pretrained,\n",
        "            attn_type=\"tpa\",\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "        ).to(device)\n",
        "\n",
        "    elif attn_type == \"nonlinear_tpa\":\n",
        "        if mlp_ratio is None:\n",
        "            mlp_ratio = 1.0\n",
        "        model = ViTClassifier(\n",
        "            num_classes=num_classes,\n",
        "            model_name=model_name,\n",
        "            pretrained=pretrained,\n",
        "            attn_type=\"nonlinear_tpa\",\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            nonlinear_mlp_hidden_ratio=mlp_ratio,\n",
        "            nonlinear_mlp_on = mlp_on,\n",
        "        ).to(device)\n",
        "\n",
        "    elif attn_type == \"headwise_nonlinear_tpa\":\n",
        "        if mlp_ratio is None:\n",
        "            mlp_ratio = 1.0\n",
        "        model = ViTClassifier(\n",
        "            num_classes=num_classes,\n",
        "            model_name=model_name,\n",
        "            pretrained=pretrained,\n",
        "            attn_type=\"headwise_nonlinear_tpa\",\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            nonlinear_mlp_hidden_ratio=mlp_ratio,\n",
        "            nonlinear_mlp_on = mlp_on,\n",
        "        ).to(device)\n",
        "\n",
        "    elif attn_type == \"sinter_tpa\":\n",
        "        if mlp_ratio is None:\n",
        "            mlp_ratio = 1.0\n",
        "        model = ViTClassifier(\n",
        "            num_classes=num_classes,\n",
        "            model_name=model_name,\n",
        "            pretrained=pretrained,\n",
        "            attn_type=\"sinter_tpa\",\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            nonlinear_mlp_hidden_ratio=mlp_ratio,\n",
        "            sinter_A=sinter_A,\n",
        "            sinter_omega=sinter_omega,\n",
        "        ).to(device)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Unknown attn_type: {attn_type}. \"\n",
        "            f\"Expected one of ['mha','tpa','nonlinear_tpa','headwise_nonlinear_tpa','sinter_tpa']\"\n",
        "        )\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    # ========= KV cost（归一到 MHA=1）=========\n",
        "    first_attn = model.vit.blocks[0].attn\n",
        "    if hasattr(first_attn, \"dim\"):\n",
        "        dim_attn = first_attn.dim\n",
        "    else:\n",
        "        dim_attn = first_attn.qkv.in_features\n",
        "\n",
        "    num_heads = first_attn.num_heads\n",
        "    head_dim = dim_attn // num_heads\n",
        "\n",
        "    kv_mha = 2 * num_heads * head_dim  # = 2 * dim\n",
        "\n",
        "    if attn_type == \"mha\":\n",
        "        kv_cost = 1.0\n",
        "    else:\n",
        "        # TPA 系列（含 nonlinear/headwise/sinter）KV 估算公式和你之前一致\n",
        "        kv_tpa = (rank_k + rank_v) * (num_heads + head_dim)\n",
        "        kv_cost = kv_tpa / kv_mha\n",
        "\n",
        "    # ========= 训练相关 =========\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    train_loss_curve = []\n",
        "    val_loss_curve   = []\n",
        "    train_acc_curve  = []\n",
        "    val_acc_curve    = []\n",
        "    best_val_acc     = 0.0\n",
        "\n",
        "    # 每个 epoch 一份谱： (H,K)\n",
        "    svals_qk_epochs_list = []\n",
        "    svals_q_epochs_list  = []\n",
        "    svals_k_epochs_list  = []\n",
        "    svals_v_epochs_list  = []\n",
        "\n",
        "    scaler = None  # 先保持不开 AMP（跟你现在谱实验一致）\n",
        "\n",
        "    for epoch in range(total_epochs):\n",
        "        # ---- train ----\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model=model,\n",
        "            loader=train_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "            scaler=scaler,\n",
        "        )\n",
        "\n",
        "        # ---- val ----\n",
        "        val_loss, val_acc = eval_one_epoch(\n",
        "            model=model,\n",
        "            loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "        )\n",
        "\n",
        "        train_loss_curve.append(train_loss)\n",
        "        val_loss_curve.append(val_loss)\n",
        "        train_acc_curve.append(train_acc)\n",
        "        val_acc_curve.append(val_acc)\n",
        "        best_val_acc = max(best_val_acc, val_acc)\n",
        "\n",
        "        print(\n",
        "            f\"[{attn_type}] Epoch {epoch+1}/{total_epochs} | \"\n",
        "            f\"train loss: {train_loss:.4f}, train acc: {train_acc:.3f} | \"\n",
        "            f\"val loss: {val_loss:.4f}, val acc: {val_acc:.3f}\"\n",
        "        )\n",
        "\n",
        "        # ---- spectrum ----\n",
        "        out = _collect_block_svals_one_epoch(\n",
        "            model=model,\n",
        "            val_loader=val_loader,\n",
        "            block_idx=block_idx,\n",
        "            top_k=top_k,\n",
        "            num_batches_spec=num_batches_spec,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "        # 兼容两种返回：\n",
        "        # 1) 新版： (svals_qk, svals_q, svals_k, svals_v)\n",
        "        # 2) 旧版： svals_qk\n",
        "        if isinstance(out, (tuple, list)) and len(out) == 4:\n",
        "            svals_qk_epoch, svals_q_epoch, svals_k_epoch, svals_v_epoch = out\n",
        "        else:\n",
        "            svals_qk_epoch = out\n",
        "            svals_q_epoch  = None\n",
        "            svals_k_epoch  = None\n",
        "            svals_v_epoch  = None\n",
        "\n",
        "        svals_qk_epochs_list.append(svals_qk_epoch.detach().cpu())\n",
        "\n",
        "        if svals_q_epoch is not None:\n",
        "            svals_q_epochs_list.append(svals_q_epoch.detach().cpu())\n",
        "        if svals_k_epoch is not None:\n",
        "            svals_k_epochs_list.append(svals_k_epoch.detach().cpu())\n",
        "        if svals_v_epoch is not None:\n",
        "            svals_v_epochs_list.append(svals_v_epoch.detach().cpu())\n",
        "\n",
        "    # ---- stack over epochs: (E,H,K) ----\n",
        "    svals_qk_epochs = torch.stack(svals_qk_epochs_list, dim=0)  # (E,H,K)\n",
        "\n",
        "    svals_q_epochs = torch.stack(svals_q_epochs_list, dim=0) if len(svals_q_epochs_list) > 0 else None\n",
        "    svals_k_epochs = torch.stack(svals_k_epochs_list, dim=0) if len(svals_k_epochs_list) > 0 else None\n",
        "    svals_v_epochs = torch.stack(svals_v_epochs_list, dim=0) if len(svals_v_epochs_list) > 0 else None\n",
        "\n",
        "    # 兼容你后续 compute_effective_rank(svals_epochs)\n",
        "    svals_epochs = svals_qk_epochs\n",
        "\n",
        "    hist = {\n",
        "        \"train_loss_curve\": train_loss_curve,\n",
        "        \"val_loss_curve\":   val_loss_curve,\n",
        "        \"train_acc_curve\":  train_acc_curve,\n",
        "        \"val_acc_curve\":    val_acc_curve,\n",
        "        \"best_val_acc\":     best_val_acc,\n",
        "\n",
        "        \"svals_epochs\":     svals_epochs,\n",
        "\n",
        "        \"svals_qk_epochs\":  svals_qk_epochs,\n",
        "        \"svals_q_epochs\":   svals_q_epochs,\n",
        "        \"svals_k_epochs\":   svals_k_epochs,\n",
        "        \"svals_v_epochs\":   svals_v_epochs,\n",
        "\n",
        "        \"total_params\":     total_params,\n",
        "        \"kv_cost\":          kv_cost,\n",
        "        \"num_heads\":        num_heads,\n",
        "        \"head_dim\":         head_dim,\n",
        "        \"mlp_ratio_used\":   mlp_ratio,\n",
        "        \"optimizer_state\":  optimizer.state_dict(),\n",
        "        \"last_epoch\": total_epochs - 1,\n",
        "    }\n",
        "\n",
        "    return model, hist\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model_MHA(\n",
        "    model: nn.Module,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    device,\n",
        "    total_epochs: int,\n",
        "    scaler=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    适用于 MHA（或任何普通单阶段模型）的训练函数。\n",
        "\n",
        "    行为：\n",
        "      - 连续跑 total_epochs 轮\n",
        "      - 每轮：\n",
        "          - 调用 train_one_epoch / eval_one_epoch\n",
        "          - 记录 train/val loss & acc\n",
        "      - 返回一个 dict，字段和其他 train_model_* 保持一致：\n",
        "          {\n",
        "            \"train_loss_curve\": [...],\n",
        "            \"val_loss_curve\":   [...],\n",
        "            \"train_acc_curve\":  [...],\n",
        "            \"val_acc_curve\":    [...],\n",
        "            \"best_val_acc\":     float,\n",
        "          }\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    train_loss_curve = []\n",
        "    val_loss_curve   = []\n",
        "    train_acc_curve  = []\n",
        "    val_acc_curve    = []\n",
        "    best_val_acc     = 0.0\n",
        "\n",
        "    use_amp = scaler is not None  # 预留，和其他函数保持一致\n",
        "\n",
        "    for epoch in range(total_epochs):\n",
        "        # 一轮训练\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model=model,\n",
        "            loader=train_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "            scaler=scaler,\n",
        "        )\n",
        "\n",
        "        # 一轮验证\n",
        "        val_loss, val_acc = eval_one_epoch(\n",
        "            model=model,\n",
        "            loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "        )\n",
        "\n",
        "        train_loss_curve.append(train_loss)\n",
        "        val_loss_curve.append(val_loss)\n",
        "        train_acc_curve.append(train_acc)\n",
        "        val_acc_curve.append(val_acc)\n",
        "        best_val_acc = max(best_val_acc, val_acc)\n",
        "\n",
        "        print(\n",
        "            f\"[MHA] Epoch {epoch+1}/{total_epochs} | \"\n",
        "            f\"train loss: {train_loss:.4f}, train acc: {train_acc:.3f} | \"\n",
        "            f\"val loss: {val_loss:.4f}, val acc: {val_acc:.3f}\"\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"train_loss_curve\": train_loss_curve,\n",
        "        \"val_loss_curve\":   val_loss_curve,\n",
        "        \"train_acc_curve\":  train_acc_curve,\n",
        "        \"val_acc_curve\":    val_acc_curve,\n",
        "        \"best_val_acc\":     best_val_acc,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1um9zlRUpH5I"
      },
      "source": [
        "TPA module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "grhHD8m3pK0H"
      },
      "outputs": [],
      "source": [
        "class ContextualCPAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    CP-style Tensor Product Attention，支持两种模式：\n",
        "    - contextA = True :\n",
        "        A_q(x), A_k(x), A_v(x) 是 token 因子 (B, N, R) —— contextual A\n",
        "        B_q, B_k, B_v 是 head 因子 (R, H, D) —— non-contextual B\n",
        "        Q = sum_r A_q(x)[r] * B_q[r]\n",
        "\n",
        "    - contextA = False :\n",
        "        A_q, A_k, A_v 是全局 token 因子 (R,) —— non-contextual A\n",
        "        B_q(x), B_k(x), B_v(x) 是 head 因子 (B, N, R, H, D) —— contextual B\n",
        "        Q = sum_r A_q[r] * B_q(x)[r]\n",
        "    接口和 timm 的 Attention 一致：forward(x, attn_mask=None) -> (B, N, C)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        num_heads: int = 8,\n",
        "        rank_q: int = 16,\n",
        "        rank_k: int = 16,\n",
        "        rank_v: int = 16,\n",
        "        qkv_bias: bool = True,\n",
        "        qk_scale: float = None,\n",
        "        attn_drop: float = 0.0,\n",
        "        proj_drop: float = 0.0,\n",
        "        contextA: bool = True,   # True: contextual A, False: contextual B\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0, \"dim must be divisible by num_heads\"\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "\n",
        "        self.rank_q = rank_q\n",
        "        self.rank_k = rank_k\n",
        "        self.rank_v = rank_v\n",
        "        self.contextA = contextA\n",
        "\n",
        "        # ===== 模式一：contextual A, non-contextual B =====\n",
        "        if self.contextA:\n",
        "            # token 因子 A_q(x), A_k(x), A_v(x) : (B, N, R)\n",
        "            self.A_q = nn.Linear(dim, rank_q, bias=qkv_bias)\n",
        "            self.A_k = nn.Linear(dim, rank_k, bias=qkv_bias)\n",
        "            self.A_v = nn.Linear(dim, rank_v, bias=qkv_bias)\n",
        "\n",
        "            # head 因子 B_q, B_k, B_v : (R, H, D) 全局参数\n",
        "            self.B_q = nn.Parameter(torch.empty(rank_q, num_heads, self.head_dim))\n",
        "            self.B_k = nn.Parameter(torch.empty(rank_k, num_heads, self.head_dim))\n",
        "            self.B_v = nn.Parameter(torch.empty(rank_v, num_heads, self.head_dim))\n",
        "\n",
        "            nn.init.xavier_uniform_(self.B_q.view(rank_q, -1))\n",
        "            nn.init.xavier_uniform_(self.B_k.view(rank_k, -1))\n",
        "            nn.init.xavier_uniform_(self.B_v.view(rank_v, -1))\n",
        "\n",
        "        # ===== 模式二：non-contextual A, contextual B =====\n",
        "        else:\n",
        "            # token 因子 A_q, A_k, A_v : (R,) 全局参数\n",
        "            self.A_q = nn.Parameter(torch.empty(rank_q))\n",
        "            self.A_k = nn.Parameter(torch.empty(rank_k))\n",
        "            self.A_v = nn.Parameter(torch.empty(rank_v))\n",
        "\n",
        "            nn.init.normal_(self.A_q, std=0.02)\n",
        "            nn.init.normal_(self.A_k, std=0.02)\n",
        "            nn.init.normal_(self.A_v, std=0.02)\n",
        "\n",
        "            # head 因子 B_q(x), B_k(x), B_v(x) : (B, N, R, H, D)\n",
        "            self.B_q = nn.Linear(dim, rank_q * num_heads * self.head_dim, bias=qkv_bias)\n",
        "            self.B_k = nn.Linear(dim, rank_k * num_heads * self.head_dim, bias=qkv_bias)\n",
        "            self.B_v = nn.Linear(dim, rank_v * num_heads * self.head_dim, bias=qkv_bias)\n",
        "\n",
        "        self.scale = qk_scale or (self.head_dim ** -0.5)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def _make_qkv(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, N, C)\n",
        "        return q, k, v: (B, H, N, D)\n",
        "        \"\"\"\n",
        "        B, N, C = x.shape\n",
        "\n",
        "        if self.contextA:\n",
        "            # ---------- contextual A, non-contextual B ----------\n",
        "            q_tok = self.A_q(x)   # (B, N, R_q)\n",
        "            k_tok = self.A_k(x)   # (B, N, R_k)\n",
        "            v_tok = self.A_v(x)   # (B, N, R_v)\n",
        "\n",
        "            # 外积重构 Q/K/V: bnr, r h d -> b n h d\n",
        "            q = torch.einsum(\"bnr,rhd->bnhd\", q_tok, self.B_q)\n",
        "            k = torch.einsum(\"bnr,rhd->bnhd\", k_tok, self.B_k)\n",
        "            v = torch.einsum(\"bnr,rhd->bnhd\", v_tok, self.B_v)\n",
        "\n",
        "        else:\n",
        "            # ---------- non-contextual A, contextual B ----------\n",
        "            # A: (R,) -> (1,1,R) -> (B,N,R)\n",
        "            q_tok = self.A_q.view(1, 1, self.rank_q).expand(B, N, -1)  # (B,N,R_q)\n",
        "            k_tok = self.A_k.view(1, 1, self.rank_k).expand(B, N, -1)  # (B,N,R_k)\n",
        "            v_tok = self.A_v.view(1, 1, self.rank_v).expand(B, N, -1)  # (B,N,R_v)\n",
        "\n",
        "            # B(x): (B,N,R,H,D)\n",
        "            Bq = self.B_q(x).view(B, N, self.rank_q, self.num_heads, self.head_dim)\n",
        "            Bk = self.B_k(x).view(B, N, self.rank_k, self.num_heads, self.head_dim)\n",
        "            Bv = self.B_v(x).view(B, N, self.rank_v, self.num_heads, self.head_dim)\n",
        "\n",
        "            # bnr, bnrhd -> bnhd\n",
        "            q = torch.einsum(\"bnr,bnrhd->bnhd\", q_tok, Bq)\n",
        "            k = torch.einsum(\"bnr,bnrhd->bnhd\", k_tok, Bk)\n",
        "            v = torch.einsum(\"bnr,bnrhd->bnhd\", v_tok, Bv)\n",
        "\n",
        "        # reshape 成 (B, H, N, D)\n",
        "        q = q.permute(0, 2, 1, 3)\n",
        "        k = k.permute(0, 2, 1, 3)\n",
        "        v = v.permute(0, 2, 1, 3)\n",
        "\n",
        "        return q, k, v\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        \"\"\"\n",
        "        x: (B, N, C)\n",
        "        attn_mask: 兼容 timm 接口，一般 ViT 不会用到\n",
        "        \"\"\"\n",
        "        B, N, C = x.shape\n",
        "\n",
        "        q, k, v = self._make_qkv(x)  # (B, H, N, D)\n",
        "\n",
        "        attn = (q * self.scale) @ k.transpose(-2, -1)  # (B, H, N, N)\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            attn = attn + attn_mask\n",
        "\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        out = attn @ v  # (B, H, N, D)\n",
        "        out = out.transpose(1, 2).reshape(B, N, C)  # (B, N, C)\n",
        "\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UNXvu7Pff-DS"
      },
      "outputs": [],
      "source": [
        "class TPAAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    True Tensor Product Attention with separate ranks R_q, R_k, R_v,\n",
        "    按原文公式 100% 走「两向量外积」版本：\n",
        "\n",
        "      对每个 token t：\n",
        "        A_Q(x_t) ∈ R^{R_q × h},  B_Q(x_t) ∈ R^{R_q × d_h}\n",
        "        Q_t = (1 / R_q) * A_Q(x_t)^T B_Q(x_t) ∈ R^{h × d_h}\n",
        "\n",
        "      K, V 同理。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        num_heads: int = 8,\n",
        "        rank_q: int = 16,\n",
        "        rank_k: int = 2,\n",
        "        rank_v: int = 2,\n",
        "        qkv_bias: bool = True,\n",
        "        qk_scale: float = None,\n",
        "        attn_drop: float = 0.0,\n",
        "        proj_drop: float = 0.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0, \"dim must be divisible by num_heads\"\n",
        "\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "\n",
        "        self.rank_q = rank_q\n",
        "        self.rank_k = rank_k\n",
        "        self.rank_v = rank_v\n",
        "\n",
        "        # ========== A(x): head-dim factors, shape (R * h) ==========\n",
        "        # 对应论文里的 A_Q(xt) ∈ R^{R_q×h} 展平之后的线性映射\n",
        "        self.A_q = nn.Linear(dim, rank_q * num_heads, bias=qkv_bias)\n",
        "        self.A_k = nn.Linear(dim, rank_k * num_heads, bias=qkv_bias)\n",
        "        self.A_v = nn.Linear(dim, rank_v * num_heads, bias=qkv_bias)\n",
        "\n",
        "        # ========== B(x): token-dim factors, shape (R * d_h) ==========\n",
        "        # 对应论文里的 B_Q(xt) ∈ R^{R_q×d_h} 展平之后的线性映射\n",
        "        self.B_q = nn.Linear(dim, rank_q * self.head_dim, bias=qkv_bias)\n",
        "        self.B_k = nn.Linear(dim, rank_k * self.head_dim, bias=qkv_bias)\n",
        "        self.B_v = nn.Linear(dim, rank_v * self.head_dim, bias=qkv_bias)\n",
        "\n",
        "        # 缩放和输出\n",
        "        self.scale = qk_scale or (self.head_dim ** -0.5)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def _make_qkv(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, N, C = dim)\n",
        "\n",
        "        返回:\n",
        "          q, k, v: (B, H, N, D_h)\n",
        "        \"\"\"\n",
        "        B, N, C = x.shape\n",
        "        H, Dh = self.num_heads, self.head_dim\n",
        "\n",
        "        # ---------- queries ----------\n",
        "        Aq = self.A_q(x).view(B, N, self.rank_q, H)      # (B,N,R_q,H)\n",
        "        Bq = self.B_q(x).view(B, N, self.rank_q, Dh)     # (B,N,R_q,D_h)\n",
        "        # Qt: (B,N,H,D_h) = (1/R_q) * sum_r a_r ⊗ b_r\n",
        "        Q = torch.einsum(\"bnrh,bnrd->bnhd\", Aq, Bq) / float(self.rank_q)\n",
        "\n",
        "        # ---------- keys ----------\n",
        "        Ak = self.A_k(x).view(B, N, self.rank_k, H)      # (B,N,R_k,H)\n",
        "        Bk = self.B_k(x).view(B, N, self.rank_k, Dh)     # (B,N,R_k,D_h)\n",
        "        K = torch.einsum(\"bnrh,bnrd->bnhd\", Ak, Bk) / float(self.rank_k)\n",
        "\n",
        "        # ---------- values ----------\n",
        "        Av = self.A_v(x).view(B, N, self.rank_v, H)      # (B,N,R_v,H)\n",
        "        Bv = self.B_v(x).view(B, N, self.rank_v, Dh)     # (B,N,R_v,D_h)\n",
        "        V = torch.einsum(\"bnrh,bnrd->bnhd\", Av, Bv) / float(self.rank_v)\n",
        "\n",
        "        # 现在 Q,K,V 形状是 (B, N, H, D_h)，需要转成 (B, H, N, D_h)\n",
        "        Q = Q.permute(0, 2, 1, 3).contiguous()\n",
        "        K = K.permute(0, 2, 1, 3).contiguous()\n",
        "        V = V.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        return Q, K, V\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        \"\"\"\n",
        "        x: (B, N, C)\n",
        "        返回: (B, N, C)\n",
        "        \"\"\"\n",
        "        B, N, C = x.shape\n",
        "        assert C == self.dim\n",
        "\n",
        "        q, k, v = self._make_qkv(x)        # (B,H,N,D_h)\n",
        "\n",
        "        attn = (q * self.scale) @ k.transpose(-2, -1)  # (B,H,N,N)\n",
        "        if attn_mask is not None:\n",
        "            attn = attn + attn_mask\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        out = attn @ v                     # (B,H,N,D_h)\n",
        "        out = out.transpose(1, 2).reshape(B, N, C)  # (B,N,C)\n",
        "\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def train_model_TPA(\n",
        "    model: nn.Module,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    device,\n",
        "    total_epochs: int,\n",
        "    scaler=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    适用于 TPA（或普通单阶段模型）的训练函数。\n",
        "\n",
        "    行为：\n",
        "      - 连续跑 total_epochs 轮\n",
        "      - 每轮：\n",
        "          - 调用 train_one_epoch / eval_one_epoch\n",
        "          - 记录 train/val loss & acc\n",
        "      - 返回一个 dict，字段和 train_model_two_stage_tucker 保持一致：\n",
        "          {\n",
        "            \"train_loss_curve\": [...],\n",
        "            \"val_loss_curve\":   [...],\n",
        "            \"train_acc_curve\":  [...],\n",
        "            \"val_acc_curve\":    [...],\n",
        "            \"best_val_acc\":     float,\n",
        "          }\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    train_loss_curve = []\n",
        "    val_loss_curve   = []\n",
        "    train_acc_curve  = []\n",
        "    val_acc_curve    = []\n",
        "    best_val_acc     = 0.0\n",
        "\n",
        "    use_amp = scaler is not None\n",
        "\n",
        "    for epoch in range(total_epochs):\n",
        "        # 一轮训练\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model=model,\n",
        "            loader=train_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "            scaler=scaler,\n",
        "        )\n",
        "\n",
        "        # 一轮验证\n",
        "        val_loss, val_acc = eval_one_epoch(\n",
        "            model=model,\n",
        "            loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "        )\n",
        "\n",
        "        train_loss_curve.append(train_loss)\n",
        "        val_loss_curve.append(val_loss)\n",
        "        train_acc_curve.append(train_acc)\n",
        "        val_acc_curve.append(val_acc)\n",
        "        best_val_acc = max(best_val_acc, val_acc)\n",
        "\n",
        "        print(\n",
        "            f\"[TPA] Epoch {epoch+1}/{total_epochs} | \"\n",
        "            f\"train loss: {train_loss:.4f}, train acc: {train_acc:.3f} | \"\n",
        "            f\"val loss: {val_loss:.4f}, val acc: {val_acc:.3f}\"\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"train_loss_curve\": train_loss_curve,\n",
        "        \"val_loss_curve\":   val_loss_curve,\n",
        "        \"train_acc_curve\":  train_acc_curve,\n",
        "        \"val_acc_curve\":    val_acc_curve,\n",
        "        \"best_val_acc\":     best_val_acc,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class NonlinearTPAAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    True TPA + shared MLP 非线性（可选作用于 Q/K/V 的任意组合）\n",
        "      Q_lin = (1/R_q) * A_Q(x)^T B_Q(x)\n",
        "      Q = f(Q_lin)\n",
        "\n",
        "    通过 mlp_on 控制对哪些分支加 MLP：\n",
        "      - \"qkv\" / \"qk\" / \"kv\" / \"q\" / \"k\" / \"v\" / \"none\"\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        num_heads: int = 8,\n",
        "        rank_q: int = 16,\n",
        "        rank_k: int = 2,\n",
        "        rank_v: int = 2,\n",
        "        qkv_bias: bool = True,\n",
        "        qk_scale: float = None,\n",
        "        attn_drop: float = 0.0,\n",
        "        proj_drop: float = 0.0,\n",
        "        mlp_hidden_ratio: float = 1.0,\n",
        "        mlp_on: str = \"qkv\",   # ✅ 新增\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0, \"dim must be divisible by num_heads\"\n",
        "\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "\n",
        "        self.rank_q = rank_q\n",
        "        self.rank_k = rank_k\n",
        "        self.rank_v = rank_v\n",
        "\n",
        "        # ====== A(x) / B(x) ======\n",
        "        self.A_q = nn.Linear(dim, rank_q * num_heads, bias=qkv_bias)\n",
        "        self.A_k = nn.Linear(dim, rank_k * num_heads, bias=qkv_bias)\n",
        "        self.A_v = nn.Linear(dim, rank_v * num_heads, bias=qkv_bias)\n",
        "\n",
        "        self.B_q = nn.Linear(dim, rank_q * self.head_dim, bias=qkv_bias)\n",
        "        self.B_k = nn.Linear(dim, rank_k * self.head_dim, bias=qkv_bias)\n",
        "        self.B_v = nn.Linear(dim, rank_v * self.head_dim, bias=qkv_bias)\n",
        "\n",
        "        # -------- MLP 选择逻辑（和你的 headwise 版本一致的风格）--------\n",
        "        mlp_on = \"none\" if mlp_on is None else str(mlp_on).lower().strip()\n",
        "\n",
        "\n",
        "        self.kv_shared = (mlp_on == \"kv_shared\")\n",
        "\n",
        "        allowed = set(\"qkv\")\n",
        "        if mlp_on in (\"\", \"none\", \"null\", \"no\", \"false\", \"0\"):\n",
        "            mlp_set = set()\n",
        "\n",
        "        elif self.kv_shared:\n",
        "            mlp_set = set(\"kv\")\n",
        "\n",
        "        else:\n",
        "            mlp_set = set(mlp_on)\n",
        "            if not mlp_set.issubset(allowed):\n",
        "                raise ValueError(f\"mlp_on must be subset of 'qkv' or 'none', got: {mlp_on}\")\n",
        "        self.mlp_on = mlp_set\n",
        "\n",
        "        hidden_dim = int(self.head_dim * mlp_hidden_ratio)\n",
        "\n",
        "        def make_mlp():\n",
        "            return nn.Sequential(\n",
        "                nn.Linear(self.head_dim, hidden_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Linear(hidden_dim, self.head_dim),\n",
        "            )\n",
        "\n",
        "        # ✅ shared MLP：没选中的分支用 Identity，确保“数值不变”\n",
        "        self.q_mlp = make_mlp() if \"q\" in self.mlp_on else nn.Identity()\n",
        "        if self.kv_shared and (\"k\" in self.mlp_on) and (\"v\" in self.mlp_on):\n",
        "            kv_mlp = make_mlp()\n",
        "            self.k_mlp = kv_mlp\n",
        "            self.v_mlp = kv_mlp\n",
        "        else:\n",
        "            self.k_mlp = make_mlp() if \"k\" in self.mlp_on else nn.Identity()\n",
        "            self.v_mlp = make_mlp() if \"v\" in self.mlp_on else nn.Identity()\n",
        "\n",
        "        # attention 输出\n",
        "        self.scale = qk_scale or (self.head_dim ** -0.5)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def _make_qkv(self, x):\n",
        "        B, N, C = x.shape\n",
        "        H, Dh = self.num_heads, self.head_dim\n",
        "\n",
        "        # ---------- linear TPA ----------\n",
        "        Aq = self.A_q(x).view(B, N, self.rank_q, H)\n",
        "        Bq = self.B_q(x).view(B, N, self.rank_q, Dh)\n",
        "        Q = torch.einsum(\"bnrh,bnrd->bnhd\", Aq, Bq) / float(self.rank_q)\n",
        "\n",
        "        Ak = self.A_k(x).view(B, N, self.rank_k, H)\n",
        "        Bk = self.B_k(x).view(B, N, self.rank_k, Dh)\n",
        "        K = torch.einsum(\"bnrh,bnrd->bnhd\", Ak, Bk) / float(self.rank_k)\n",
        "\n",
        "        Av = self.A_v(x).view(B, N, self.rank_v, H)\n",
        "        Bv = self.B_v(x).view(B, N, self.rank_v, Dh)\n",
        "        V = torch.einsum(\"bnrh,bnrd->bnhd\", Av, Bv) / float(self.rank_v)\n",
        "\n",
        "        Q = Q.permute(0, 2, 1, 3).contiguous()  # (B,H,N,Dh)\n",
        "        K = K.permute(0, 2, 1, 3).contiguous()\n",
        "        V = V.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        # ---------- optional nonlinearity ----------\n",
        "        Q = self.q_mlp(Q)\n",
        "        K = self.k_mlp(K)\n",
        "        V = self.v_mlp(V)\n",
        "\n",
        "        return Q, K, V\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        B, N, C = x.shape\n",
        "        assert C == self.dim\n",
        "\n",
        "        q, k, v = self._make_qkv(x)\n",
        "        attn = (q * self.scale) @ k.transpose(-2, -1)\n",
        "        if attn_mask is not None:\n",
        "            attn = attn + attn_mask\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        out = attn @ v\n",
        "        out = out.transpose(1, 2).reshape(B, N, C)\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "def train_model_nonlinear_TPA(\n",
        "    model: nn.Module,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    device,\n",
        "    total_epochs: int,\n",
        "    scaler=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    适用于 NonlinearTPAAttention（或其它单阶段模型）的训练函数。\n",
        "\n",
        "    行为和 train_model_TPA 一致，只是打印前缀换成 [NonlinearTPA]，\n",
        "    方便你后面对比两条曲线。\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    train_loss_curve = []\n",
        "    val_loss_curve   = []\n",
        "    train_acc_curve  = []\n",
        "    val_acc_curve    = []\n",
        "    best_val_acc     = 0.0\n",
        "\n",
        "    use_amp = scaler is not None  # 这里先保留这个变量，方便以后需要用\n",
        "\n",
        "    for epoch in range(total_epochs):\n",
        "        # 一轮训练\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model=model,\n",
        "            loader=train_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "            scaler=scaler,\n",
        "        )\n",
        "\n",
        "        # 一轮验证\n",
        "        val_loss, val_acc = eval_one_epoch(\n",
        "            model=model,\n",
        "            loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "        )\n",
        "\n",
        "        train_loss_curve.append(train_loss)\n",
        "        val_loss_curve.append(val_loss)\n",
        "        train_acc_curve.append(train_acc)\n",
        "        val_acc_curve.append(val_acc)\n",
        "        best_val_acc = max(best_val_acc, val_acc)\n",
        "\n",
        "        print(\n",
        "            f\"[NonlinearTPA] Epoch {epoch+1}/{total_epochs} | \"\n",
        "            f\"train loss: {train_loss:.4f}, train acc: {train_acc:.3f} | \"\n",
        "            f\"val loss: {val_loss:.4f}, val acc: {val_acc:.3f}\"\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"train_loss_curve\": train_loss_curve,\n",
        "        \"val_loss_curve\":   val_loss_curve,\n",
        "        \"train_acc_curve\":  train_acc_curve,\n",
        "        \"val_acc_curve\":    val_acc_curve,\n",
        "        \"best_val_acc\":     best_val_acc,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class HeadwiseNonlinearTPAAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    True TPA + 每个 head 独立的 MLP 非线性（可选作用于 Q/K/V 的任意组合）\n",
        "\n",
        "    通过 mlp_on 控制对哪些分支加 MLP：\n",
        "      - \"qkv\" / \"qk\" / \"kv\" / \"q\" / \"k\" / \"v\" / \"none\"\n",
        "      - 额外支持：\"kv_shared\"\n",
        "          含义：每个 head 一个 MLP，但该 head 内 K/V 共享同一个 MLP\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        num_heads: int = 8,\n",
        "        rank_q: int = 16,\n",
        "        rank_k: int = 2,\n",
        "        rank_v: int = 2,\n",
        "        qkv_bias: bool = True,\n",
        "        qk_scale: float = None,\n",
        "        attn_drop: float = 0.0,\n",
        "        proj_drop: float = 0.0,\n",
        "        mlp_hidden_ratio: float = 1.0,\n",
        "        mlp_on: str = \"qkv\",\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0, \"dim must be divisible by num_heads\"\n",
        "\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "\n",
        "        self.rank_q = rank_q\n",
        "        self.rank_k = rank_k\n",
        "        self.rank_v = rank_v\n",
        "\n",
        "        # -------- A(x) / B(x) --------\n",
        "        self.A_q = nn.Linear(dim, rank_q * num_heads, bias=qkv_bias)\n",
        "        self.A_k = nn.Linear(dim, rank_k * num_heads, bias=qkv_bias)\n",
        "        self.A_v = nn.Linear(dim, rank_v * num_heads, bias=qkv_bias)\n",
        "\n",
        "        self.B_q = nn.Linear(dim, rank_q * self.head_dim, bias=qkv_bias)\n",
        "        self.B_k = nn.Linear(dim, rank_k * self.head_dim, bias=qkv_bias)\n",
        "        self.B_v = nn.Linear(dim, rank_v * self.head_dim, bias=qkv_bias)\n",
        "\n",
        "        # -------- MLP 选择逻辑（新增 kv_shared）--------\n",
        "        mlp_on = \"none\" if mlp_on is None else str(mlp_on).lower().strip()\n",
        "        self.kv_shared = (mlp_on == \"kv_shared\")\n",
        "\n",
        "        allowed = set(\"qkv\")\n",
        "        if mlp_on in (\"\", \"none\", \"null\", \"no\", \"false\", \"0\"):\n",
        "            mlp_set = set()\n",
        "        elif self.kv_shared:\n",
        "            mlp_set = set(\"kv\")  # => {\"k\",\"v\"}\n",
        "        else:\n",
        "            mlp_set = set(mlp_on)\n",
        "            if not mlp_set.issubset(allowed):\n",
        "                raise ValueError(f\"mlp_on must be subset of 'qkv' or 'none' (or 'kv_shared'), got: {mlp_on}\")\n",
        "        self.mlp_on = mlp_set\n",
        "\n",
        "        hidden_dim = max(1, int(self.head_dim * mlp_hidden_ratio))\n",
        "\n",
        "        def make_mlp():\n",
        "            return nn.Sequential(\n",
        "                nn.Linear(self.head_dim, hidden_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Linear(hidden_dim, self.head_dim),\n",
        "            )\n",
        "\n",
        "        # -------- 每个 head 一套 MLP；没选中的分支用 Identity --------\n",
        "        # Q\n",
        "        if \"q\" in self.mlp_on:\n",
        "            self.q_mlps = nn.ModuleList([make_mlp() for _ in range(num_heads)])\n",
        "        else:\n",
        "            self.q_mlps = nn.ModuleList([nn.Identity() for _ in range(num_heads)])\n",
        "\n",
        "        # K/V\n",
        "        if self.kv_shared:\n",
        "            # 关键：只注册一次 kv_mlps，避免重复参数引用\n",
        "            self.kv_mlps = nn.ModuleList([make_mlp() for _ in range(num_heads)])\n",
        "            self.k_mlps = None\n",
        "            self.v_mlps = None\n",
        "        else:\n",
        "            self.kv_mlps = None\n",
        "            if \"k\" in self.mlp_on:\n",
        "                self.k_mlps = nn.ModuleList([make_mlp() for _ in range(num_heads)])\n",
        "            else:\n",
        "                self.k_mlps = nn.ModuleList([nn.Identity() for _ in range(num_heads)])\n",
        "\n",
        "            if \"v\" in self.mlp_on:\n",
        "                self.v_mlps = nn.ModuleList([make_mlp() for _ in range(num_heads)])\n",
        "            else:\n",
        "                self.v_mlps = nn.ModuleList([nn.Identity() for _ in range(num_heads)])\n",
        "\n",
        "        # -------- attention 输出部分 --------\n",
        "        self.scale = qk_scale or (self.head_dim ** -0.5)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def _apply_headwise_mlp(self, x_bhnd, mlps: nn.ModuleList):\n",
        "        \"\"\"\n",
        "        x_bhnd: (B, H, N, D_h)\n",
        "        对每个 head 分别过对应的 mlp\n",
        "        \"\"\"\n",
        "        B, H, N, Dh = x_bhnd.shape\n",
        "        outs = []\n",
        "        for h in range(H):\n",
        "            outs.append(mlps[h](x_bhnd[:, h, :, :]))  # (B,N,Dh)\n",
        "        return torch.stack(outs, dim=1)  # (B,H,N,Dh)\n",
        "\n",
        "    def _make_qkv(self, x):\n",
        "        B, N, C = x.shape\n",
        "        H, Dh = self.num_heads, self.head_dim\n",
        "\n",
        "        Aq = self.A_q(x).view(B, N, self.rank_q, H)\n",
        "        Bq = self.B_q(x).view(B, N, self.rank_q, Dh)\n",
        "        Q = torch.einsum(\"bnrh,bnrd->bnhd\", Aq, Bq) / float(self.rank_q)\n",
        "\n",
        "        Ak = self.A_k(x).view(B, N, self.rank_k, H)\n",
        "        Bk = self.B_k(x).view(B, N, self.rank_k, Dh)\n",
        "        K = torch.einsum(\"bnrh,bnrd->bnhd\", Ak, Bk) / float(self.rank_k)\n",
        "\n",
        "        Av = self.A_v(x).view(B, N, self.rank_v, H)\n",
        "        Bv = self.B_v(x).view(B, N, self.rank_v, Dh)\n",
        "        V = torch.einsum(\"bnrh,bnrd->bnhd\", Av, Bv) / float(self.rank_v)\n",
        "\n",
        "        Q = Q.permute(0, 2, 1, 3).contiguous()  # (B,H,N,Dh)\n",
        "        K = K.permute(0, 2, 1, 3).contiguous()\n",
        "        V = V.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        # head-wise 非线性\n",
        "        Q = self._apply_headwise_mlp(Q, self.q_mlps)\n",
        "\n",
        "        if self.kv_shared:\n",
        "            K = self._apply_headwise_mlp(K, self.kv_mlps)\n",
        "            V = self._apply_headwise_mlp(V, self.kv_mlps)\n",
        "        else:\n",
        "            K = self._apply_headwise_mlp(K, self.k_mlps)\n",
        "            V = self._apply_headwise_mlp(V, self.v_mlps)\n",
        "\n",
        "        return Q, K, V\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        B, N, C = x.shape\n",
        "        assert C == self.dim\n",
        "\n",
        "        q, k, v = self._make_qkv(x)\n",
        "        attn = (q * self.scale) @ k.transpose(-2, -1)\n",
        "        if attn_mask is not None:\n",
        "            attn = attn + attn_mask\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        out = attn @ v\n",
        "        out = out.transpose(1, 2).reshape(B, N, C)\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class Sinter(nn.Module):\n",
        "    \"\"\"\n",
        "    Sinter 激活函数：\n",
        "        Sinter(x) = x + A * x * sin(omega * x)\n",
        "                  = x * (1 + A * sin(omega * x))\n",
        "\n",
        "    A 和 omega 按 LoRAN 论文给的量级设置为默认值：\n",
        "      - A 很小（1e-5 量级），保证整体接近恒等映射；\n",
        "      - omega 很大（1e4 量级），在输入空间引入高频微扰。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, A: float = 5e-5, omega: float = 1e4):\n",
        "        super().__init__()\n",
        "        self.A = A\n",
        "        self.omega = omega\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: 任意形状，逐元素作用\n",
        "        return x + self.A * x * torch.sin(self.omega * x)\n",
        "        # 等价写法：return x * (1 + self.A * torch.sin(self.omega * x))\n",
        "\n",
        "\n",
        "class SinterTPAAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    在原始 TPA 的基础上，加一层简单的 MLP + Sinter 非线性：\n",
        "      Q_lin = (1/R_q) * A_Q(x)^T B_Q(x)\n",
        "      Q = f_q(Q_lin)\n",
        "\n",
        "    f_q / f_k / f_v 都是两层 MLP: D_h -> D_h_hidden -> D_h\n",
        "    激活函数用 Sinter 而不是 GeLU。\n",
        "    默认 D_h_hidden = D_h（最简单的版本）\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        num_heads: int = 8,\n",
        "        rank_q: int = 16,\n",
        "        rank_k: int = 2,\n",
        "        rank_v: int = 2,\n",
        "        qkv_bias: bool = True,\n",
        "        qk_scale: float = None,\n",
        "        attn_drop: float = 0.0,\n",
        "        proj_drop: float = 0.0,\n",
        "        mlp_hidden_ratio: float = 1.0,  # 隐藏层大小 = ratio * head_dim\n",
        "        # Sinter 超参数\n",
        "        sinter_A: float = 5e-5,\n",
        "        sinter_omega: float = 1e4,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0, \"dim must be divisible by num_heads\"\n",
        "\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "\n",
        "        self.rank_q = rank_q\n",
        "        self.rank_k = rank_k\n",
        "        self.rank_v = rank_v\n",
        "\n",
        "        # ========== A(x): head-dim factors, shape (R * h) ==========\n",
        "        self.A_q = nn.Linear(dim, rank_q * num_heads, bias=qkv_bias)\n",
        "        self.A_k = nn.Linear(dim, rank_k * num_heads, bias=qkv_bias)\n",
        "        self.A_v = nn.Linear(dim, rank_v * num_heads, bias=qkv_bias)\n",
        "\n",
        "        # ========== B(x): token-dim factors, shape (R * d_h) ==========\n",
        "        self.B_q = nn.Linear(dim, rank_q * self.head_dim, bias=qkv_bias)\n",
        "        self.B_k = nn.Linear(dim, rank_k * self.head_dim, bias=qkv_bias)\n",
        "        self.B_v = nn.Linear(dim, rank_v * self.head_dim, bias=qkv_bias)\n",
        "\n",
        "        # ---------- 在 D_h 维度上做 MLP + Sinter 非线性 ----------\n",
        "        hidden_dim = int(self.head_dim * mlp_hidden_ratio)\n",
        "\n",
        "        def make_mlp():\n",
        "            return nn.Sequential(\n",
        "                nn.Linear(self.head_dim, hidden_dim),\n",
        "                Sinter(A=sinter_A, omega=sinter_omega),\n",
        "                nn.Linear(hidden_dim, self.head_dim),\n",
        "            )\n",
        "\n",
        "        # 可以选择 Q/K/V 各自一个 MLP，也可以视需要改为共享\n",
        "        self.q_mlp = make_mlp()\n",
        "        self.k_mlp = make_mlp()\n",
        "        self.v_mlp = make_mlp()\n",
        "\n",
        "        # 缩放和输出\n",
        "        self.scale = qk_scale or (self.head_dim ** -0.5)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def _make_qkv(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, N, C = dim)\n",
        "        返回:\n",
        "          q, k, v: (B, H, N, D_h)\n",
        "        \"\"\"\n",
        "        B, N, C = x.shape\n",
        "        H, Dh = self.num_heads, self.head_dim\n",
        "\n",
        "        # ---------- linear TPA 部分 ----------\n",
        "        # Q\n",
        "        Aq = self.A_q(x).view(B, N, self.rank_q, H)      # (B,N,R_q,H)\n",
        "        Bq = self.B_q(x).view(B, N, self.rank_q, Dh)     # (B,N,R_q,D_h)\n",
        "        Q = torch.einsum(\"bnrh,bnrd->bnhd\", Aq, Bq) / float(self.rank_q)\n",
        "\n",
        "        # K\n",
        "        Ak = self.A_k(x).view(B, N, self.rank_k, H)      # (B,N,R_k,H)\n",
        "        Bk = self.B_k(x).view(B, N, self.rank_k, Dh)     # (B,N,R_k,D_h)\n",
        "        K = torch.einsum(\"bnrh,bnrd->bnhd\", Ak, Bk) / float(self.rank_k)\n",
        "\n",
        "        # V\n",
        "        Av = self.A_v(x).view(B, N, self.rank_v, H)      # (B,N,R_v,H)\n",
        "        Bv = self.B_v(x).view(B, N, self.rank_v, Dh)     # (B,N,R_v,D_h)\n",
        "        V = torch.einsum(\"bnrh,bnrd->bnhd\", Av, Bv) / float(self.rank_v)\n",
        "\n",
        "        # 现在 Q,K,V 形状是 (B, N, H, D_h)，需要转成 (B, H, N, D_h)\n",
        "        Q = Q.permute(0, 2, 1, 3).contiguous()  # (B,H,N,D_h)\n",
        "        K = K.permute(0, 2, 1, 3).contiguous()\n",
        "        V = V.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        # ---------- 在 D_h 维度加一层 MLP: f(Q_lin) ----------\n",
        "        Q = self.q_mlp(Q)   # (B,H,N,D_h)\n",
        "        K = self.k_mlp(K)\n",
        "        V = self.v_mlp(V)\n",
        "\n",
        "        return Q, K, V\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        \"\"\"\n",
        "        x: (B, N, C)\n",
        "        返回: (B, N, C)\n",
        "        \"\"\"\n",
        "        B, N, C = x.shape\n",
        "        assert C == self.dim\n",
        "\n",
        "        q, k, v = self._make_qkv(x)        # (B,H,N,D_h)\n",
        "\n",
        "        attn = (q * self.scale) @ k.transpose(-2, -1)  # (B,H,N,N)\n",
        "        if attn_mask is not None:\n",
        "            attn = attn + attn_mask\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        out = attn @ v                     # (B,H,N,D_h)\n",
        "        out = out.transpose(1, 2).reshape(B, N, C)  # (B,N,C)\n",
        "\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out\n",
        "    \n",
        "\n",
        "\n",
        "def train_model_sinter_TPA(\n",
        "    model: nn.Module,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    device,\n",
        "    total_epochs: int,\n",
        "    scaler=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    适用于 SinterTPAAttention（或其它单阶段模型）的训练函数。\n",
        "\n",
        "    跟 train_model_nonlinear_TPA 一样，只是打印前缀换成 [SinterTPA]，\n",
        "    方便对比曲线。\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    train_loss_curve = []\n",
        "    val_loss_curve   = []\n",
        "    train_acc_curve  = []\n",
        "    val_acc_curve    = []\n",
        "    best_val_acc     = 0.0\n",
        "\n",
        "    use_amp = scaler is not None  # 预留，之后如果要改 AMP 逻辑可以用\n",
        "\n",
        "    for epoch in range(total_epochs):\n",
        "        # 一轮训练\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model=model,\n",
        "            loader=train_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "            scaler=scaler,\n",
        "        )\n",
        "\n",
        "        # 一轮验证\n",
        "        val_loss, val_acc = eval_one_epoch(\n",
        "            model=model,\n",
        "            loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "        )\n",
        "\n",
        "        train_loss_curve.append(train_loss)\n",
        "        val_loss_curve.append(val_loss)\n",
        "        train_acc_curve.append(train_acc)\n",
        "        val_acc_curve.append(val_acc)\n",
        "        best_val_acc = max(best_val_acc, val_acc)\n",
        "\n",
        "        print(\n",
        "            f\"[SinterTPA] Epoch {epoch+1}/{total_epochs} | \"\n",
        "            f\"train loss: {train_loss:.4f}, train acc: {train_acc:.3f} | \"\n",
        "            f\"val loss: {val_loss:.4f}, val acc: {val_acc:.3f}\"\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"train_loss_curve\": train_loss_curve,\n",
        "        \"val_loss_curve\":   val_loss_curve,\n",
        "        \"train_acc_curve\":  train_acc_curve,\n",
        "        \"val_acc_curve\":    val_acc_curve,\n",
        "        \"best_val_acc\":     best_val_acc,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ta-l3DXqVDYy"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class ContextualTuckerTPAAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        num_heads: int = 8,\n",
        "        rank_q: int = 16,\n",
        "        rank_k: int = 2,\n",
        "        rank_v: int = 2,\n",
        "        rank_head: int = None,\n",
        "        rank_channel: int = None,\n",
        "        qkv_bias: bool = True,\n",
        "        qk_scale: float = None,\n",
        "        attn_drop: float = 0.0,\n",
        "        proj_drop: float = 0.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "\n",
        "        # -------- rank 解析（和你原来的逻辑一样）---------\n",
        "        if rank_q is None:\n",
        "            if rank_head is not None:\n",
        "                rank_q = rank_head\n",
        "            elif rank_channel is not None:\n",
        "                rank_q = rank_channel\n",
        "            else:\n",
        "                raise ValueError(\"rank_q is None and no rank_head/rank_channel provided.\")\n",
        "        if rank_k is None:\n",
        "            rank_k = rank_q\n",
        "        if rank_v is None:\n",
        "            rank_v = rank_q\n",
        "\n",
        "        self.rank_q = int(rank_q)\n",
        "        self.rank_k = int(rank_k)\n",
        "        self.rank_v = int(rank_v)\n",
        "\n",
        "        Rq, Rk, Rv = self.rank_q, self.rank_k, self.rank_v\n",
        "        H, Dh = self.num_heads, self.head_dim\n",
        "\n",
        "        # Stage1: 先走 CP / TPA\n",
        "        self.cp_only = True\n",
        "\n",
        "        # 缩放因子，和 TPAAttention 一致： /R\n",
        "        self.scale_q_tucker = 1.0 / float(Rq)\n",
        "        self.scale_k_tucker = 1.0 / float(Rk)\n",
        "        self.scale_v_tucker = 1.0 / float(Rv)\n",
        "\n",
        "        # ====== Q 分支 A/B/G ======\n",
        "        # 和 TPAAttention 完全相同的映射维度：\n",
        "        #   A: (B,N,R,H)  ← out_features = R*H\n",
        "        #   B: (B,N,R,Dh) ← out_features = R*Dh\n",
        "        self.q_A_proj = nn.Linear(dim, Rq * H,  bias=qkv_bias)\n",
        "        self.q_B_proj = nn.Linear(dim, Rq * Dh, bias=qkv_bias)\n",
        "        self.q_G_proj = nn.Linear(dim, Rq * Rq, bias=qkv_bias)\n",
        "\n",
        "        # ====== K 分支 ======\n",
        "        self.k_A_proj = nn.Linear(dim, Rk * H,  bias=qkv_bias)\n",
        "        self.k_B_proj = nn.Linear(dim, Rk * Dh, bias=qkv_bias)\n",
        "        self.k_G_proj = nn.Linear(dim, Rk * Rk, bias=qkv_bias)\n",
        "\n",
        "        # ====== V 分支 ======\n",
        "        self.v_A_proj = nn.Linear(dim, Rv * H,  bias=qkv_bias)\n",
        "        self.v_B_proj = nn.Linear(dim, Rv * Dh, bias=qkv_bias)\n",
        "        self.v_G_proj = nn.Linear(dim, Rv * Rv, bias=qkv_bias)\n",
        "\n",
        "        self.scale = qk_scale or (self.head_dim ** -0.5)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        \"\"\"\n",
        "        为了让 Stage1 尽量贴近 TPAAttention：\n",
        "          - A/B 使用 nn.Linear 的默认初始化（和 TPAAttention 一样）\n",
        "          - 只对 G 的线性层做特殊 init\n",
        "        \"\"\"\n",
        "        for m in [self.q_G_proj, self.k_G_proj, self.v_G_proj]:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "            # 初期减小 G 的影响（Stage2 用）\n",
        "            m.weight.data.mul_(0.1)\n",
        "\n",
        "    # ====== CP / TPA 分支：和 TPAAttention 完全同构 ======\n",
        "    @staticmethod\n",
        "    def _cp_from_factors(A, B, scale: float):\n",
        "        \"\"\"\n",
        "        A: (B, N, R, H)\n",
        "        B: (B, N, R, D_h)\n",
        "\n",
        "        Q[b,n,h,d] = (1/R) * Σ_r A[b,n,r,h] * B[b,n,r,d]\n",
        "        \"\"\"\n",
        "        Q = torch.einsum(\"bnrh,bnrd->bnhd\", A, B)  # (B,N,H,Dh)\n",
        "        Q = Q * scale\n",
        "        Q = Q.permute(0, 2, 1, 3).contiguous()     # (B,H,N,Dh)\n",
        "        return Q\n",
        "\n",
        "    # ====== Tucker 分支：A^T G B 版本（为了兼容 Stage1 的排布） ======\n",
        "    @staticmethod\n",
        "    def _tucker_from_factors(A, G, B, scale: float):\n",
        "        \"\"\"\n",
        "        A: (B, N, R, H)   对应 A(x) ∈ R^{R×H}\n",
        "        G: (B, N, R, R)\n",
        "        B: (B, N, R, D_h)\n",
        "\n",
        "        Q = A^T G B ∈ R^{H×D_h}\n",
        "        \"\"\"\n",
        "        # M = A^T G  → (B,N,H,R)\n",
        "        # M[b,n,h,q] = Σ_p A[b,n,p,h] * G[b,n,p,q]\n",
        "        M = torch.einsum(\"bnph,bnpq->bnhq\", A, G)\n",
        "\n",
        "        # Q = M B    → (B,N,H,Dh)\n",
        "        # Q[b,n,h,d] = Σ_q M[b,n,h,q] * B[b,n,q,d]\n",
        "        Q = torch.einsum(\"bnhq,bnqd->bnhd\", M, B)\n",
        "\n",
        "        Q = Q * scale\n",
        "        Q = Q.permute(0, 2, 1, 3).contiguous()  # (B,H,N,Dh)\n",
        "        return Q\n",
        "\n",
        "    def _make_qkv(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, N, C)\n",
        "        返回 q,k,v: (B, H, N, D_h)\n",
        "        \"\"\"\n",
        "        B, N, C = x.shape\n",
        "        H, Dh = self.num_heads, self.head_dim\n",
        "        Rq, Rk, Rv = self.rank_q, self.rank_k, self.rank_v\n",
        "\n",
        "        # ---- Q ----\n",
        "        qA = self.q_A_proj(x).view(B, N, Rq, H)   # (B,N,R,H)  ✅ 与 TPAAttention 对齐\n",
        "        qB = self.q_B_proj(x).view(B, N, Rq, Dh)  # (B,N,R,Dh)\n",
        "        if self.cp_only:\n",
        "            q = self._cp_from_factors(qA, qB, self.scale_q_tucker)\n",
        "        else:\n",
        "            qG = self.q_G_proj(x).view(B, N, Rq, Rq)\n",
        "            q = self._tucker_from_factors(qA, qG, qB, self.scale_q_tucker)\n",
        "\n",
        "        # ---- K ----\n",
        "        kA = self.k_A_proj(x).view(B, N, Rk, H)\n",
        "        kB = self.k_B_proj(x).view(B, N, Rk, Dh)\n",
        "        if self.cp_only:\n",
        "            k = self._cp_from_factors(kA, kB, self.scale_k_tucker)\n",
        "        else:\n",
        "            kG = self.k_G_proj(x).view(B, N, Rk, Rk)\n",
        "            k = self._tucker_from_factors(kA, kG, kB, self.scale_k_tucker)\n",
        "\n",
        "        # ---- V ----\n",
        "        vA = self.v_A_proj(x).view(B, N, Rv, H)\n",
        "        vB = self.v_B_proj(x).view(B, N, Rv, Dh)\n",
        "        if self.cp_only:\n",
        "            v = self._cp_from_factors(vA, vB, self.scale_v_tucker)\n",
        "        else:\n",
        "            vG = self.v_G_proj(x).view(B, N, Rv, Rv)\n",
        "            v = self._tucker_from_factors(vA, vG, vB, self.scale_v_tucker)\n",
        "\n",
        "        return q, k, v\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        B, N, C = x.shape\n",
        "        assert C == self.dim\n",
        "\n",
        "        q, k, v = self._make_qkv(x)  # (B,H,N,Dh)\n",
        "\n",
        "        attn = (q * self.scale) @ k.transpose(-2, -1)  # (B,H,N,N)\n",
        "        if attn_mask is not None:\n",
        "            attn = attn + attn_mask\n",
        "\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        out = attn @ v  # (B,H,N,Dh)\n",
        "        out = out.transpose(1, 2).reshape(B, N, C)\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# ===================== 工具函数：切换模式 / 控制参数训练 =====================\n",
        "\n",
        "def set_tucker_cp_mode(model: nn.Module, cp_only: bool):\n",
        "    \"\"\"\n",
        "    在整个 model 里，把所有 \n",
        "      的 cp_only 统一设置。\n",
        "\n",
        "    Phase 1（TPA 阶段）: cp_only = True\n",
        "    Phase 2（Tucker 阶段）: cp_only = False\n",
        "    \"\"\"\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, ContextualTuckerTPAAttention):\n",
        "            m.cp_only = cp_only\n",
        "\n",
        "\n",
        "def set_tucker_ab_requires_grad(model: nn.Module, requires_grad: bool):\n",
        "    \"\"\"\n",
        "    控制所有 Tucker 注意力里的 A/B 投影是否参与训练。\n",
        "    即：\n",
        "      - q_A_proj, q_B_proj\n",
        "      - k_A_proj, k_B_proj\n",
        "      - v_A_proj, v_B_proj\n",
        "    \"\"\"\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, ContextualTuckerTPAAttention):\n",
        "            for proj in [\n",
        "                m.q_A_proj, m.q_B_proj,\n",
        "                m.k_A_proj, m.k_B_proj,\n",
        "                m.v_A_proj, m.v_B_proj,\n",
        "            ]:\n",
        "                for p in proj.parameters():\n",
        "                    p.requires_grad = requires_grad\n",
        "\n",
        "\n",
        "def set_tucker_core_requires_grad(model: nn.Module, requires_grad: bool):\n",
        "    \"\"\"\n",
        "    控制所有 Tucker 注意力里的 G 部分是否参与训练：\n",
        "      - q_G_proj, k_G_proj, v_G_proj\n",
        "    \"\"\"\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, ContextualTuckerTPAAttention):\n",
        "            for proj in [m.q_G_proj, m.k_G_proj, m.v_G_proj]:\n",
        "                for p in proj.parameters():\n",
        "                    p.requires_grad = requires_grad\n",
        "\n",
        "\n",
        "def init_tucker_core_as_identity(model: nn.Module):\n",
        "    \"\"\"\n",
        "    在「Tucker 阶段开始」时调用：\n",
        "      把所有 G 的线性映射初始化成恒等核 I：\n",
        "\n",
        "        G_Q(x) ≡ I_{R_q},  G_K(x) ≡ I_{R_k},  G_V(x) ≡ I_{R_v}\n",
        "\n",
        "    实现方式：\n",
        "      - 把 q_G_proj / k_G_proj / v_G_proj 的 weight 置 0\n",
        "      - 把 bias 置成 vec(I_R)\n",
        "      这样对任何 x 都有 G(x)=I，从而保证：\n",
        "\n",
        "        A(x) G(x) B(x)^T = A(x) B(x)^T\n",
        "\n",
        "      => Phase2 初始时，函数形式与 Phase1 完全一致（真·等价 TPA）。\n",
        "    \"\"\"\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, ContextualTuckerTPAAttention):\n",
        "            with torch.no_grad():\n",
        "                for proj, R in [\n",
        "                    (m.q_G_proj, m.rank_q),\n",
        "                    (m.k_G_proj, m.rank_k),\n",
        "                    (m.v_G_proj, m.rank_v),\n",
        "                ]:\n",
        "                    if proj is None:\n",
        "                        continue\n",
        "\n",
        "                    # W = 0\n",
        "                    proj.weight.zero_()\n",
        "\n",
        "                    # 偏置存在则置 0，然后写成 vec(I)\n",
        "                    if proj.bias is not None:\n",
        "                        proj.bias.zero_()\n",
        "                        eye = torch.eye(R, device=proj.weight.device, dtype=proj.weight.dtype)\n",
        "                        proj.bias.copy_(eye.reshape(-1))\n",
        "\n",
        "\n",
        "# ===================== 两阶段训练函数 =====================\n",
        "\n",
        "def train_model_two_stage_tucker(\n",
        "    model: nn.Module,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    device,\n",
        "    total_epochs: int,\n",
        "    ab_epochs: int = 40,   # 第一阶段：只训 A/B（CP/TPA）\n",
        "    scaler=None,\n",
        "    is_tucker_model: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    通用 train 函数：\n",
        "\n",
        "      - 对 MHA / 纯 TPA model：is_tucker_model=False\n",
        "            → 普通训练 total_epochs 轮。\n",
        "\n",
        "      - 对 Tucker-TPA：is_tucker_model=True\n",
        "            → 两阶段：\n",
        "                * epoch < ab_epochs:\n",
        "                    cp_only = True\n",
        "                    A/B 可训练，G 不训练   （函数族 = TPA）\n",
        "                * epoch == ab_epochs:\n",
        "                    切换到 Tucker：\n",
        "                      - cp_only = False\n",
        "                      - 重置 G 为恒等核 I\n",
        "                      - 冻结 A/B，只训 G\n",
        "                * epoch > ab_epochs:\n",
        "                    继续 Tucker 阶段\n",
        "    \"\"\"\n",
        "    train_loss_curve = []\n",
        "    val_loss_curve   = []\n",
        "    train_acc_curve  = []\n",
        "    val_acc_curve    = []\n",
        "    best_val_acc     = 0.0\n",
        "\n",
        "    for epoch in range(total_epochs):\n",
        "\n",
        "        # ====== 阶段切换逻辑 ======\n",
        "        if is_tucker_model:\n",
        "            if epoch < ab_epochs:\n",
        "                # Phase 1: CP/TPA —— 训 A/B，G 不参与训练\n",
        "                set_tucker_cp_mode(model, cp_only=True)\n",
        "                set_tucker_ab_requires_grad(model, True)\n",
        "                set_tucker_core_requires_grad(model, False)\n",
        "                phase_tag = \"TPA-phase(AB)\"\n",
        "\n",
        "            elif epoch == ab_epochs:\n",
        "                # Phase 2 开始：把 G 初始化为 I，切换到 Tucker 形式，只训 G\n",
        "                set_tucker_cp_mode(model, cp_only=False)\n",
        "                set_tucker_ab_requires_grad(model, False)\n",
        "                set_tucker_core_requires_grad(model, True)\n",
        "                init_tucker_core_as_identity(model)\n",
        "                phase_tag = \"Tucker-phase(G, init=I)\"\n",
        "\n",
        "            else:\n",
        "                # Phase 2 后续：继续 Tucker，只训 G\n",
        "                set_tucker_cp_mode(model, cp_only=False)\n",
        "                set_tucker_ab_requires_grad(model, False)\n",
        "                set_tucker_core_requires_grad(model, True)\n",
        "                phase_tag = \"Tucker-phase(G)\"\n",
        "        else:\n",
        "            # 非 Tucker 模型：普通训练\n",
        "            phase_tag = \"normal\"\n",
        "\n",
        "        # ====== 一轮训练 & 验证 ======\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, device, epoch, total_epochs, scaler\n",
        "        )\n",
        "        val_loss, val_acc = eval_one_epoch(\n",
        "            model, val_loader, criterion, device, epoch, total_epochs\n",
        "        )\n",
        "\n",
        "        train_loss_curve.append(train_loss)\n",
        "        val_loss_curve.append(val_loss)\n",
        "        train_acc_curve.append(train_acc)\n",
        "        val_acc_curve.append(val_acc)\n",
        "        best_val_acc = max(best_val_acc, val_acc)\n",
        "\n",
        "        print(\n",
        "            f\"[Epoch {epoch+1}/{total_epochs} | phase={phase_tag}] \"\n",
        "            f\"train loss: {train_loss:.4f}, train acc: {train_acc:.3f} | \"\n",
        "            f\"val loss: {val_loss:.4f}, val acc: {val_acc:.3f}\"\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"train_loss_curve\": train_loss_curve,\n",
        "        \"val_loss_curve\": val_loss_curve,\n",
        "        \"train_acc_curve\": train_acc_curve,\n",
        "        \"val_acc_curve\": val_acc_curve,\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "    }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_tucker_cp_mode(model: nn.Module, cp_only: bool):\n",
        "    \"\"\"\n",
        "    在整个 model 里，把所有 ContextualTuckerTPAAttention 的 cp_only 统一设置。\n",
        "\n",
        "    Phase 1（TPA 阶段）: cp_only = True\n",
        "    Phase 2（Tucker 阶段）: cp_only = False\n",
        "    \"\"\"\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, ContextualTuckerTPAAttention):\n",
        "            m.cp_only = cp_only\n",
        "\n",
        "\n",
        "def set_tucker_ab_requires_grad(model: nn.Module, requires_grad: bool):\n",
        "    \"\"\"\n",
        "    控制所有 Tucker 注意力里的 A/B 投影是否参与训练：\n",
        "      - q_A_proj, q_B_proj\n",
        "      - k_A_proj, k_B_proj\n",
        "      - v_A_proj, v_B_proj\n",
        "    \"\"\"\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, ContextualTuckerTPAAttention):\n",
        "            for proj in [\n",
        "                m.q_A_proj, m.q_B_proj,\n",
        "                m.k_A_proj, m.k_B_proj,\n",
        "                m.v_A_proj, m.v_B_proj,\n",
        "            ]:\n",
        "                for p in proj.parameters():\n",
        "                    p.requires_grad = requires_grad\n",
        "\n",
        "\n",
        "def set_tucker_core_requires_grad(model: nn.Module, requires_grad: bool):\n",
        "    \"\"\"\n",
        "    控制所有 Tucker 注意力里的 G 部分是否参与训练：\n",
        "      - q_G_proj, k_G_proj, v_G_proj\n",
        "    \"\"\"\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, ContextualTuckerTPAAttention):\n",
        "            for proj in [m.q_G_proj, m.k_G_proj, m.v_G_proj]:\n",
        "                for p in proj.parameters():\n",
        "                    p.requires_grad = requires_grad\n",
        "\n",
        "\n",
        "def init_tucker_core_as_identity(model: nn.Module):\n",
        "    \"\"\"\n",
        "    在「Tucker 第二阶段开始」时调用：\n",
        "      把所有 G 的线性映射初始化成恒等核 I：\n",
        "\n",
        "        G_Q(x) ≡ I_{R_q},  G_K(x) ≡ I_{R_k},  G_V(x) ≡ I_{R_v}\n",
        "\n",
        "    做法：\n",
        "      - weight 全 0\n",
        "      - bias 写成 vec(I_R)\n",
        "    这样对任何 x 都有 G(x)=I，从而保证：\n",
        "        A(x)^T G(x) B(x) = A(x)^T B(x)\n",
        "      → 第二阶段一开始与第一阶段前向完全等价。\n",
        "    \"\"\"\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, ContextualTuckerTPAAttention):\n",
        "            with torch.no_grad():\n",
        "                for proj, R in [\n",
        "                    (m.q_G_proj, m.rank_q),\n",
        "                    (m.k_G_proj, m.rank_k),\n",
        "                    (m.v_G_proj, m.rank_v),\n",
        "                ]:\n",
        "                    if proj is None:\n",
        "                        continue\n",
        "\n",
        "                    # W = 0\n",
        "                    proj.weight.zero_()\n",
        "\n",
        "                    if proj.bias is not None:\n",
        "                        proj.bias.zero_()\n",
        "                        eye = torch.eye(\n",
        "                            R,\n",
        "                            device=proj.weight.device,\n",
        "                            dtype=proj.weight.dtype,\n",
        "                        )\n",
        "                        proj.bias.copy_(eye.reshape(-1))  # vec(I_R)\n",
        "\n",
        "def train_model_two_stage_tucker(\n",
        "    model: nn.Module,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    device,\n",
        "    total_epochs: int,\n",
        "    ab_epochs: int = 40,   # 第一阶段：只训 A/B（CP/TPA）\n",
        "    scaler=None,\n",
        "    is_tucker_model: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    通用两阶段训练函数：\n",
        "\n",
        "      - 对非 Tucker 模型（例如普通 MHA / 纯 TPA）：\n",
        "            is_tucker_model = False\n",
        "        → 完全等同于单阶段训练，跑 total_epochs 轮。\n",
        "\n",
        "      - 对使用 ContextualTuckerTPAAttention 的模型：\n",
        "            is_tucker_model = True\n",
        "        → 两阶段：\n",
        "            * epoch < ab_epochs:\n",
        "                - cp_only = True      （纯 TPA / CP）\n",
        "                - A/B 可训练\n",
        "                - G 不训练\n",
        "            * epoch == ab_epochs:\n",
        "                - cp_only = False     （切换到 Tucker）\n",
        "                - 初始化 G(x) ≡ I     （前向与上个 epoch 完全等价）\n",
        "                - 冻结 A/B，只训 G\n",
        "            * epoch > ab_epochs:\n",
        "                - cp_only = False\n",
        "                - A/B 仍冻结\n",
        "                - 继续只训 G\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    train_loss_curve = []\n",
        "    val_loss_curve   = []\n",
        "    train_acc_curve  = []\n",
        "    val_acc_curve    = []\n",
        "    best_val_acc     = 0.0\n",
        "\n",
        "    for epoch in range(total_epochs):\n",
        "\n",
        "        # ================== 阶段切换逻辑 ==================\n",
        "        if is_tucker_model:\n",
        "            if epoch < ab_epochs:\n",
        "                # Phase 1: TPA / CP —— 训 A/B，G 不参与训练\n",
        "                set_tucker_cp_mode(model, cp_only=True)\n",
        "                set_tucker_ab_requires_grad(model, True)\n",
        "                set_tucker_core_requires_grad(model, False)\n",
        "                phase_tag = \"TPA-phase(AB)\"\n",
        "\n",
        "            elif epoch == ab_epochs:\n",
        "                # Phase 2 刚开始：切到 Tucker（A^T G B）\n",
        "                #   - cp_only=False\n",
        "                #   - G 初始化为恒等核 I\n",
        "                #   - 冻结 A/B，只训 G\n",
        "                set_tucker_cp_mode(model, cp_only=False)\n",
        "                init_tucker_core_as_identity(model)\n",
        "                set_tucker_ab_requires_grad(model, False)\n",
        "                set_tucker_core_requires_grad(model, True)\n",
        "                phase_tag = \"Tucker-phase(G, init=I)\"\n",
        "\n",
        "            else:\n",
        "                # Phase 2 后续：继续 Tucker，只训 G\n",
        "                set_tucker_cp_mode(model, cp_only=False)\n",
        "                set_tucker_ab_requires_grad(model, False)\n",
        "                set_tucker_core_requires_grad(model, True)\n",
        "                phase_tag = \"Tucker-phase(G)\"\n",
        "        else:\n",
        "            phase_tag = \"normal\"\n",
        "\n",
        "        # ================== 一轮训练 + 验证 ==================\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model=model,\n",
        "            loader=train_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "            scaler=scaler,\n",
        "        )\n",
        "\n",
        "        val_loss, val_acc = eval_one_epoch(\n",
        "            model=model,\n",
        "            loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            epochs=total_epochs,\n",
        "        )\n",
        "\n",
        "        train_loss_curve.append(train_loss)\n",
        "        val_loss_curve.append(val_loss)\n",
        "        train_acc_curve.append(train_acc)\n",
        "        val_acc_curve.append(val_acc)\n",
        "        best_val_acc = max(best_val_acc, val_acc)\n",
        "\n",
        "        print(\n",
        "            f\"[Epoch {epoch+1}/{total_epochs} | phase={phase_tag}] \"\n",
        "            f\"train loss: {train_loss:.4f}, train acc: {train_acc:.3f} | \"\n",
        "            f\"val loss: {val_loss:.4f}, val acc: {val_acc:.3f}\"\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"train_loss_curve\": train_loss_curve,\n",
        "        \"val_loss_curve\":   val_loss_curve,\n",
        "        \"train_acc_curve\":  train_acc_curve,\n",
        "        \"val_acc_curve\":    val_acc_curve,\n",
        "        \"best_val_acc\":     best_val_acc,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "roALAmqitH8c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class StaticCoreTuckerTPAAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Tucker-style Tensor Product Attention with:\n",
        "      - token-dependent A_t(x), B_t(x)\n",
        "      - *static* global cores G_q, G_k, G_v (non-contextual)\n",
        "\n",
        "    对每个 token t:\n",
        "        Q_t = A_t(x) · G_q_eff · B_t(x)^T\n",
        "\n",
        "    其中 G_q_eff 可以通过 tucker_lambda 在 diag(G) 和 full(G) 之间渐进过渡：\n",
        "        G_eff = λ * diag(G_raw) + (1-λ) * G_raw\n",
        "      - λ = 1 → CP/TPA 风格 (只用 diag)\n",
        "      - λ = 0 → full Tucker\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        num_heads: int = 8,\n",
        "        rank_head: int = 2,     # R_h\n",
        "        rank_channel: int = 4,  # R_d\n",
        "        qkv_bias: bool = True,\n",
        "        qk_scale: float = None,\n",
        "        attn_drop: float = 0.0,\n",
        "        proj_drop: float = 0.0,\n",
        "        progressive_g: bool = True,\n",
        "        init_lambda: float = 1.0,   # 默认一开始 λ=1：CP/TPA 模式\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0, \"dim must be divisible by num_heads\"\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "\n",
        "        self.rank_head = rank_head\n",
        "        self.rank_channel = rank_channel\n",
        "\n",
        "        Rh, Rd = rank_head, rank_channel\n",
        "        H, Dh = num_heads, self.head_dim\n",
        "\n",
        "        # λ ∈ [0,1] : 1 → diag, 0 → full\n",
        "        self.progressive_g = progressive_g\n",
        "        self.tucker_lambda = float(init_lambda)\n",
        "\n",
        "        # Tucker 输出缩放，防止 Q/K 范数随 rank 爆炸\n",
        "        self.tucker_scale = 1.0 / math.sqrt(rank_head * rank_channel)\n",
        "\n",
        "        # ---- Q 的 A/B (token-dependent) ----\n",
        "        self.q_A_proj = nn.Linear(dim, H * Rh, bias=qkv_bias)   # (B,N,H,Rh)\n",
        "        self.q_B_proj = nn.Linear(dim, Dh * Rd, bias=qkv_bias)  # (B,N,Dh,Rd)\n",
        "        # ---- Q 的 static core G_q ----\n",
        "        self.G_q = nn.Parameter(torch.randn(Rh, Rd) * 0.02)\n",
        "\n",
        "        # ---- K 的 A/B + static core G_k ----\n",
        "        self.k_A_proj = nn.Linear(dim, H * Rh, bias=qkv_bias)\n",
        "        self.k_B_proj = nn.Linear(dim, Dh * Rd, bias=qkv_bias)\n",
        "        self.G_k = nn.Parameter(torch.randn(Rh, Rd) * 0.02)\n",
        "\n",
        "        # ---- V 的 A/B + static core G_v ----\n",
        "        self.v_A_proj = nn.Linear(dim, H * Rh, bias=qkv_bias)\n",
        "        self.v_B_proj = nn.Linear(dim, Dh * Rd, bias=qkv_bias)\n",
        "        self.G_v = nn.Parameter(torch.randn(Rh, Rd) * 0.02)\n",
        "\n",
        "        # 标准 attention 组件\n",
        "        self.scale = qk_scale or (self.head_dim ** -0.5)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        # A/B 全部 xavier，bias 置 0\n",
        "        for m in [\n",
        "            self.q_A_proj, self.q_B_proj,\n",
        "            self.k_A_proj, self.k_B_proj,\n",
        "            self.v_A_proj, self.v_B_proj,\n",
        "        ]:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "        # static G 用较小 init，避免一开始爆\n",
        "        for G in [self.G_q, self.G_k, self.G_v]:\n",
        "            nn.init.xavier_uniform_(G)\n",
        "            G.data.mul_(0.1)\n",
        "\n",
        "    # ========== 关键：对 static G 做 λ 控制 ==========\n",
        "\n",
        "    def _core_with_lambda(self, G_raw: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        G_raw: (R_h, R_d)\n",
        "\n",
        "        返回 G_eff:\n",
        "          - 如果 progressive_g=False 或 lambda<=0: 返回 full G\n",
        "          - 如果 lambda>=1: 只保留 diag(G_raw)\n",
        "          - 否则: λ*diag(G_raw) + (1-λ)*G_raw\n",
        "        \"\"\"\n",
        "        if (not self.progressive_g) or self.tucker_lambda <= 0.0:\n",
        "            return G_raw\n",
        "\n",
        "        lam = float(self.tucker_lambda)\n",
        "        lam = max(0.0, min(1.0, lam))\n",
        "        if lam == 0.0:\n",
        "            return G_raw\n",
        "\n",
        "        Rh, Rd = G_raw.shape\n",
        "        k = min(Rh, Rd)\n",
        "\n",
        "        diag_matrix = torch.zeros_like(G_raw)\n",
        "        idx = torch.arange(k, device=G_raw.device)\n",
        "        diag_matrix[idx, idx] = G_raw[idx, idx]\n",
        "\n",
        "        G_eff = lam * diag_matrix + (1.0 - lam) * G_raw\n",
        "        return G_eff\n",
        "\n",
        "    @staticmethod\n",
        "    def _tucker_from_factors(A, G, B, scale: float):\n",
        "        \"\"\"\n",
        "        A: (B, N, H, R_h)\n",
        "        G: (R_h, R_d)      or broadcasted to (B,N,R_h,R_d)\n",
        "        B: (B, N, D_h, R_d)\n",
        "\n",
        "        return:\n",
        "          out: (B, H, N, D_h)\n",
        "        \"\"\"\n",
        "        Bsz, N, H, Rh = A.shape\n",
        "        _, _, Dh, Rd = B.shape\n",
        "\n",
        "        if G.dim() == 2:\n",
        "            # (Rh,Rd) -> (1,1,Rh,Rd) -> (B,N,Rh,Rd)\n",
        "            Gb = G.view(1, 1, Rh, Rd).expand(Bsz, N, Rh, Rd)\n",
        "        else:\n",
        "            Gb = G  # 已经是 (B,N,Rh,Rd)\n",
        "\n",
        "        # (B,N,H,R_h) × (B,N,R_h,R_d) -> (B,N,H,R_d)\n",
        "        T = torch.einsum(\"bnhp,bnpq->bnhq\", A, Gb)\n",
        "        # (B,N,H,R_d) × (B,N,D_h,R_d) -> (B,N,H,D_h)\n",
        "        Q = torch.einsum(\"bnhq,bndq->bnhd\", T, B)\n",
        "        Q = Q * scale\n",
        "        Q = Q.permute(0, 2, 1, 3).contiguous()  # (B,H,N,D_h)\n",
        "        return Q\n",
        "\n",
        "    def _make_qkv(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, N, C)\n",
        "        return q, k, v: (B, H, N, D_h)\n",
        "        \"\"\"\n",
        "        Bsz, N, C = x.shape\n",
        "        H, Dh = self.num_heads, self.head_dim\n",
        "        Rh, Rd = self.rank_head, self.rank_channel\n",
        "\n",
        "        # ========= Q =========\n",
        "        qA = self.q_A_proj(x).view(Bsz, N, H, Rh)\n",
        "        qB = self.q_B_proj(x).view(Bsz, N, Dh, Rd)\n",
        "        Gq_eff = self._core_with_lambda(self.G_q)  # (Rh,Rd)\n",
        "        q = self._tucker_from_factors(qA, Gq_eff, qB, self.tucker_scale)\n",
        "\n",
        "        # ========= K =========\n",
        "        kA = self.k_A_proj(x).view(Bsz, N, H, Rh)\n",
        "        kB = self.k_B_proj(x).view(Bsz, N, Dh, Rd)\n",
        "        Gk_eff = self._core_with_lambda(self.G_k)\n",
        "        k = self._tucker_from_factors(kA, Gk_eff, kB, self.tucker_scale)\n",
        "\n",
        "        # ========= V =========\n",
        "        vA = self.v_A_proj(x).view(Bsz, N, H, Rh)\n",
        "        vB = self.v_B_proj(x).view(Bsz, N, Dh, Rd)\n",
        "        Gv_eff = self._core_with_lambda(self.G_v)\n",
        "        v = self._tucker_from_factors(vA, Gv_eff, vB, self.tucker_scale)\n",
        "\n",
        "        return q, k, v\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        Bsz, N, C = x.shape\n",
        "        assert C == self.dim, f\"[StaticCoreTuckerTPAAttention] expected dim={self.dim}, got {C}\"\n",
        "\n",
        "        q, k, v = self._make_qkv(x)  # (B, H, N, D_h)\n",
        "\n",
        "        attn = (q * self.scale) @ k.transpose(-2, -1)  # (B, H, N, N)\n",
        "        if attn_mask is not None:\n",
        "            attn = attn + attn_mask\n",
        "\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        out = attn @ v  # (B,H,N,D_h)\n",
        "        out = out.transpose(1, 2).reshape(Bsz, N, C)\n",
        "\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eavkASF5rDAv"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FocusContextualTPAAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    full + low-rank (TPA) 双分支注意力 + 空间 gate：\n",
        "    - full 分支：正常 MHA\n",
        "    - low-rank 分支：True TPA（两个向量的 outer product）：\n",
        "        Q_t = (1/R) * sum_r a_r(x_t) ⊗ b_r(x_t)\n",
        "      并支持两种 ablation：\n",
        "        * contextA = True : contextual A, non-contextual B\n",
        "        * contextA = False: non-contextual A, contextual B\n",
        "    - gate: 用 full 分支的 attention + 2D 空间权重，决定每个 token\n",
        "            更偏 full 还是偏 low-rank\n",
        "    同时维护 alpha 的 running mean，方便估算 KV cache。\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        num_heads=8,\n",
        "        rank=16,\n",
        "        qkv_bias=True,\n",
        "        qk_scale=None,\n",
        "        attn_drop=0.0,\n",
        "        proj_drop=0.0,\n",
        "        grid_size=(14, 14),  # ViT tiny: (224,16) -> (14,14)\n",
        "        gamma=1.0,           # 空间邻域加权强度\n",
        "        sigma=None,          # 高斯宽度\n",
        "        gate_scale=1.0,      # s_norm 放大多少再过 sigmoid\n",
        "        contextA=True,       # True: contextual A, False: contextual B\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0, \"dim 必须能整除 num_heads\"\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.rank = rank\n",
        "        self.contextA = contextA\n",
        "\n",
        "        self.scale = qk_scale or self.head_dim ** -0.5\n",
        "\n",
        "        # ===== full 分支：标准 qkv =====\n",
        "        self.qkv_full = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "\n",
        "        # ===== low-rank 分支：True TPA（两向量 outer product）=====\n",
        "        H = self.num_heads\n",
        "        Dh = self.head_dim\n",
        "        R = self.rank\n",
        "\n",
        "        if self.contextA:\n",
        "            # ------- contextual A(x), non-contextual B -------\n",
        "            # A_q/A_k/A_v(x): (B,N,R*H) -> (B,N,R,H)\n",
        "            self.A_q = nn.Linear(dim, R * H, bias=qkv_bias)\n",
        "            self.A_k = nn.Linear(dim, R * H, bias=qkv_bias)\n",
        "            self.A_v = nn.Linear(dim, R * H, bias=qkv_bias)\n",
        "\n",
        "            # B_q/B_k/B_v: (R,D_h) 全局参数（non-contextual）\n",
        "            self.B_q = nn.Parameter(torch.empty(R, Dh))\n",
        "            self.B_k = nn.Parameter(torch.empty(R, Dh))\n",
        "            self.B_v = nn.Parameter(torch.empty(R, Dh))\n",
        "\n",
        "            nn.init.xavier_uniform_(self.B_q)\n",
        "            nn.init.xavier_uniform_(self.B_k)\n",
        "            nn.init.xavier_uniform_(self.B_v)\n",
        "\n",
        "        else:\n",
        "            # ------- non-contextual A, contextual B(x) -------\n",
        "            # A_q/A_k/A_v: (R,H) 全局参数\n",
        "            self.A_q = nn.Parameter(torch.empty(R, H))\n",
        "            self.A_k = nn.Parameter(torch.empty(R, H))\n",
        "            self.A_v = nn.Parameter(torch.empty(R, H))\n",
        "\n",
        "            nn.init.xavier_uniform_(self.A_q)\n",
        "            nn.init.xavier_uniform_(self.A_k)\n",
        "            nn.init.xavier_uniform_(self.A_v)\n",
        "\n",
        "            # B_q/B_k/B_v(x): (B,N,R*D_h) -> (B,N,R,D_h)\n",
        "            self.B_q = nn.Linear(dim, R * Dh, bias=qkv_bias)\n",
        "            self.B_k = nn.Linear(dim, R * Dh, bias=qkv_bias)\n",
        "            self.B_v = nn.Linear(dim, R * Dh, bias=qkv_bias)\n",
        "\n",
        "        # 输出投影（和原来一样）\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "        # ===== 空间 gate（保持原样） =====\n",
        "        self.grid_size = grid_size\n",
        "        Hp, Wp = grid_size\n",
        "        num_patches = Hp * Wp\n",
        "        self.num_patches = num_patches\n",
        "        self.gamma = gamma\n",
        "        self.gate_scale = gate_scale\n",
        "\n",
        "        # 预计算 2D 距离矩阵 -> 空间权重 w_ij\n",
        "        coords = []\n",
        "        for y in range(Hp):\n",
        "            for x in range(Wp):\n",
        "                coords.append((x, y))\n",
        "        coords = torch.tensor(coords, dtype=torch.float32)  # (P,2)\n",
        "        dists = torch.cdist(coords, coords, p=2)            # (P,P)\n",
        "\n",
        "        if sigma is None:\n",
        "            sigma = max(Hp, Wp) / 2.0\n",
        "\n",
        "        w = 1.0 + gamma * torch.exp(- (dists ** 2) / (2 * sigma ** 2))  # (P,P)\n",
        "        self.register_buffer(\"spatial_weight\", w)\n",
        "\n",
        "        self.eps = 1e-6\n",
        "        self.last_alpha = None\n",
        "\n",
        "        # 统计 alpha 的 running mean（用来估算 KV cache）\n",
        "        self.register_buffer(\"alpha_running_sum\", torch.zeros(1))\n",
        "        self.register_buffer(\"alpha_count\", torch.zeros(1))\n",
        "\n",
        "    # === low-rank 分支：构造 Q/K/V（True TPA） ===\n",
        "    def _low_rank_qkv(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, N, C)\n",
        "        return q, k, v: (B, H, N, D_h)\n",
        "        \"\"\"\n",
        "        B, N, C = x.shape\n",
        "        H, Dh, R = self.num_heads, self.head_dim, self.rank\n",
        "\n",
        "        if self.contextA:\n",
        "            # ---------- contextual A(x) , non-contextual B ----------\n",
        "            # A(x): (B,N,R,H)\n",
        "            Aq = self.A_q(x).view(B, N, R, H)\n",
        "            Ak = self.A_k(x).view(B, N, R, H)\n",
        "            Av = self.A_v(x).view(B, N, R, H)\n",
        "\n",
        "            # B: (R,D_h)\n",
        "            Bq = self.B_q               # (R,D_h)\n",
        "            Bk = self.B_k\n",
        "            Bv = self.B_v\n",
        "\n",
        "            # Q/K/V: (B,N,H,D_h) = (1/R) * sum_r a_r ⊗ b_r\n",
        "            q = torch.einsum(\"bnrh,rd->bnhd\", Aq, Bq) / float(R)\n",
        "            k = torch.einsum(\"bnrh,rd->bnhd\", Ak, Bk) / float(R)\n",
        "            v = torch.einsum(\"bnrh,rd->bnhd\", Av, Bv) / float(R)\n",
        "\n",
        "        else:\n",
        "            # ---------- non-contextual A , contextual B(x) ----------\n",
        "            # A: (R,H)\n",
        "            Aq = self.A_q              # (R,H)\n",
        "            Ak = self.A_k\n",
        "            Av = self.A_v\n",
        "\n",
        "            # B(x): (B,N,R,D_h)\n",
        "            Bq = self.B_q(x).view(B, N, R, Dh)\n",
        "            Bk = self.B_k(x).view(B, N, R, Dh)\n",
        "            Bv = self.B_v(x).view(B, N, R, Dh)\n",
        "\n",
        "            # Q/K/V: (B,N,H,D_h) = (1/R) * sum_r a_r ⊗ b_r\n",
        "            q = torch.einsum(\"rh,bnrd->bnhd\", Aq, Bq) / float(R)\n",
        "            k = torch.einsum(\"rh,bnrd->bnhd\", Ak, Bk) / float(R)\n",
        "            v = torch.einsum(\"rh,bnrd->bnhd\", Av, Bv) / float(R)\n",
        "\n",
        "        # 变成 (B,H,N,D_h)\n",
        "        q = q.permute(0, 2, 1, 3)\n",
        "        k = k.permute(0, 2, 1, 3)\n",
        "        v = v.permute(0, 2, 1, 3)\n",
        "        return q, k, v\n",
        "\n",
        "    # === 从 full attention + 2D 位置 得到 gate alpha（保持原样） ===\n",
        "    def _compute_gate(self, attn_full, gate_strength=1.0):\n",
        "        \"\"\"\n",
        "        attn_full: (B, H, N, N)，已经 softmax\n",
        "        return alpha_final: (B, N, 1)\n",
        "        \"\"\"\n",
        "        B, H, N, _ = attn_full.shape\n",
        "\n",
        "        # 对 head 平均: (B,N,N)\n",
        "        attn_mean = attn_full.mean(dim=1)\n",
        "\n",
        "        # u[b,i] = sum_j attn[j,i]  (被多少 token 看)\n",
        "        u = attn_mean.sum(dim=1)  # (B,N)\n",
        "\n",
        "        if N == self.num_patches + 1:\n",
        "            has_cls = True\n",
        "            u_cls = u[:, :1]\n",
        "            u_patch = u[:, 1:]\n",
        "        elif N == self.num_patches:\n",
        "            has_cls = False\n",
        "            u_patch = u\n",
        "            u_cls = None\n",
        "        else:\n",
        "            # 防御式：假定前面有一些非 patch token\n",
        "            has_cls = True\n",
        "            extra = N - self.num_patches\n",
        "            u_cls = u[:, :extra]\n",
        "            u_patch = u[:, extra:]\n",
        "\n",
        "        # 空间加权: s = u_patch @ W^T\n",
        "        s_patch = torch.matmul(u_patch, self.spatial_weight.t())  # (B,P)\n",
        "\n",
        "        mean = s_patch.mean(dim=-1, keepdim=True)\n",
        "        std = s_patch.std(dim=-1, keepdim=True) + self.eps\n",
        "        s_norm = (s_patch - mean) / std\n",
        "\n",
        "        alpha_patch = torch.sigmoid(self.gate_scale * s_norm)  # (B,P)\n",
        "\n",
        "        if has_cls:\n",
        "            alpha_full = torch.ones(\n",
        "                B, self.num_patches + 1, 1,\n",
        "                device=attn_full.device,\n",
        "                dtype=attn_full.dtype,\n",
        "            )\n",
        "            alpha_full[:, 0, 0] = 1.0  # cls 全 full\n",
        "            alpha_full[:, 1:, 0] = alpha_patch\n",
        "        else:\n",
        "            alpha_full = alpha_patch.unsqueeze(-1)  # (B,P,1)\n",
        "\n",
        "        # gate_strength: 0 -> 全部 1, 1 -> 用 alpha_full\n",
        "        if gate_strength < 1.0:\n",
        "            alpha_final = 1.0 - gate_strength * (1.0 - alpha_full)\n",
        "        else:\n",
        "            alpha_final = alpha_full\n",
        "\n",
        "        self.last_alpha = alpha_final.detach()\n",
        "\n",
        "        # 更新 running mean\n",
        "        self.alpha_running_sum += alpha_final.detach().sum()\n",
        "        self.alpha_count += torch.tensor(\n",
        "            alpha_final.numel(),\n",
        "            device=alpha_final.device,\n",
        "            dtype=self.alpha_running_sum.dtype,\n",
        "        )\n",
        "\n",
        "        return alpha_final  # (B,N,1)\n",
        "\n",
        "    def reset_alpha_stats(self):\n",
        "        self.alpha_running_sum.zero_()\n",
        "        self.alpha_count.zero_()\n",
        "\n",
        "    def get_mean_alpha(self):\n",
        "        if self.alpha_count.item() <= 0:\n",
        "            return None\n",
        "        return (self.alpha_running_sum / self.alpha_count).item()\n",
        "\n",
        "    def forward(self, x, attn_mask=None, gate_strength=1.0):\n",
        "        B, N, C = x.shape\n",
        "\n",
        "        # ===== full 分支 =====\n",
        "        qkv = self.qkv_full(x).reshape(B, N, 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)  # (3,B,H,N,D)\n",
        "        q_full, k_full, v_full = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        attn_scores_full = (q_full * self.scale) @ k_full.transpose(-2, -1)\n",
        "        if attn_mask is not None:\n",
        "            attn_scores_full = attn_scores_full + attn_mask\n",
        "        attn_full = attn_scores_full.softmax(dim=-1)\n",
        "        attn_full = self.attn_drop(attn_full)\n",
        "\n",
        "        # gate\n",
        "        alpha = self._compute_gate(attn_full, gate_strength=gate_strength)  # (B,N,1)\n",
        "\n",
        "        out_full = attn_full @ v_full  # (B,H,N,D)\n",
        "        out_full = out_full.transpose(1, 2).reshape(B, N, C)  # (B,N,C)\n",
        "\n",
        "        # ===== low-rank 分支（True TPA）=====\n",
        "        q_low, k_low, v_low = self._low_rank_qkv(x)\n",
        "        attn_scores_low = (q_low * self.scale) @ k_low.transpose(-2, -1)\n",
        "        if attn_mask is not None:\n",
        "            attn_scores_low = attn_scores_low + attn_mask\n",
        "        attn_low = attn_scores_low.softmax(dim=-1)\n",
        "        attn_low = self.attn_drop(attn_low)\n",
        "\n",
        "        out_low = attn_low @ v_low\n",
        "        out_low = out_low.transpose(1, 2).reshape(B, N, C)\n",
        "\n",
        "        # ===== gate 混合 =====\n",
        "        if gate_strength <= 0.0:\n",
        "            out = out_full\n",
        "        else:\n",
        "            out = alpha * out_full + (1.0 - alpha) * out_low\n",
        "\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "T3skkF6IdpDR"
      },
      "outputs": [],
      "source": [
        "# B 也 contextual 的 Focus-TPA（A、B 都是 contextual，两向量 outer product 版本）\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "class FocusTPAAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    full + low-rank (TPA) 双分支注意力 + 空间 gate：\n",
        "    - full 分支：正常 MHA\n",
        "    - low-rank 分支：True TPA（两个向量的 outer product）：\n",
        "        对每个 token t:\n",
        "          A_Q(x_t) ∈ R^{R × H},  B_Q(x_t) ∈ R^{R × D_h}\n",
        "          Q_t = (1/R) * sum_r A_Q(x_t)[r] ⊗ B_Q(x_t)[r] ∈ R^{H×D_h}\n",
        "      K, V 同理，A、B 都是 contextual（依赖 x_t）\n",
        "    - gate: 用 full 分支的 attention + 2D 空间权重，决定每个 token\n",
        "            更偏 full 还是偏 low-rank\n",
        "    同时维护 alpha 的 running mean，方便估算 KV cache。\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        num_heads=8,\n",
        "        rank=16,\n",
        "        qkv_bias=True,\n",
        "        qk_scale=None,\n",
        "        attn_drop=0.0,\n",
        "        proj_drop=0.0,\n",
        "        grid_size=(14, 14),  # ViT tiny: (224,16) -> (14,14)\n",
        "        gamma=1.0,           # 空间邻域加权强度\n",
        "        sigma=None,          # 高斯宽度\n",
        "        gate_scale=1.0,      # s_norm 放大多少再过 sigmoid\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0, \"dim 必须能整除 num_heads\"\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.rank = rank\n",
        "\n",
        "        self.scale = qk_scale or self.head_dim ** -0.5\n",
        "\n",
        "        # ===== full 分支：标准 qkv =====\n",
        "        self.qkv_full = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "\n",
        "        # ===== low-rank 分支：True TPA（A、B 都 contextual，两个向量 outer product）=====\n",
        "        H = self.num_heads\n",
        "        Dh = self.head_dim\n",
        "        R = self.rank\n",
        "\n",
        "        # A_q/A_k/A_v(x): (B,N,R*H) -> (B,N,R,H)\n",
        "        self.A_q = nn.Linear(dim, R * H, bias=qkv_bias)\n",
        "        self.A_k = nn.Linear(dim, R * H, bias=qkv_bias)\n",
        "        self.A_v = nn.Linear(dim, R * H, bias=qkv_bias)\n",
        "\n",
        "        # B_q/B_k/B_v(x): (B,N,R*D_h) -> (B,N,R,D_h)\n",
        "        self.B_q = nn.Linear(dim, R * Dh, bias=qkv_bias)\n",
        "        self.B_k = nn.Linear(dim, R * Dh, bias=qkv_bias)\n",
        "        self.B_v = nn.Linear(dim, R * Dh, bias=qkv_bias)\n",
        "\n",
        "        # 输出投影\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "        # ===== 空间 gate =====\n",
        "        self.grid_size = grid_size\n",
        "        Hp, Wp = grid_size\n",
        "        num_patches = Hp * Wp\n",
        "        self.num_patches = num_patches\n",
        "        self.gamma = gamma\n",
        "        self.gate_scale = gate_scale\n",
        "\n",
        "        # 预计算 2D 距离矩阵 -> 空间权重 w_ij\n",
        "        coords = []\n",
        "        for y in range(Hp):\n",
        "            for x in range(Wp):\n",
        "                coords.append((x, y))\n",
        "        coords = torch.tensor(coords, dtype=torch.float32)  # (P,2)\n",
        "        dists = torch.cdist(coords, coords, p=2)            # (P,P)\n",
        "\n",
        "        if sigma is None:\n",
        "            sigma = max(Hp, Wp) / 2.0\n",
        "\n",
        "        w = 1.0 + gamma * torch.exp(- (dists ** 2) / (2 * sigma ** 2))  # (P,P)\n",
        "        self.register_buffer(\"spatial_weight\", w)\n",
        "\n",
        "        self.eps = 1e-6\n",
        "        self.last_alpha = None\n",
        "\n",
        "        # 统计 alpha 的 running mean（用来估算 KV cache）\n",
        "        self.register_buffer(\"alpha_running_sum\", torch.zeros(1))\n",
        "        self.register_buffer(\"alpha_count\", torch.zeros(1))\n",
        "\n",
        "        # 模块级 gate 强度（默认 1.0，训练时会被外部调度）\n",
        "        self.gate_strength = 1.0\n",
        "\n",
        "    # === low-rank 分支：构造 Q/K/V（原版 TPA，两向量 outer product） ===\n",
        "    def _low_rank_qkv(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, N, C)\n",
        "        return q, k, v: (B, H, N, D)\n",
        "        \"\"\"\n",
        "        B, N, C = x.shape\n",
        "        H, Dh, R = self.num_heads, self.head_dim, self.rank\n",
        "\n",
        "        # ---------- Q ----------\n",
        "        Aq = self.A_q(x).view(B, N, R, H)   # (B,N,R,H)\n",
        "        Bq = self.B_q(x).view(B, N, R, Dh)  # (B,N,R,D_h)\n",
        "        # (B,N,H,D_h) = (1/R) * sum_r a_r ⊗ b_r\n",
        "        q = torch.einsum(\"bnrh,bnrd->bnhd\", Aq, Bq) / float(R)\n",
        "\n",
        "        # ---------- K ----------\n",
        "        Ak = self.A_k(x).view(B, N, R, H)\n",
        "        Bk = self.B_k(x).view(B, N, R, Dh)\n",
        "        k = torch.einsum(\"bnrh,bnrd->bnhd\", Ak, Bk) / float(R)\n",
        "\n",
        "        # ---------- V ----------\n",
        "        Av = self.A_v(x).view(B, N, R, H)\n",
        "        Bv = self.B_v(x).view(B, N, R, Dh)\n",
        "        v = torch.einsum(\"bnrh,bnrd->bnhd\", Av, Bv) / float(R)\n",
        "\n",
        "        # reshape 成 (B, H, N, D)\n",
        "        q = q.permute(0, 2, 1, 3)  # (B,H,N,D)\n",
        "        k = k.permute(0, 2, 1, 3)\n",
        "        v = v.permute(0, 2, 1, 3)\n",
        "        return q, k, v\n",
        "\n",
        "    # === 从 full attention + 2D 位置 得到 gate alpha ===\n",
        "    def _compute_gate(self, attn_full, gate_strength=1.0):\n",
        "        \"\"\"\n",
        "        attn_full: (B, H, N, N)，已经 softmax\n",
        "        return alpha_final: (B, N, 1)\n",
        "        \"\"\"\n",
        "        B, H, N, _ = attn_full.shape\n",
        "\n",
        "        # 对 head 平均: (B,N,N)\n",
        "        attn_mean = attn_full.mean(dim=1)\n",
        "\n",
        "        # u[b,i] = sum_j attn[j,i]  (被多少 token 看)\n",
        "        u = attn_mean.sum(dim=1)  # (B,N)\n",
        "\n",
        "        if N == self.num_patches + 1:\n",
        "            has_cls = True\n",
        "            u_cls = u[:, :1]\n",
        "            u_patch = u[:, 1:]\n",
        "        elif N == self.num_patches:\n",
        "            has_cls = False\n",
        "            u_patch = u\n",
        "            u_cls = None\n",
        "        else:\n",
        "            # 防御式：假定前面有一些非 patch token\n",
        "            has_cls = True\n",
        "            extra = N - self.num_patches\n",
        "            u_cls = u[:, :extra]\n",
        "            u_patch = u[:, extra:]\n",
        "\n",
        "        # 空间加权: s = u_patch @ W^T\n",
        "        s_patch = torch.matmul(u_patch, self.spatial_weight.t())  # (B,P)\n",
        "\n",
        "        mean = s_patch.mean(dim=-1, keepdim=True)\n",
        "        std = s_patch.std(dim=-1, keepdim=True) + self.eps\n",
        "        s_norm = (s_patch - mean) / std\n",
        "\n",
        "        alpha_patch = torch.sigmoid(self.gate_scale * s_norm)  # (B,P)\n",
        "\n",
        "        if has_cls:\n",
        "            alpha_full = torch.ones(\n",
        "                B, self.num_patches + 1, 1,\n",
        "                device=attn_full.device,\n",
        "                dtype=attn_full.dtype,\n",
        "            )\n",
        "            alpha_full[:, 0, 0] = 1.0  # cls 全 full\n",
        "            alpha_full[:, 1:, 0] = alpha_patch\n",
        "        else:\n",
        "            alpha_full = alpha_patch.unsqueeze(-1)  # (B,P,1)\n",
        "\n",
        "        # gate_strength: 0 -> 全部 1, 1 -> 用 alpha_full\n",
        "        if gate_strength < 1.0:\n",
        "            alpha_final = 1.0 - gate_strength * (1.0 - alpha_full)\n",
        "        else:\n",
        "            alpha_final = alpha_full\n",
        "\n",
        "        self.last_alpha = alpha_final.detach()\n",
        "\n",
        "        # 更新 running mean\n",
        "        self.alpha_running_sum += alpha_final.detach().sum()\n",
        "        self.alpha_count += torch.tensor(\n",
        "            alpha_final.numel(),\n",
        "            device=alpha_final.device,\n",
        "            dtype=self.alpha_running_sum.dtype,\n",
        "        )\n",
        "\n",
        "        return alpha_final  # (B,N,1)\n",
        "\n",
        "    def reset_alpha_stats(self):\n",
        "        self.alpha_running_sum.zero_()\n",
        "        self.alpha_count.zero_()\n",
        "\n",
        "    def get_mean_alpha(self):\n",
        "        if self.alpha_count.item() <= 0:\n",
        "            return None\n",
        "        return (self.alpha_running_sum / self.alpha_count).item()\n",
        "\n",
        "    def forward(self, x, attn_mask=None, gate_strength=None):\n",
        "        B, N, C = x.shape\n",
        "\n",
        "        # 如果调用方没传 gate_strength，就用模块自己的值（由训练循环控制）\n",
        "        if gate_strength is None:\n",
        "            gate_strength = float(self.gate_strength)\n",
        "\n",
        "        # ===== full 分支 =====\n",
        "        qkv = self.qkv_full(x).reshape(B, N, 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)  # (3,B,H,N,D)\n",
        "        q_full, k_full, v_full = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        attn_scores_full = (q_full * self.scale) @ k_full.transpose(-2, -1)\n",
        "        if attn_mask is not None:\n",
        "            attn_scores_full = attn_scores_full + attn_mask\n",
        "        attn_full = attn_scores_full.softmax(dim=-1)\n",
        "        attn_full = self.attn_drop(attn_full)\n",
        "\n",
        "        # gate\n",
        "        alpha = self._compute_gate(attn_full, gate_strength=gate_strength)  # (B,N,1)\n",
        "\n",
        "        out_full = attn_full @ v_full  # (B,H,N,D)\n",
        "        out_full = out_full.transpose(1, 2).reshape(B, N, C)  # (B,N,C)\n",
        "\n",
        "        # ===== low-rank 分支（TPA）=====\n",
        "        q_low, k_low, v_low = self._low_rank_qkv(x)\n",
        "        attn_scores_low = (q_low * self.scale) @ k_low.transpose(-2, -1)\n",
        "        if attn_mask is not None:\n",
        "            attn_scores_low = attn_scores_low + attn_mask\n",
        "        attn_low = attn_scores_low.softmax(dim=-1)\n",
        "        attn_low = self.attn_drop(attn_low)\n",
        "\n",
        "        out_low = attn_low @ v_low\n",
        "        out_low = out_low.transpose(1, 2).reshape(B, N, C)\n",
        "\n",
        "        # ===== gate 混合 =====\n",
        "        if gate_strength <= 0.0:\n",
        "            out = out_full\n",
        "        else:\n",
        "            out = alpha * out_full + (1.0 - alpha) * out_low\n",
        "\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out\n",
        "def set_focus_tpa_gate_strength(model: nn.Module, gate_strength: float):\n",
        "    \"\"\"\n",
        "    在整个模型里，把所有 FocusTPAAttention 的 gate_strength 设为同一个值。\n",
        "\n",
        "    gate_strength 含义：\n",
        "      - 0.0  → out ≈ 纯 full MHA 分支\n",
        "      - 1.0  → 使用空间 gate：alpha * full + (1-alpha) * low-rank\n",
        "      - 中间值 → 从纯 full 逐渐过渡到 gated 混合\n",
        "    \"\"\"\n",
        "    from inspect import isclass\n",
        "    # 防止名字没导入的问题，兼容你之前定义的 FocusTPAAttention\n",
        "    try:\n",
        "        FocusClass = FocusTPAAttention\n",
        "    except NameError:\n",
        "        raise RuntimeError(\"请先在上面的 cell 中定义 FocusTPAAttention 类。\")\n",
        "\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, FocusClass):\n",
        "            m.gate_strength = float(gate_strength)\n",
        "\n",
        "\n",
        "def train_model_focus_tpa(\n",
        "    model: nn.Module,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    device,\n",
        "    total_epochs: int,\n",
        "    warmup_full_epochs: int = 10,   # 阶段1：纯 full MHA\n",
        "    ramp_gate_epochs: int = 10,     # 阶段2：gate_strength 线性从 0→1\n",
        "    scaler=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    适用于 FocusTPAAttention 的训练函数（full + low-rank True TPA + 空间 gate）。\n",
        "\n",
        "    三个阶段：\n",
        "      - Epoch < warmup_full_epochs:\n",
        "          gate_strength = 0.0       → 输出完全来自 full 分支\n",
        "      - warmup_full_epochs <= Epoch < warmup_full_epochs + ramp_gate_epochs:\n",
        "          gate_strength 线性从 0→1 → 逐步引入 low-rank 分支\n",
        "      - 之后:\n",
        "          gate_strength = 1.0       → 使用空间 gate 的完整混合\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    train_loss_curve = []\n",
        "    val_loss_curve   = []\n",
        "    train_acc_curve  = []\n",
        "    val_acc_curve    = []\n",
        "    best_val_acc     = 0.0\n",
        "\n",
        "    for epoch in range(total_epochs):\n",
        "        # ====== 决定本 epoch 的 gate_strength & phase 标记 ======\n",
        "        if epoch < warmup_full_epochs:\n",
        "            gate_strength = 0.0\n",
        "            phase_tag = \"focus-warmup(full-only)\"\n",
        "        elif epoch < warmup_full_epochs + ramp_gate_epochs and ramp_gate_epochs > 0:\n",
        "            # 线性从 0 → 1\n",
        "            progress = (epoch - warmup_full_epochs + 1) / float(ramp_gate_epochs)\n",
        "            gate_strength = max(0.0, min(1.0, progress))\n",
        "            phase_tag = f\"focus-ramp(g={gate_strength:.2f})\"\n",
        "        else:\n",
        "            gate_strength = 1.0\n",
        "            phase_tag = \"focus-mix(full+lowrank)\"\n",
        "\n",
        "        # 把 gate_strength 写进所有 FocusTPAAttention 模块\n",
        "        set_focus_tpa_gate_strength(model, gate_strength)\n",
        "\n",
        "        # ====== 一轮训练 & 验证 ======\n",
        "        # 这里要和你原来 MHA/TPA/Tucker 用的 train_one_epoch / eval_one_epoch 保持一致\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, device, epoch, total_epochs, scaler\n",
        "        )\n",
        "        val_loss, val_acc = eval_one_epoch(\n",
        "            model, val_loader, criterion, device, epoch, total_epochs\n",
        "        )\n",
        "\n",
        "        train_loss_curve.append(train_loss)\n",
        "        val_loss_curve.append(val_loss)\n",
        "        train_acc_curve.append(train_acc)\n",
        "        val_acc_curve.append(val_acc)\n",
        "        best_val_acc = max(best_val_acc, val_acc)\n",
        "\n",
        "        print(\n",
        "            f\"[FocusTPA] Epoch {epoch+1}/{total_epochs} | phase={phase_tag} | \"\n",
        "            f\"train loss: {train_loss:.4f}, train acc: {train_acc:.3f} | \"\n",
        "            f\"val loss: {val_loss:.4f}, val acc: {val_acc:.3f}\"\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"train_loss_curve\": train_loss_curve,\n",
        "        \"val_loss_curve\":   val_loss_curve,\n",
        "        \"train_acc_curve\":  train_acc_curve,\n",
        "        \"val_acc_curve\":    val_acc_curve,\n",
        "        \"best_val_acc\":     best_val_acc,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CHKzXfy7pN_8"
      },
      "outputs": [],
      "source": [
        "from timm.models.vision_transformer import VisionTransformer\n",
        "import torch.nn as nn\n",
        "\n",
        "# 记得这几个类已经在别的文件里定义好：\n",
        "# - TPAAttention\n",
        "# - ContextualCPAttention   （如果你还用的话）\n",
        "# - FocusTPAAttention\n",
        "# - FocusContextualTPAAttention\n",
        "# - ContextualTuckerTPAAttention\n",
        "# - StaticCoreTuckerTPAAttention  （如果还需要静态版）\n",
        "\n",
        "\n",
        "def replace_vit_attn_with_tpa_true(\n",
        "    vit_model: VisionTransformer,\n",
        "    rank_q: int,\n",
        "    rank_k: int,\n",
        "    rank_v: int,\n",
        "):\n",
        "    \"\"\"\n",
        "    把 timm ViT 的每个 block.attn 换成：论文原版 True TPA (A/B 都 contextual, 两向量外积)\n",
        "    使用 TPAAttention（你之前那版实现）。\n",
        "    \"\"\"\n",
        "    for blk in vit_model.blocks:\n",
        "        old_attn = blk.attn\n",
        "\n",
        "        dim = old_attn.qkv.in_features\n",
        "        num_heads = old_attn.num_heads\n",
        "        attn_drop = float(old_attn.attn_drop.p)\n",
        "        proj_drop = float(old_attn.proj_drop.p)\n",
        "        qkv_bias = old_attn.qkv.bias is not None\n",
        "        qk_scale = old_attn.scale if hasattr(old_attn, \"scale\") else None\n",
        "\n",
        "        blk.attn = TPAAttention(\n",
        "            dim=dim,\n",
        "            num_heads=num_heads,\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            qkv_bias=qkv_bias,\n",
        "            qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=proj_drop,\n",
        "        )\n",
        "def replace_vit_attn_with_nonlinear_tpa(\n",
        "    vit_model,\n",
        "    rank_q: int,\n",
        "    rank_k: int,\n",
        "    rank_v: int,\n",
        "    mlp_hidden_ratio: float = 1.0,\n",
        "    mlp_on: str = \"qkv\",   # ✅ 新增\n",
        "):\n",
        "    for blk in vit_model.blocks:\n",
        "        old_attn = blk.attn\n",
        "\n",
        "        dim = old_attn.qkv.in_features\n",
        "        num_heads = old_attn.num_heads\n",
        "        attn_drop = float(old_attn.attn_drop.p)\n",
        "        proj_drop = float(old_attn.proj_drop.p)\n",
        "        qkv_bias = old_attn.qkv.bias is not None\n",
        "        qk_scale = old_attn.scale if hasattr(old_attn, \"scale\") else None\n",
        "\n",
        "        blk.attn = NonlinearTPAAttention(\n",
        "            dim=dim,\n",
        "            num_heads=num_heads,\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            qkv_bias=qkv_bias,\n",
        "            qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=proj_drop,\n",
        "            mlp_hidden_ratio=mlp_hidden_ratio,\n",
        "            mlp_on=mlp_on,   # ✅ 关键\n",
        "        )\n",
        "\n",
        "        \n",
        "def replace_vit_attn_with_headwise_nonlinear_tpa(\n",
        "    vit_model,\n",
        "    rank_q: int,\n",
        "    rank_k: int,\n",
        "    rank_v: int,\n",
        "    mlp_hidden_ratio: float = 1.0,\n",
        "    mlp_on: str = \"qkv\",\n",
        "):\n",
        "    \n",
        "    for blk in vit_model.blocks:\n",
        "        old_attn = blk.attn\n",
        "\n",
        "        dim = old_attn.qkv.in_features\n",
        "        num_heads = old_attn.num_heads\n",
        "        attn_drop = float(old_attn.attn_drop.p)\n",
        "        proj_drop = float(old_attn.proj_drop.p)\n",
        "        qkv_bias = old_attn.qkv.bias is not None\n",
        "        qk_scale = old_attn.scale if hasattr(old_attn, \"scale\") else None\n",
        "\n",
        "        blk.attn = HeadwiseNonlinearTPAAttention(\n",
        "            dim=dim,\n",
        "            num_heads=num_heads,\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            qkv_bias=qkv_bias,\n",
        "            qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=proj_drop,\n",
        "            mlp_hidden_ratio=mlp_hidden_ratio,\n",
        "            mlp_on=mlp_on,\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "def replace_vit_attn_with_sinter_tpa(\n",
        "    vit_model: VisionTransformer,\n",
        "    rank_q: int,\n",
        "    rank_k: int,\n",
        "    rank_v: int,\n",
        "    mlp_hidden_ratio: float = 1.0,\n",
        "    sinter_A: float = 5e-5,\n",
        "    sinter_omega: float = 1e4,\n",
        "):\n",
        "    \"\"\"\n",
        "    把 timm ViT 的每个 block.attn 换成 SinterTPAAttention 版本的 TPA：\n",
        "      Q_lin = 1/R * A^T B\n",
        "      Q = MLP_Sinter(Q_lin)\n",
        "\n",
        "    参数\n",
        "    ----\n",
        "    rank_q, rank_k, rank_v : TPA 的 rank\n",
        "    mlp_hidden_ratio       : hidden_dim = mlp_hidden_ratio * head_dim\n",
        "    sinter_A, sinter_omega : Sinter 激活的超参数\n",
        "    \"\"\"\n",
        "    for blk in vit_model.blocks:\n",
        "        old_attn = blk.attn\n",
        "\n",
        "        dim = old_attn.qkv.in_features\n",
        "        num_heads = old_attn.num_heads\n",
        "        attn_drop = float(old_attn.attn_drop.p)\n",
        "        proj_drop = float(old_attn.proj_drop.p)\n",
        "        qkv_bias = old_attn.qkv.bias is not None\n",
        "        qk_scale = old_attn.scale if hasattr(old_attn, \"scale\") else None\n",
        "\n",
        "        blk.attn = SinterTPAAttention(\n",
        "            dim=dim,\n",
        "            num_heads=num_heads,\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            qkv_bias=qkv_bias,\n",
        "            qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=proj_drop,\n",
        "            mlp_hidden_ratio=mlp_hidden_ratio,\n",
        "            sinter_A=sinter_A,\n",
        "            sinter_omega=sinter_omega,\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def replace_vit_attn_with_contextual_tpa(\n",
        "    vit_model: VisionTransformer,\n",
        "    rank_q: int,\n",
        "    rank_k: int,\n",
        "    rank_v: int,\n",
        "    contextA: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    把 timm ViT 的每个 block.attn 换成：ContextualCPAttention（简化 CP 版 TPA）\n",
        "      - contextA=True  -> contextual A, non-contextual B\n",
        "      - contextA=False -> non-contextual A, contextual B\n",
        "    \"\"\"\n",
        "    for blk in vit_model.blocks:\n",
        "        old_attn = blk.attn\n",
        "\n",
        "        dim = old_attn.qkv.in_features\n",
        "        num_heads = old_attn.num_heads\n",
        "        attn_drop = float(old_attn.attn_drop.p)\n",
        "        proj_drop = float(old_attn.proj_drop.p)\n",
        "        qkv_bias = old_attn.qkv.bias is not None\n",
        "        qk_scale = old_attn.scale if hasattr(old_attn, \"scale\") else None\n",
        "\n",
        "        blk.attn = ContextualCPAttention(\n",
        "            dim=dim,\n",
        "            num_heads=num_heads,\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            qkv_bias=qkv_bias,\n",
        "            qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=proj_drop,\n",
        "            contextA=contextA,\n",
        "        )\n",
        "\n",
        "\n",
        "def replace_vit_attn_with_focus_tpa(\n",
        "    vit_model: VisionTransformer,\n",
        "    rank: int = 2,\n",
        "    gamma: float = 1.0,\n",
        "    sigma=None,\n",
        "    gate_scale: float = 1.0,\n",
        "):\n",
        "    \"\"\"\n",
        "    把 timm ViT 的每个 block.attn 换成：FocusTPAAttention\n",
        "    （full MHA + low-rank True TPA + spatial gate）\n",
        "    \"\"\"\n",
        "    # timm 的 ViT 有 patch_embed.grid_size\n",
        "    grid_size = vit_model.patch_embed.grid_size  # (Hp, Wp)\n",
        "\n",
        "    for blk in vit_model.blocks:\n",
        "        old_attn = blk.attn\n",
        "\n",
        "        dim = old_attn.qkv.in_features\n",
        "        num_heads = old_attn.num_heads\n",
        "        attn_drop = float(old_attn.attn_drop.p)\n",
        "        proj_drop = float(old_attn.proj_drop.p)\n",
        "        qkv_bias = old_attn.qkv.bias is not None\n",
        "        qk_scale = old_attn.scale if hasattr(old_attn, \"scale\") else None\n",
        "\n",
        "        blk.attn = FocusTPAAttention(\n",
        "            dim=dim,\n",
        "            num_heads=num_heads,\n",
        "            rank=rank,\n",
        "            qkv_bias=qkv_bias,\n",
        "            qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=proj_drop,\n",
        "            grid_size=grid_size,\n",
        "            gamma=gamma,\n",
        "            sigma=sigma,\n",
        "            gate_scale=gate_scale,\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "def replace_vit_attn_with_focus_contextual_tpa(\n",
        "    vit_model: VisionTransformer,\n",
        "    rank: int = 2,\n",
        "    gamma: float = 1.0,\n",
        "    sigma=None,\n",
        "    gate_scale: float = 1.0,\n",
        "    contextA: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    把 timm ViT 的每个 block.attn 换成：FocusContextualTPAAttention\n",
        "    （full MHA + contextual TPA + spatial gate）\n",
        "    \"\"\"\n",
        "    grid_size = vit_model.patch_embed.grid_size  # (Hp, Wp)\n",
        "\n",
        "    for blk in vit_model.blocks:\n",
        "        old_attn = blk.attn\n",
        "\n",
        "        dim = old_attn.qkv.in_features\n",
        "        num_heads = old_attn.num_heads\n",
        "        attn_drop = float(old_attn.attn_drop.p)\n",
        "        proj_drop = float(old_attn.proj_drop.p)\n",
        "        qkv_bias = old_attn.qkv.bias is not None\n",
        "        qk_scale = old_attn.scale if hasattr(old_attn, \"scale\") else None\n",
        "\n",
        "        blk.attn = FocusContextualTPAAttention(\n",
        "            dim=dim,\n",
        "            num_heads=num_heads,\n",
        "            rank=rank,\n",
        "            qkv_bias=qkv_bias,\n",
        "            qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=proj_drop,\n",
        "            grid_size=grid_size,\n",
        "            gamma=gamma,\n",
        "            sigma=sigma,\n",
        "            gate_scale=gate_scale,\n",
        "            contextA=contextA,\n",
        "        )\n",
        "\n",
        "\n",
        "# ================== ✅ 重点：新的 Tucker 版本 ==================\n",
        "\n",
        "def replace_vit_attn_with_contextual_tucker_tpa(\n",
        "    vit_model: VisionTransformer,\n",
        "    rank_q: int,\n",
        "    rank_k: int,\n",
        "    rank_v: int,\n",
        "):\n",
        "    \"\"\"\n",
        "    把 timm ViT 的每个 block.attn 换成：ContextualTuckerTPAAttention（统一版）\n",
        "\n",
        "    接口对齐为 rank_q / rank_k / rank_v，\n",
        "    这样你可以做到：\n",
        "\n",
        "        - TPA:    rank_q, rank_k, rank_v\n",
        "        - Tucker: rank_q, rank_k, rank_v（完全一致）\n",
        "\n",
        "    并且在两阶段训练里：\n",
        "      - Phase 1: cp_only=True, 只用 A/B（函数族 = TPA）\n",
        "      - Phase 2: cp_only=False, 用 A/G/B^T（Tucker 提升 expressive power）\n",
        "    \"\"\"\n",
        "    for blk in vit_model.blocks:\n",
        "        old_attn = blk.attn\n",
        "\n",
        "        if not hasattr(old_attn, \"qkv\"):\n",
        "            raise ValueError(\"当前 block.attn 没有 qkv 属性，可能不是标准 timm ViT Attention。\")\n",
        "\n",
        "        dim = old_attn.qkv.in_features\n",
        "        num_heads = old_attn.num_heads\n",
        "        attn_drop = float(old_attn.attn_drop.p)\n",
        "        proj_drop = float(old_attn.proj_drop.p)\n",
        "        qkv_bias = old_attn.qkv.bias is not None\n",
        "        qk_scale = getattr(old_attn, \"scale\", None)\n",
        "\n",
        "        blk.attn = ContextualTuckerTPAAttention(\n",
        "            dim=dim,\n",
        "            num_heads=num_heads,\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            qkv_bias=qkv_bias,\n",
        "            qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=proj_drop,\n",
        "        )\n",
        "\n",
        "\n",
        "def replace_vit_attn_with_static_tucker_tpa(\n",
        "    vit_model: VisionTransformer,\n",
        "    rank_q: int,\n",
        "    rank_k: int,\n",
        "    rank_v: int,\n",
        "    progressive_g: bool = True,\n",
        "    init_lambda: float = 1.0,\n",
        "):\n",
        "    \"\"\"\n",
        "    如果你还保留 StaticCoreTuckerTPAAttention 的话，\n",
        "    这里也可以按新的 rank_q / rank_k / rank_v 接口改。\n",
        "    不用的话可以整个函数删掉。\n",
        "    \"\"\"\n",
        "    for blk in vit_model.blocks:\n",
        "        old_attn = blk.attn\n",
        "\n",
        "        if hasattr(old_attn, \"qkv\"):\n",
        "            dim = old_attn.qkv.in_features\n",
        "            qkv_bias = old_attn.qkv.bias is not None\n",
        "        else:\n",
        "            dim = old_attn.dim\n",
        "            qkv_bias = True\n",
        "\n",
        "        num_heads = old_attn.num_heads\n",
        "        attn_drop = float(old_attn.attn_drop.p)\n",
        "        proj_drop = float(old_attn.proj_drop.p)\n",
        "        qk_scale = getattr(old_attn, \"scale\", None)\n",
        "\n",
        "        blk.attn = StaticCoreTuckerTPAAttention(\n",
        "            dim=dim,\n",
        "            num_heads=num_heads,\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            qkv_bias=qkv_bias,\n",
        "            qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=proj_drop,\n",
        "            progressive_g=progressive_g,\n",
        "            init_lambda=init_lambda,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Upv4Sl9BpQgu"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ViTClassifier(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes,\n",
        "        model_name: str = \"vit_tiny_patch16_224\",\n",
        "        pretrained: bool = False,\n",
        "\n",
        "        # 选择注意力类型：\n",
        "        # \"mha\" / \"tpa\" / \"nonlinear_tpa\" / \"sinter_tpa\" /\n",
        "        # \"contextual_tpa\" / \"focus_tpa\" / \"focus_contextual_tpa\" / \"tucker_tpa\"\n",
        "        attn_type: str = \"mha\",\n",
        "\n",
        "        # ====== TPA / Contextual-TPA 的 rank 设置 ======\n",
        "        rank_q: int = 16,\n",
        "        rank_k: int = 2,\n",
        "        rank_v: int = 2,\n",
        "        contextual_tpa_A: bool = True,   # 对 contextual_tpa: True=contextual A, False=contextual B\n",
        "\n",
        "        # ====== Nonlinear / Sinter TPA 的 MLP 设置 ======\n",
        "        nonlinear_mlp_hidden_ratio: float = 2.0,  # hidden_dim = ratio * head_dim\n",
        "\n",
        "        # Sinter 激活的超参（只在 attn_type == \"sinter_tpa\" 时使用）\n",
        "        sinter_A: float = 5e-5,\n",
        "        sinter_omega: float = 1e4,\n",
        "\n",
        "        # ====== Focus-(Contextual)-TPA 的参数 ======\n",
        "        focus_rank: int = 2,\n",
        "        focus_gamma: float = 1.0,\n",
        "        focus_gate_scale: float = 1.0,\n",
        "        focus_contextual_A: bool = True, # 对 focus_contextual_tpa：同上，控制 A/B 谁 contextual\n",
        "\n",
        "        # ====== Tucker-TPA 的 rank 设置 ======\n",
        "        # 对于新的 contextual Tucker-TPA：\n",
        "        #   - 实际只用到 rank_head / rank_channel\n",
        "        #   - rank_token 在这里可以暂时忽略（兼容原配置）\n",
        "        rank_token: int = 16,\n",
        "        rank_head: int = 8,\n",
        "        rank_channel: int = 8,\n",
        "\n",
        "        nonlinear_mlp_on: str = \"qkv\"\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # 创建基础 ViT 模型\n",
        "        self.vit = timm.create_model(\n",
        "            model_name,\n",
        "            pretrained=pretrained,\n",
        "            num_classes=num_classes,\n",
        "        )\n",
        "\n",
        "        # 根据 attn_type 替换 attention\n",
        "        if attn_type == \"mha\":\n",
        "            # 原生 MHA，什么都不做\n",
        "            pass\n",
        "\n",
        "        elif attn_type == \"tpa\":\n",
        "            # True TPA（A/B 全 contextual，两向量 outer product）\n",
        "            replace_vit_attn_with_tpa_true(\n",
        "                self.vit,\n",
        "                rank_q=rank_q,\n",
        "                rank_k=rank_k,\n",
        "                rank_v=rank_v,\n",
        "            )\n",
        "\n",
        "        elif attn_type == \"nonlinear_tpa\":\n",
        "            # True TPA + head 内一层 MLP 非线性：Q = MLP(1/R A^T B)\n",
        "            replace_vit_attn_with_nonlinear_tpa(\n",
        "                self.vit,\n",
        "                rank_q=rank_q,\n",
        "                rank_k=rank_k,\n",
        "                rank_v=rank_v,\n",
        "                mlp_hidden_ratio=nonlinear_mlp_hidden_ratio,\n",
        "                mlp_on=nonlinear_mlp_on,\n",
        "            )\n",
        "        elif attn_type == \"headwise_nonlinear_tpa\":\n",
        "            replace_vit_attn_with_headwise_nonlinear_tpa(\n",
        "        self.vit,\n",
        "        rank_q=rank_q,\n",
        "        rank_k=rank_k,\n",
        "        rank_v=rank_v,\n",
        "        mlp_hidden_ratio=nonlinear_mlp_hidden_ratio,\n",
        "        mlp_on=nonlinear_mlp_on,\n",
        "    )\n",
        "\n",
        "\n",
        "        elif attn_type == \"sinter_tpa\":\n",
        "            # True TPA + head 内一层 MLP(Sinter)：Q = MLP_Sinter(1/R A^T B)\n",
        "            replace_vit_attn_with_sinter_tpa(\n",
        "                self.vit,\n",
        "                rank_q=rank_q,\n",
        "                rank_k=rank_k,\n",
        "                rank_v=rank_v,\n",
        "                mlp_hidden_ratio=nonlinear_mlp_hidden_ratio,\n",
        "                sinter_A=sinter_A,\n",
        "                sinter_omega=sinter_omega,\n",
        "            )\n",
        "\n",
        "        elif attn_type == \"contextual_tpa\":\n",
        "            # 简化版 Contextual TPA（CP 形式）\n",
        "            replace_vit_attn_with_contextual_tpa(\n",
        "                self.vit,\n",
        "                rank_q=rank_q,\n",
        "                rank_k=rank_k,\n",
        "                rank_v=rank_v,\n",
        "                contextA=contextual_tpa_A,\n",
        "            )\n",
        "\n",
        "        elif attn_type == \"focus_tpa\":\n",
        "            # Focus-TPA（full + low-rank True TPA）\n",
        "            replace_vit_attn_with_focus_tpa(\n",
        "                self.vit,\n",
        "                rank=focus_rank,\n",
        "                gamma=focus_gamma,\n",
        "                sigma=None,\n",
        "                gate_scale=focus_gate_scale,\n",
        "            )\n",
        "\n",
        "        elif attn_type == \"focus_contextual_tpa\":\n",
        "            # Focus-Contextual-TPA（full + 低秩 contextual TPA）\n",
        "            replace_vit_attn_with_focus_contextual_tpa(\n",
        "                self.vit,\n",
        "                rank=focus_rank,\n",
        "                gamma=focus_gamma,\n",
        "                sigma=None,\n",
        "                gate_scale=focus_gate_scale,\n",
        "                contextA=focus_contextual_A,\n",
        "            )\n",
        "\n",
        "        elif attn_type == \"tucker_tpa\":\n",
        "            # Tucker-style Contextual Tensor Product Attention\n",
        "            replace_vit_attn_with_contextual_tucker_tpa(\n",
        "                self.vit,\n",
        "                rank_q=rank_q,\n",
        "                rank_k=rank_k,\n",
        "                rank_v=rank_v,\n",
        "                # 如果你新版本的函数需要 rank_head / rank_channel，\n",
        "                # 也可以在这里一起传进去：\n",
        "                # rank_head=rank_head,\n",
        "                # rank_channel=rank_channel,\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Unknown attn_type: {attn_type}. \"\n",
        "                f\"Expected one of ['mha','tpa','nonlinear_tpa','sinter_tpa',\"\n",
        "                f\"'contextual_tpa','focus_tpa','focus_contextual_tpa','tucker_tpa']\"\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Jph6eWJ6pUH8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "######################## Run dir: result\\ablation_seed2_20260105_113812_tiny_vit_tiny_patch16_224_EpC1040_C10020_bs128_lr0.0003_wd0.05_rq16_rk2_rv2_ratios_QKV1.0_KV1.5_KVsh3.0_single3.0 ########################\n",
            "\n",
            "\n",
            "==================== DATASET: cifar10 (epochs=40) ====================\n",
            "[Info] Resolved MHA attn_type = mha\n",
            "\n",
            "-------------------- [cifar10] Experiment: MHA_baseline --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/40]: 100%|████████████████████████████████████| 391/391 [01:33<00:00,  4.19it/s, loss=1.68]\n",
            "Val   [1/40]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.41it/s, loss=1.66]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 1/40 | train loss: 1.8298, train acc: 0.319 | val loss: 1.6354, val acc: 0.393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/40]: 100%|████████████████████████████████████| 391/391 [01:31<00:00,  4.27it/s, loss=1.64]\n",
            "Val   [2/40]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.60it/s, loss=1.42]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 2/40 | train loss: 1.5606, train acc: 0.426 | val loss: 1.4687, val acc: 0.467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/40]: 100%|████████████████████████████████████| 391/391 [01:30<00:00,  4.33it/s, loss=1.28]\n",
            "Val   [3/40]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.66it/s, loss=1.18]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 3/40 | train loss: 1.3918, train acc: 0.494 | val loss: 1.3726, val acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/40]: 100%|████████████████████████████████████| 391/391 [01:29<00:00,  4.35it/s, loss=1.12]\n",
            "Val   [4/40]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.64it/s, loss=1.04]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 4/40 | train loss: 1.2542, train acc: 0.549 | val loss: 1.2154, val acc: 0.560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/40]: 100%|████████████████████████████████████| 391/391 [01:30<00:00,  4.33it/s, loss=0.99]\n",
            "Val   [5/40]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.61it/s, loss=0.86]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 5/40 | train loss: 1.1626, train acc: 0.582 | val loss: 1.1725, val acc: 0.574\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/40]: 100%|████████████████████████████████████| 391/391 [01:30<00:00,  4.33it/s, loss=1.18]\n",
            "Val   [6/40]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.63it/s, loss=1.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 6/40 | train loss: 1.0966, train acc: 0.609 | val loss: 1.0860, val acc: 0.612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/40]: 100%|████████████████████████████████████| 391/391 [01:30<00:00,  4.34it/s, loss=1.01]\n",
            "Val   [7/40]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.20it/s, loss=0.98]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 7/40 | train loss: 1.0471, train acc: 0.625 | val loss: 1.0367, val acc: 0.623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/40]: 100%|███████████████████████████████████| 391/391 [01:30<00:00,  4.32it/s, loss=0.736]\n",
            "Val   [8/40]: 100%|█████████████████████████████████████| 79/79 [00:11<00:00,  6.90it/s, loss=0.975]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 8/40 | train loss: 0.9841, train acc: 0.648 | val loss: 1.0054, val acc: 0.635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/40]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.28it/s, loss=0.953]\n",
            "Val   [9/40]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.32it/s, loss=0.966]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 9/40 | train loss: 0.9424, train acc: 0.662 | val loss: 1.0324, val acc: 0.631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/40]: 100%|██████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=0.873]\n",
            "Val   [10/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.55it/s, loss=0.756]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 10/40 | train loss: 0.8990, train acc: 0.680 | val loss: 0.9290, val acc: 0.667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/40]: 100%|███████████████████████████████████| 391/391 [01:30<00:00,  4.30it/s, loss=1.07]\n",
            "Val   [11/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.57it/s, loss=0.672]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 11/40 | train loss: 0.8479, train acc: 0.699 | val loss: 0.9372, val acc: 0.665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/40]: 100%|██████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=0.765]\n",
            "Val   [12/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.56it/s, loss=0.548]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 12/40 | train loss: 0.8159, train acc: 0.710 | val loss: 0.8627, val acc: 0.693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/40]: 100%|██████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=0.677]\n",
            "Val   [13/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.59it/s, loss=0.659]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 13/40 | train loss: 0.7739, train acc: 0.724 | val loss: 0.8466, val acc: 0.698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/40]: 100%|██████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=0.681]\n",
            "Val   [14/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.59it/s, loss=0.556]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 14/40 | train loss: 0.7435, train acc: 0.737 | val loss: 0.8343, val acc: 0.701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.30it/s, loss=0.967]\n",
            "Val   [15/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.60it/s, loss=0.535]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 15/40 | train loss: 0.7099, train acc: 0.748 | val loss: 0.8849, val acc: 0.691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/40]: 100%|████████████████████████████████████| 391/391 [01:30<00:00,  4.31it/s, loss=0.5]\n",
            "Val   [16/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.53it/s, loss=0.512]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 16/40 | train loss: 0.6807, train acc: 0.760 | val loss: 0.8083, val acc: 0.719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/40]: 100%|███████████████████████████████████| 391/391 [01:30<00:00,  4.31it/s, loss=0.72]\n",
            "Val   [17/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.65it/s, loss=0.729]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 17/40 | train loss: 0.6531, train acc: 0.768 | val loss: 0.7968, val acc: 0.723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/40]: 100%|██████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=0.743]\n",
            "Val   [18/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.40it/s, loss=0.481]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 18/40 | train loss: 0.6212, train acc: 0.781 | val loss: 0.8111, val acc: 0.716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.33it/s, loss=0.395]\n",
            "Val   [19/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.30it/s, loss=0.546]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 19/40 | train loss: 0.5943, train acc: 0.790 | val loss: 0.7795, val acc: 0.735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.32it/s, loss=0.734]\n",
            "Val   [20/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.66it/s, loss=0.455]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 20/40 | train loss: 0.5636, train acc: 0.802 | val loss: 0.7690, val acc: 0.734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [21/40]: 100%|██████████████████████████████████| 391/391 [01:31<00:00,  4.27it/s, loss=0.702]\n",
            "Val   [21/40]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.42it/s, loss=0.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 21/40 | train loss: 0.5367, train acc: 0.810 | val loss: 0.8132, val acc: 0.722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [22/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.31it/s, loss=0.489]\n",
            "Val   [22/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.56it/s, loss=0.475]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 22/40 | train loss: 0.5058, train acc: 0.821 | val loss: 0.7944, val acc: 0.729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [23/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.30it/s, loss=0.457]\n",
            "Val   [23/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.28it/s, loss=0.388]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 23/40 | train loss: 0.4806, train acc: 0.830 | val loss: 0.7956, val acc: 0.733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [24/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.31it/s, loss=0.486]\n",
            "Val   [24/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.56it/s, loss=0.455]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 24/40 | train loss: 0.4618, train acc: 0.836 | val loss: 0.8186, val acc: 0.734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [25/40]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=0.55]\n",
            "Val   [25/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.46it/s, loss=0.296]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 25/40 | train loss: 0.4402, train acc: 0.844 | val loss: 0.8059, val acc: 0.736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [26/40]: 100%|████████████████████████████████████| 391/391 [01:30<00:00,  4.30it/s, loss=0.3]\n",
            "Val   [26/40]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.42it/s, loss=0.49]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 26/40 | train loss: 0.4042, train acc: 0.857 | val loss: 0.8173, val acc: 0.741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [27/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.32it/s, loss=0.424]\n",
            "Val   [27/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.48it/s, loss=0.507]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 27/40 | train loss: 0.3878, train acc: 0.863 | val loss: 0.8005, val acc: 0.744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [28/40]: 100%|██████████████████████████████████| 391/391 [01:31<00:00,  4.28it/s, loss=0.445]\n",
            "Val   [28/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.57it/s, loss=0.609]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 28/40 | train loss: 0.3574, train acc: 0.872 | val loss: 0.8190, val acc: 0.739\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [29/40]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=0.27]\n",
            "Val   [29/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.34it/s, loss=0.572]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 29/40 | train loss: 0.3326, train acc: 0.881 | val loss: 0.8310, val acc: 0.744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [30/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.30it/s, loss=0.214]\n",
            "Val   [30/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.58it/s, loss=0.278]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 30/40 | train loss: 0.3110, train acc: 0.889 | val loss: 0.8082, val acc: 0.754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [31/40]: 100%|██████████████████████████████████| 391/391 [01:32<00:00,  4.25it/s, loss=0.313]\n",
            "Val   [31/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.59it/s, loss=0.384]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 31/40 | train loss: 0.2875, train acc: 0.897 | val loss: 0.8439, val acc: 0.750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [32/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.32it/s, loss=0.363]\n",
            "Val   [32/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.60it/s, loss=0.359]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 32/40 | train loss: 0.2700, train acc: 0.903 | val loss: 0.8480, val acc: 0.747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [33/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.30it/s, loss=0.264]\n",
            "Val   [33/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.60it/s, loss=0.525]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 33/40 | train loss: 0.2340, train acc: 0.916 | val loss: 0.9085, val acc: 0.746\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [34/40]: 100%|██████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=0.368]\n",
            "Val   [34/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.55it/s, loss=0.515]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 34/40 | train loss: 0.2319, train acc: 0.917 | val loss: 0.9285, val acc: 0.748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [35/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.30it/s, loss=0.391]\n",
            "Val   [35/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.63it/s, loss=0.546]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 35/40 | train loss: 0.2090, train acc: 0.925 | val loss: 0.9633, val acc: 0.734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [36/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.31it/s, loss=0.233]\n",
            "Val   [36/40]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.63it/s, loss=0.49]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 36/40 | train loss: 0.1910, train acc: 0.933 | val loss: 0.9562, val acc: 0.743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [37/40]: 100%|██████████████████████████████████| 391/391 [01:31<00:00,  4.30it/s, loss=0.234]\n",
            "Val   [37/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.53it/s, loss=0.265]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 37/40 | train loss: 0.1864, train acc: 0.934 | val loss: 0.9772, val acc: 0.745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [38/40]: 100%|█████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=0.0739]\n",
            "Val   [38/40]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.59it/s, loss=0.32]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 38/40 | train loss: 0.1617, train acc: 0.943 | val loss: 1.0114, val acc: 0.742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [39/40]: 100%|█████████████████████████████████| 391/391 [01:30<00:00,  4.32it/s, loss=0.0832]\n",
            "Val   [39/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.58it/s, loss=0.414]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 39/40 | train loss: 0.1577, train acc: 0.944 | val loss: 1.0167, val acc: 0.743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [40/40]: 100%|██████████████████████████████████| 391/391 [01:30<00:00,  4.30it/s, loss=0.266]\n",
            "Val   [40/40]: 100%|████████████████████████████████████| 79/79 [00:10<00:00,  7.57it/s, loss=0.407]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 40/40 | train loss: 0.1465, train acc: 0.947 | val loss: 1.0247, val acc: 0.745\n",
            "\n",
            "-------------------- [cifar10] Experiment: TPA_r1622 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/40]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=1.56]\n",
            "Val   [1/40]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.49it/s, loss=1.27]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 1/40 | train loss: 1.7359, train acc: 0.353 | val loss: 1.5742, val acc: 0.423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/40]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=1.48]\n",
            "Val   [2/40]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.46it/s, loss=1.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 2/40 | train loss: 1.4755, train acc: 0.462 | val loss: 1.3794, val acc: 0.497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/40]: 100%|████████████████████████████████████| 391/391 [02:28<00:00,  2.63it/s, loss=1.41]\n",
            "Val   [3/40]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.50it/s, loss=1.16]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 3/40 | train loss: 1.3342, train acc: 0.516 | val loss: 1.3128, val acc: 0.525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/40]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=1.29]\n",
            "Val   [4/40]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.50it/s, loss=1.44]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 4/40 | train loss: 1.2422, train acc: 0.553 | val loss: 1.2981, val acc: 0.529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/40]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=1.16]\n",
            "Val   [5/40]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.50it/s, loss=1.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 5/40 | train loss: 1.1593, train acc: 0.582 | val loss: 1.1230, val acc: 0.595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/40]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=1.07]\n",
            "Val   [6/40]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.50it/s, loss=1.17]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 6/40 | train loss: 1.0861, train acc: 0.611 | val loss: 1.1449, val acc: 0.591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/40]: 100%|███████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.981]\n",
            "Val   [7/40]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.46it/s, loss=1.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 7/40 | train loss: 1.0279, train acc: 0.633 | val loss: 1.0773, val acc: 0.613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/40]: 100%|███████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.852]\n",
            "Val   [8/40]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.48it/s, loss=0.823]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 8/40 | train loss: 0.9651, train acc: 0.655 | val loss: 1.0165, val acc: 0.635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/40]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=1.03]\n",
            "Val   [9/40]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.49it/s, loss=0.917]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 9/40 | train loss: 0.9120, train acc: 0.674 | val loss: 1.0141, val acc: 0.643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.791]\n",
            "Val   [10/40]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.48it/s, loss=0.76]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 10/40 | train loss: 0.8699, train acc: 0.689 | val loss: 0.9527, val acc: 0.660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.762]\n",
            "Val   [11/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=0.724]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 11/40 | train loss: 0.8289, train acc: 0.703 | val loss: 0.9215, val acc: 0.674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/40]: 100%|██████████████████████████████████| 391/391 [02:28<00:00,  2.63it/s, loss=0.765]\n",
            "Val   [12/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.52it/s, loss=0.842]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 12/40 | train loss: 0.7874, train acc: 0.720 | val loss: 0.9380, val acc: 0.662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/40]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.8]\n",
            "Val   [13/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.49it/s, loss=0.735]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 13/40 | train loss: 0.7473, train acc: 0.733 | val loss: 0.9126, val acc: 0.683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.564]\n",
            "Val   [14/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.50it/s, loss=0.989]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 14/40 | train loss: 0.7076, train acc: 0.747 | val loss: 0.9058, val acc: 0.688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.727]\n",
            "Val   [15/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.50it/s, loss=0.974]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 15/40 | train loss: 0.6690, train acc: 0.761 | val loss: 0.8724, val acc: 0.694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.699]\n",
            "Val   [16/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.52it/s, loss=0.649]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 16/40 | train loss: 0.6348, train acc: 0.772 | val loss: 0.8944, val acc: 0.693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.874]\n",
            "Val   [17/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.42it/s, loss=0.634]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 17/40 | train loss: 0.6081, train acc: 0.784 | val loss: 0.8937, val acc: 0.693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.479]\n",
            "Val   [18/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.49it/s, loss=0.591]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 18/40 | train loss: 0.5600, train acc: 0.800 | val loss: 0.8358, val acc: 0.716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.772]\n",
            "Val   [19/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.48it/s, loss=0.512]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 19/40 | train loss: 0.5233, train acc: 0.813 | val loss: 0.9035, val acc: 0.694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.489]\n",
            "Val   [20/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=0.474]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 20/40 | train loss: 0.4920, train acc: 0.825 | val loss: 0.8651, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [21/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.443]\n",
            "Val   [21/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.49it/s, loss=0.465]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 21/40 | train loss: 0.4550, train acc: 0.838 | val loss: 0.8783, val acc: 0.716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [22/40]: 100%|██████████████████████████████████| 391/391 [02:28<00:00,  2.63it/s, loss=0.591]\n",
            "Val   [22/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=0.593]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 22/40 | train loss: 0.4213, train acc: 0.849 | val loss: 0.9414, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [23/40]: 100%|██████████████████████████████████| 391/391 [02:28<00:00,  2.63it/s, loss=0.503]\n",
            "Val   [23/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.53it/s, loss=0.809]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 23/40 | train loss: 0.4002, train acc: 0.856 | val loss: 0.9572, val acc: 0.699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [24/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.386]\n",
            "Val   [24/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=0.617]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 24/40 | train loss: 0.3560, train acc: 0.873 | val loss: 0.9476, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [25/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.356]\n",
            "Val   [25/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.50it/s, loss=0.565]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 25/40 | train loss: 0.3297, train acc: 0.881 | val loss: 0.9817, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [26/40]: 100%|██████████████████████████████████| 391/391 [02:28<00:00,  2.63it/s, loss=0.295]\n",
            "Val   [26/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.52it/s, loss=0.711]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 26/40 | train loss: 0.3117, train acc: 0.888 | val loss: 0.9561, val acc: 0.723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [27/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.206]\n",
            "Val   [27/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.48it/s, loss=0.492]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 27/40 | train loss: 0.2747, train acc: 0.902 | val loss: 0.9944, val acc: 0.716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [28/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.181]\n",
            "Val   [28/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.48it/s, loss=0.507]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 28/40 | train loss: 0.2539, train acc: 0.910 | val loss: 1.0144, val acc: 0.718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [29/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.291]\n",
            "Val   [29/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.48it/s, loss=0.615]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 29/40 | train loss: 0.2380, train acc: 0.914 | val loss: 1.0415, val acc: 0.713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [30/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.372]\n",
            "Val   [30/40]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.49it/s, loss=1.08]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 30/40 | train loss: 0.2268, train acc: 0.919 | val loss: 1.1053, val acc: 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [31/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.186]\n",
            "Val   [31/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.49it/s, loss=0.737]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 31/40 | train loss: 0.1925, train acc: 0.932 | val loss: 1.1432, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [32/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.214]\n",
            "Val   [32/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.49it/s, loss=0.689]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 32/40 | train loss: 0.1842, train acc: 0.934 | val loss: 1.1424, val acc: 0.715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [33/40]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.2]\n",
            "Val   [33/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.48it/s, loss=0.515]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 33/40 | train loss: 0.1784, train acc: 0.936 | val loss: 1.1918, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [34/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.207]\n",
            "Val   [34/40]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.52it/s, loss=0.81]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 34/40 | train loss: 0.1637, train acc: 0.942 | val loss: 1.1703, val acc: 0.717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [35/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.132]\n",
            "Val   [35/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.52it/s, loss=0.835]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 35/40 | train loss: 0.1445, train acc: 0.948 | val loss: 1.2090, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [36/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.141]\n",
            "Val   [36/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=0.453]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 36/40 | train loss: 0.1473, train acc: 0.949 | val loss: 1.2330, val acc: 0.715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [37/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.248]\n",
            "Val   [37/40]: 100%|████████████████████████████████████| 79/79 [00:17<00:00,  4.50it/s, loss=0.541]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 37/40 | train loss: 0.1446, train acc: 0.949 | val loss: 1.1964, val acc: 0.721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [38/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=0.103]\n",
            "Val   [38/40]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.49it/s, loss=1.22]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 38/40 | train loss: 0.1324, train acc: 0.954 | val loss: 1.2328, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [39/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.135]\n",
            "Val   [39/40]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.50it/s, loss=1.05]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 39/40 | train loss: 0.1077, train acc: 0.963 | val loss: 1.2777, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [40/40]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.126]\n",
            "Val   [40/40]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.49it/s, loss=1.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 40/40 | train loss: 0.1320, train acc: 0.953 | val loss: 1.2661, val acc: 0.711\n",
            "\n",
            "-------------------- [cifar10] Experiment: NonlinearTPA_KV --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/40]: 100%|████████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=1.53]\n",
            "Val   [1/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=1.28]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/40 | train loss: 1.7839, train acc: 0.328 | val loss: 1.6287, val acc: 0.388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/40]: 100%|████████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=1.59]\n",
            "Val   [2/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=1.34]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/40 | train loss: 1.5038, train acc: 0.446 | val loss: 1.4506, val acc: 0.471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/40]: 100%|████████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=1.45]\n",
            "Val   [3/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=1.11]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/40 | train loss: 1.3709, train acc: 0.501 | val loss: 1.3891, val acc: 0.496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/40]: 100%|█████████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=1.2]\n",
            "Val   [4/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=1.05]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/40 | train loss: 1.2734, train acc: 0.539 | val loss: 1.2779, val acc: 0.537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/40]: 100%|████████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=1.15]\n",
            "Val   [5/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.788]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/40 | train loss: 1.1933, train acc: 0.571 | val loss: 1.1859, val acc: 0.573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/40]: 100%|████████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=1.04]\n",
            "Val   [6/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=0.812]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/40 | train loss: 1.1221, train acc: 0.596 | val loss: 1.1117, val acc: 0.601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/40]: 100%|████████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=1.15]\n",
            "Val   [7/40]: 100%|███████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=1.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/40 | train loss: 1.0603, train acc: 0.620 | val loss: 1.0781, val acc: 0.610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/40]: 100%|███████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.971]\n",
            "Val   [8/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.878]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/40 | train loss: 1.0038, train acc: 0.640 | val loss: 1.0474, val acc: 0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/40]: 100%|███████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.842]\n",
            "Val   [9/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.706]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/40 | train loss: 0.9442, train acc: 0.661 | val loss: 1.0180, val acc: 0.634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.801]\n",
            "Val   [10/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.693]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/40 | train loss: 0.9009, train acc: 0.678 | val loss: 1.0054, val acc: 0.644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.793]\n",
            "Val   [11/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.841]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/40 | train loss: 0.8566, train acc: 0.692 | val loss: 0.9111, val acc: 0.676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.626]\n",
            "Val   [12/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=0.85]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/40 | train loss: 0.8176, train acc: 0.706 | val loss: 0.9383, val acc: 0.668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.699]\n",
            "Val   [13/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=0.623]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/40 | train loss: 0.7833, train acc: 0.720 | val loss: 0.9096, val acc: 0.678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.748]\n",
            "Val   [14/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.568]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/40 | train loss: 0.7523, train acc: 0.730 | val loss: 0.8866, val acc: 0.687\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.33it/s, loss=0.793]\n",
            "Val   [15/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.584]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/40 | train loss: 0.7124, train acc: 0.745 | val loss: 0.8716, val acc: 0.690\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.691]\n",
            "Val   [16/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.441]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/40 | train loss: 0.6828, train acc: 0.755 | val loss: 0.8555, val acc: 0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/40]: 100%|███████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.68]\n",
            "Val   [17/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.553]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/40 | train loss: 0.6503, train acc: 0.770 | val loss: 0.8615, val acc: 0.699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.419]\n",
            "Val   [18/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.621]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/40 | train loss: 0.6151, train acc: 0.780 | val loss: 0.8813, val acc: 0.702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.625]\n",
            "Val   [19/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.565]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/40 | train loss: 0.5863, train acc: 0.789 | val loss: 0.8487, val acc: 0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.655]\n",
            "Val   [20/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.617]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/40 | train loss: 0.5670, train acc: 0.798 | val loss: 0.8542, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [21/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.698]\n",
            "Val   [21/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.87]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 21/40 | train loss: 0.5231, train acc: 0.815 | val loss: 0.8608, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [22/40]: 100%|███████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.45]\n",
            "Val   [22/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=0.513]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 22/40 | train loss: 0.5038, train acc: 0.820 | val loss: 0.8702, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [23/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.441]\n",
            "Val   [23/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.621]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 23/40 | train loss: 0.4664, train acc: 0.835 | val loss: 0.8712, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [24/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.439]\n",
            "Val   [24/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=0.511]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 24/40 | train loss: 0.4406, train acc: 0.842 | val loss: 0.8858, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [25/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.574]\n",
            "Val   [25/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.556]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 25/40 | train loss: 0.4127, train acc: 0.852 | val loss: 0.9115, val acc: 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [26/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.375]\n",
            "Val   [26/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.884]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 26/40 | train loss: 0.3810, train acc: 0.864 | val loss: 0.9440, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [27/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.33it/s, loss=0.362]\n",
            "Val   [27/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.686]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 27/40 | train loss: 0.3529, train acc: 0.873 | val loss: 0.9393, val acc: 0.719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [28/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.33it/s, loss=0.224]\n",
            "Val   [28/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.559]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 28/40 | train loss: 0.3349, train acc: 0.881 | val loss: 0.9164, val acc: 0.718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [29/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.321]\n",
            "Val   [29/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.582]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 29/40 | train loss: 0.3025, train acc: 0.891 | val loss: 0.9671, val acc: 0.723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [30/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.302]\n",
            "Val   [30/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.414]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 30/40 | train loss: 0.2814, train acc: 0.898 | val loss: 0.9839, val acc: 0.724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [31/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.333]\n",
            "Val   [31/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.964]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 31/40 | train loss: 0.2609, train acc: 0.907 | val loss: 1.0889, val acc: 0.713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [32/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.376]\n",
            "Val   [32/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.47]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 32/40 | train loss: 0.2404, train acc: 0.913 | val loss: 1.0539, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [33/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.341]\n",
            "Val   [33/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.76]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 33/40 | train loss: 0.2200, train acc: 0.922 | val loss: 1.0986, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [34/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.156]\n",
            "Val   [34/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=0.552]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 34/40 | train loss: 0.2044, train acc: 0.929 | val loss: 1.1090, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [35/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.318]\n",
            "Val   [35/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.517]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 35/40 | train loss: 0.1887, train acc: 0.933 | val loss: 1.1070, val acc: 0.716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [36/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.218]\n",
            "Val   [36/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.952]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 36/40 | train loss: 0.1843, train acc: 0.935 | val loss: 1.1698, val acc: 0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [37/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.194]\n",
            "Val   [37/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.965]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 37/40 | train loss: 0.1734, train acc: 0.939 | val loss: 1.1488, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [38/40]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.33it/s, loss=0.268]\n",
            "Val   [38/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.68]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 38/40 | train loss: 0.1562, train acc: 0.944 | val loss: 1.1857, val acc: 0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [39/40]: 100%|█████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.0593]\n",
            "Val   [39/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=1.12]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 39/40 | train loss: 0.1538, train acc: 0.945 | val loss: 1.2153, val acc: 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [40/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.33it/s, loss=0.196]\n",
            "Val   [40/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.341]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 40/40 | train loss: 0.1432, train acc: 0.949 | val loss: 1.1702, val acc: 0.718\n",
            "\n",
            "-------------------- [cifar10] Experiment: NonlinearTPA_KV_shared --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/40]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.65]\n",
            "Val   [1/40]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=1.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/40 | train loss: 1.7898, train acc: 0.329 | val loss: 1.5724, val acc: 0.413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.44]\n",
            "Val   [2/40]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=1.35]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/40 | train loss: 1.4695, train acc: 0.461 | val loss: 1.3912, val acc: 0.496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.26]\n",
            "Val   [3/40]: 100%|███████████████████████████████████████| 79/79 [00:19<00:00,  3.99it/s, loss=1.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/40 | train loss: 1.3289, train acc: 0.517 | val loss: 1.3360, val acc: 0.522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.15it/s, loss=1.33]\n",
            "Val   [4/40]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  3.99it/s, loss=1.13]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/40 | train loss: 1.2380, train acc: 0.552 | val loss: 1.2222, val acc: 0.555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.97]\n",
            "Val   [5/40]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=1.08]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/40 | train loss: 1.1558, train acc: 0.585 | val loss: 1.1520, val acc: 0.589\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.23]\n",
            "Val   [6/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.99it/s, loss=0.997]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/40 | train loss: 1.0943, train acc: 0.606 | val loss: 1.0929, val acc: 0.603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.11]\n",
            "Val   [7/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.722]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/40 | train loss: 1.0412, train acc: 0.625 | val loss: 1.0557, val acc: 0.617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/40]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=1.02]\n",
            "Val   [8/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=0.863]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/40 | train loss: 0.9759, train acc: 0.649 | val loss: 1.0383, val acc: 0.629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/40]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.825]\n",
            "Val   [9/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.96it/s, loss=0.973]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/40 | train loss: 0.9374, train acc: 0.662 | val loss: 0.9624, val acc: 0.656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.824]\n",
            "Val   [10/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=0.645]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/40 | train loss: 0.8986, train acc: 0.678 | val loss: 0.9558, val acc: 0.656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.845]\n",
            "Val   [11/40]: 100%|████████████████████████████████████| 79/79 [00:20<00:00,  3.95it/s, loss=0.741]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/40 | train loss: 0.8554, train acc: 0.695 | val loss: 0.9375, val acc: 0.664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.949]\n",
            "Val   [12/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=0.846]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/40 | train loss: 0.8098, train acc: 0.709 | val loss: 0.9242, val acc: 0.669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.532]\n",
            "Val   [13/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.95it/s, loss=0.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/40 | train loss: 0.7802, train acc: 0.720 | val loss: 0.8834, val acc: 0.686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.647]\n",
            "Val   [14/40]: 100%|████████████████████████████████████| 79/79 [00:20<00:00,  3.95it/s, loss=0.782]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/40 | train loss: 0.7448, train acc: 0.736 | val loss: 0.8737, val acc: 0.689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.855]\n",
            "Val   [15/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.634]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/40 | train loss: 0.7139, train acc: 0.744 | val loss: 0.8363, val acc: 0.705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.592]\n",
            "Val   [16/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.512]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/40 | train loss: 0.6841, train acc: 0.753 | val loss: 0.8353, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.408]\n",
            "Val   [17/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.677]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/40 | train loss: 0.6454, train acc: 0.769 | val loss: 0.8763, val acc: 0.692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.681]\n",
            "Val   [18/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=0.857]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/40 | train loss: 0.6116, train acc: 0.780 | val loss: 0.8528, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.437]\n",
            "Val   [19/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.873]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/40 | train loss: 0.5819, train acc: 0.792 | val loss: 0.8574, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.437]\n",
            "Val   [20/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.776]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/40 | train loss: 0.5584, train acc: 0.800 | val loss: 0.8464, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [21/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.299]\n",
            "Val   [21/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.96it/s, loss=0.896]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 21/40 | train loss: 0.5288, train acc: 0.810 | val loss: 0.8316, val acc: 0.723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [22/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.465]\n",
            "Val   [22/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=0.671]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 22/40 | train loss: 0.5016, train acc: 0.822 | val loss: 0.8282, val acc: 0.720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [23/40]: 100%|███████████████████████████████████| 391/391 [03:01<00:00,  2.15it/s, loss=0.53]\n",
            "Val   [23/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.00it/s, loss=0.696]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 23/40 | train loss: 0.4666, train acc: 0.834 | val loss: 0.8588, val acc: 0.719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [24/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.414]\n",
            "Val   [24/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.914]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 24/40 | train loss: 0.4435, train acc: 0.842 | val loss: 0.8529, val acc: 0.721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [25/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.593]\n",
            "Val   [25/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.657]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 25/40 | train loss: 0.4110, train acc: 0.853 | val loss: 0.8555, val acc: 0.729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [26/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.352]\n",
            "Val   [26/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.96it/s, loss=0.672]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 26/40 | train loss: 0.3850, train acc: 0.861 | val loss: 0.8718, val acc: 0.722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [27/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.257]\n",
            "Val   [27/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.801]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 27/40 | train loss: 0.3585, train acc: 0.871 | val loss: 0.9387, val acc: 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [28/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.429]\n",
            "Val   [28/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.656]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 28/40 | train loss: 0.3368, train acc: 0.881 | val loss: 0.9471, val acc: 0.719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [29/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.268]\n",
            "Val   [29/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.52]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 29/40 | train loss: 0.3121, train acc: 0.888 | val loss: 0.9119, val acc: 0.724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [30/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.364]\n",
            "Val   [30/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=0.396]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 30/40 | train loss: 0.2907, train acc: 0.895 | val loss: 0.9465, val acc: 0.726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [31/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.345]\n",
            "Val   [31/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.96it/s, loss=0.569]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 31/40 | train loss: 0.2763, train acc: 0.902 | val loss: 1.0006, val acc: 0.721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [32/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.276]\n",
            "Val   [32/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.452]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 32/40 | train loss: 0.2415, train acc: 0.914 | val loss: 1.0232, val acc: 0.725\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [33/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.198]\n",
            "Val   [33/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.96it/s, loss=0.718]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 33/40 | train loss: 0.2346, train acc: 0.916 | val loss: 1.0235, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [34/40]: 100%|███████████████████████████████████| 391/391 [03:01<00:00,  2.15it/s, loss=0.22]\n",
            "Val   [34/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.96it/s, loss=0.526]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 34/40 | train loss: 0.2121, train acc: 0.924 | val loss: 1.0369, val acc: 0.728\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [35/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.202]\n",
            "Val   [35/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.878]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 35/40 | train loss: 0.1999, train acc: 0.928 | val loss: 1.0317, val acc: 0.731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [36/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.129]\n",
            "Val   [36/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=0.306]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 36/40 | train loss: 0.1870, train acc: 0.934 | val loss: 1.1228, val acc: 0.719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [37/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.165]\n",
            "Val   [37/40]: 100%|████████████████████████████████████| 79/79 [00:20<00:00,  3.94it/s, loss=0.732]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 37/40 | train loss: 0.1855, train acc: 0.934 | val loss: 1.0630, val acc: 0.726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [38/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.238]\n",
            "Val   [38/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.502]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 38/40 | train loss: 0.1619, train acc: 0.941 | val loss: 1.1489, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [39/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.265]\n",
            "Val   [39/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=0.523]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 39/40 | train loss: 0.1603, train acc: 0.943 | val loss: 1.0854, val acc: 0.731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [40/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.169]\n",
            "Val   [40/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=0.589]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 40/40 | train loss: 0.1436, train acc: 0.949 | val loss: 1.1432, val acc: 0.725\n",
            "\n",
            "-------------------- [cifar10] Experiment: NonlinearTPA_HW_KV --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/40]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.74]\n",
            "Val   [1/40]: 100%|███████████████████████████████████████| 79/79 [00:19<00:00,  4.11it/s, loss=1.3]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 1/40 | train loss: 1.8435, train acc: 0.308 | val loss: 1.6631, val acc: 0.382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.27]\n",
            "Val   [2/40]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=1.12]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 2/40 | train loss: 1.5094, train acc: 0.445 | val loss: 1.4737, val acc: 0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/40]: 100%|█████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.5]\n",
            "Val   [3/40]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=1.38]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 3/40 | train loss: 1.3664, train acc: 0.502 | val loss: 1.3246, val acc: 0.527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/40]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.24]\n",
            "Val   [4/40]: 100%|███████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=1.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 4/40 | train loss: 1.2738, train acc: 0.539 | val loss: 1.2522, val acc: 0.549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.15it/s, loss=1.04]\n",
            "Val   [5/40]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=1.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 5/40 | train loss: 1.2138, train acc: 0.564 | val loss: 1.1891, val acc: 0.574\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/40]: 100%|█████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.2]\n",
            "Val   [6/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=0.888]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 6/40 | train loss: 1.1433, train acc: 0.587 | val loss: 1.1682, val acc: 0.581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.33]\n",
            "Val   [7/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=0.801]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 7/40 | train loss: 1.0992, train acc: 0.603 | val loss: 1.1452, val acc: 0.593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/40]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.14]\n",
            "Val   [8/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.791]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 8/40 | train loss: 1.0536, train acc: 0.621 | val loss: 1.0824, val acc: 0.612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/40]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.898]\n",
            "Val   [9/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=0.832]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 9/40 | train loss: 1.0079, train acc: 0.636 | val loss: 1.0453, val acc: 0.623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.915]\n",
            "Val   [10/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.837]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 10/40 | train loss: 0.9642, train acc: 0.653 | val loss: 1.0220, val acc: 0.634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.876]\n",
            "Val   [11/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.818]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 11/40 | train loss: 0.9229, train acc: 0.668 | val loss: 0.9856, val acc: 0.644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/40]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.88]\n",
            "Val   [12/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.717]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 12/40 | train loss: 0.8808, train acc: 0.684 | val loss: 0.9753, val acc: 0.655\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.859]\n",
            "Val   [13/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.779]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 13/40 | train loss: 0.8500, train acc: 0.693 | val loss: 0.9986, val acc: 0.648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.772]\n",
            "Val   [14/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.728]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 14/40 | train loss: 0.8229, train acc: 0.704 | val loss: 0.9126, val acc: 0.675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.727]\n",
            "Val   [15/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.11it/s, loss=0.771]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 15/40 | train loss: 0.7809, train acc: 0.720 | val loss: 0.9299, val acc: 0.676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.615]\n",
            "Val   [16/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.582]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 16/40 | train loss: 0.7519, train acc: 0.729 | val loss: 0.9204, val acc: 0.677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.828]\n",
            "Val   [17/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=0.66]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 17/40 | train loss: 0.7197, train acc: 0.741 | val loss: 0.9173, val acc: 0.681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.587]\n",
            "Val   [18/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.11it/s, loss=0.883]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 18/40 | train loss: 0.6823, train acc: 0.754 | val loss: 0.9462, val acc: 0.671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.633]\n",
            "Val   [19/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=0.553]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 19/40 | train loss: 0.6476, train acc: 0.766 | val loss: 0.8984, val acc: 0.692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.533]\n",
            "Val   [20/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=0.723]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 20/40 | train loss: 0.6235, train acc: 0.776 | val loss: 0.9177, val acc: 0.688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [21/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.733]\n",
            "Val   [21/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=0.663]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 21/40 | train loss: 0.5877, train acc: 0.790 | val loss: 0.8542, val acc: 0.704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [22/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.585]\n",
            "Val   [22/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=0.787]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 22/40 | train loss: 0.5641, train acc: 0.797 | val loss: 0.8771, val acc: 0.704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [23/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.585]\n",
            "Val   [23/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.956]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 23/40 | train loss: 0.5274, train acc: 0.812 | val loss: 0.9056, val acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [24/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.494]\n",
            "Val   [24/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=0.525]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 24/40 | train loss: 0.4955, train acc: 0.823 | val loss: 0.8714, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [25/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.608]\n",
            "Val   [25/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.919]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 25/40 | train loss: 0.4641, train acc: 0.834 | val loss: 0.9317, val acc: 0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [26/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.453]\n",
            "Val   [26/40]: 100%|████████████████████████████████████████| 79/79 [00:19<00:00,  4.11it/s, loss=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 26/40 | train loss: 0.4386, train acc: 0.843 | val loss: 0.9270, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [27/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.385]\n",
            "Val   [27/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.11it/s, loss=0.748]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 27/40 | train loss: 0.4160, train acc: 0.850 | val loss: 0.9598, val acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [28/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.15it/s, loss=0.476]\n",
            "Val   [28/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.765]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 28/40 | train loss: 0.3849, train acc: 0.862 | val loss: 0.9657, val acc: 0.702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [29/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.15it/s, loss=0.411]\n",
            "Val   [29/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=0.658]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 29/40 | train loss: 0.3564, train acc: 0.871 | val loss: 0.9746, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [30/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.285]\n",
            "Val   [30/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.542]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 30/40 | train loss: 0.3288, train acc: 0.881 | val loss: 1.0079, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [31/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.258]\n",
            "Val   [31/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=0.818]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 31/40 | train loss: 0.3158, train acc: 0.886 | val loss: 1.0221, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [32/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.212]\n",
            "Val   [32/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=1.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 32/40 | train loss: 0.2867, train acc: 0.896 | val loss: 1.0441, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [33/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.213]\n",
            "Val   [33/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=0.608]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 33/40 | train loss: 0.2573, train acc: 0.907 | val loss: 1.0613, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [34/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.312]\n",
            "Val   [34/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=0.963]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 34/40 | train loss: 0.2441, train acc: 0.912 | val loss: 1.0572, val acc: 0.715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [35/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.345]\n",
            "Val   [35/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=0.944]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 35/40 | train loss: 0.2169, train acc: 0.923 | val loss: 1.1233, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [36/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.119]\n",
            "Val   [36/40]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=0.5]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 36/40 | train loss: 0.2158, train acc: 0.921 | val loss: 1.0858, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [37/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.234]\n",
            "Val   [37/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.652]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 37/40 | train loss: 0.1864, train acc: 0.934 | val loss: 1.1651, val acc: 0.702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [38/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.206]\n",
            "Val   [38/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=0.873]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 38/40 | train loss: 0.1851, train acc: 0.934 | val loss: 1.1877, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [39/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.236]\n",
            "Val   [39/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.11it/s, loss=1.26]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 39/40 | train loss: 0.1734, train acc: 0.938 | val loss: 1.2060, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [40/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.219]\n",
            "Val   [40/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=0.952]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 40/40 | train loss: 0.1607, train acc: 0.942 | val loss: 1.1871, val acc: 0.709\n",
            "\n",
            "-------------------- [cifar10] Experiment: NonlinearTPA_HW_KV --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/40]: 100%|████████████████████████████████████| 391/391 [03:00<00:00,  2.17it/s, loss=1.61]\n",
            "Val   [1/40]: 100%|███████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=1.3]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 1/40 | train loss: 1.8047, train acc: 0.319 | val loss: 1.5776, val acc: 0.416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/40]: 100%|████████████████████████████████████| 391/391 [03:00<00:00,  2.17it/s, loss=1.38]\n",
            "Val   [2/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=1.29]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 2/40 | train loss: 1.4813, train acc: 0.458 | val loss: 1.4083, val acc: 0.487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/40]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=1.51]\n",
            "Val   [3/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=1.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 3/40 | train loss: 1.3431, train acc: 0.512 | val loss: 1.3057, val acc: 0.530\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/40]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=1.42]\n",
            "Val   [4/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.962]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 4/40 | train loss: 1.2604, train acc: 0.545 | val loss: 1.2196, val acc: 0.564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/40]: 100%|████████████████████████████████████| 391/391 [03:00<00:00,  2.17it/s, loss=1.17]\n",
            "Val   [5/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.964]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 5/40 | train loss: 1.1910, train acc: 0.569 | val loss: 1.1615, val acc: 0.589\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/40]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=1.11]\n",
            "Val   [6/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=0.915]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 6/40 | train loss: 1.1215, train acc: 0.596 | val loss: 1.1329, val acc: 0.588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/40]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=1.07]\n",
            "Val   [7/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=0.756]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 7/40 | train loss: 1.0645, train acc: 0.618 | val loss: 1.1127, val acc: 0.597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/40]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=1.17]\n",
            "Val   [8/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.872]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 8/40 | train loss: 1.0019, train acc: 0.640 | val loss: 1.0513, val acc: 0.626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/40]: 100%|███████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=0.801]\n",
            "Val   [9/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.927]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 9/40 | train loss: 0.9570, train acc: 0.657 | val loss: 1.0298, val acc: 0.631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/40]: 100%|██████████████████████████████████| 391/391 [03:00<00:00,  2.17it/s, loss=0.914]\n",
            "Val   [10/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.824]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 10/40 | train loss: 0.9118, train acc: 0.671 | val loss: 0.9737, val acc: 0.650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/40]: 100%|██████████████████████████████████| 391/391 [02:58<00:00,  2.19it/s, loss=0.994]\n",
            "Val   [11/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.727]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 11/40 | train loss: 0.8704, train acc: 0.689 | val loss: 0.9590, val acc: 0.655\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=0.804]\n",
            "Val   [12/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.614]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 12/40 | train loss: 0.8298, train acc: 0.704 | val loss: 0.9246, val acc: 0.671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/40]: 100%|███████████████████████████████████| 391/391 [02:58<00:00,  2.19it/s, loss=0.71]\n",
            "Val   [13/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.593]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 13/40 | train loss: 0.7907, train acc: 0.717 | val loss: 0.9331, val acc: 0.666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/40]: 100%|██████████████████████████████████| 391/391 [02:58<00:00,  2.19it/s, loss=0.831]\n",
            "Val   [14/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.676]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 14/40 | train loss: 0.7561, train acc: 0.729 | val loss: 0.9182, val acc: 0.680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=0.734]\n",
            "Val   [15/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=0.726]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 15/40 | train loss: 0.7249, train acc: 0.741 | val loss: 0.8981, val acc: 0.683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/40]: 100%|██████████████████████████████████| 391/391 [02:58<00:00,  2.19it/s, loss=0.895]\n",
            "Val   [16/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.673]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 16/40 | train loss: 0.6898, train acc: 0.754 | val loss: 0.9224, val acc: 0.679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=0.606]\n",
            "Val   [17/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.807]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 17/40 | train loss: 0.6613, train acc: 0.764 | val loss: 0.8982, val acc: 0.684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/40]: 100%|██████████████████████████████████| 391/391 [03:00<00:00,  2.17it/s, loss=0.598]\n",
            "Val   [18/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.712]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 18/40 | train loss: 0.6273, train acc: 0.776 | val loss: 0.8923, val acc: 0.696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=0.476]\n",
            "Val   [19/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.855]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 19/40 | train loss: 0.5894, train acc: 0.789 | val loss: 0.8813, val acc: 0.705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=0.396]\n",
            "Val   [20/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.347]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 20/40 | train loss: 0.5604, train acc: 0.801 | val loss: 0.8592, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [21/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=0.595]\n",
            "Val   [21/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.68]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 21/40 | train loss: 0.5324, train acc: 0.810 | val loss: 0.8504, val acc: 0.716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [22/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=0.621]\n",
            "Val   [22/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.581]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 22/40 | train loss: 0.4934, train acc: 0.823 | val loss: 0.8895, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [23/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=0.552]\n",
            "Val   [23/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.648]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 23/40 | train loss: 0.4618, train acc: 0.834 | val loss: 0.9029, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [24/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=0.234]\n",
            "Val   [24/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.558]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 24/40 | train loss: 0.4325, train acc: 0.846 | val loss: 0.9256, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [25/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=0.515]\n",
            "Val   [25/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.419]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 25/40 | train loss: 0.4042, train acc: 0.856 | val loss: 0.9214, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [26/40]: 100%|██████████████████████████████████| 391/391 [02:58<00:00,  2.19it/s, loss=0.384]\n",
            "Val   [26/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.697]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 26/40 | train loss: 0.3815, train acc: 0.864 | val loss: 0.9212, val acc: 0.718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [27/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=0.368]\n",
            "Val   [27/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.48]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 27/40 | train loss: 0.3450, train acc: 0.877 | val loss: 0.9642, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [28/40]: 100%|██████████████████████████████████| 391/391 [02:58<00:00,  2.19it/s, loss=0.417]\n",
            "Val   [28/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.664]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 28/40 | train loss: 0.3149, train acc: 0.889 | val loss: 0.9683, val acc: 0.716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [29/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=0.221]\n",
            "Val   [29/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.44]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 29/40 | train loss: 0.3065, train acc: 0.891 | val loss: 0.9621, val acc: 0.717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [30/40]: 100%|██████████████████████████████████| 391/391 [03:00<00:00,  2.17it/s, loss=0.442]\n",
            "Val   [30/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.502]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 30/40 | train loss: 0.2744, train acc: 0.904 | val loss: 1.0403, val acc: 0.697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [31/40]: 100%|██████████████████████████████████| 391/391 [02:58<00:00,  2.19it/s, loss=0.364]\n",
            "Val   [31/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.259]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 31/40 | train loss: 0.2565, train acc: 0.909 | val loss: 1.1146, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [32/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=0.185]\n",
            "Val   [32/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.674]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 32/40 | train loss: 0.2368, train acc: 0.916 | val loss: 1.0615, val acc: 0.717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [33/40]: 100%|██████████████████████████████████| 391/391 [02:58<00:00,  2.19it/s, loss=0.258]\n",
            "Val   [33/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.375]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 33/40 | train loss: 0.2197, train acc: 0.921 | val loss: 1.1039, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [34/40]: 100%|██████████████████████████████████| 391/391 [02:58<00:00,  2.19it/s, loss=0.235]\n",
            "Val   [34/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.539]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 34/40 | train loss: 0.1977, train acc: 0.930 | val loss: 1.1549, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [35/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=0.292]\n",
            "Val   [35/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.87]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 35/40 | train loss: 0.1927, train acc: 0.932 | val loss: 1.1140, val acc: 0.719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [36/40]: 100%|███████████████████████████████████| 391/391 [03:00<00:00,  2.17it/s, loss=0.05]\n",
            "Val   [36/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.603]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 36/40 | train loss: 0.1693, train acc: 0.939 | val loss: 1.1679, val acc: 0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [37/40]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=0.239]\n",
            "Val   [37/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.658]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 37/40 | train loss: 0.1749, train acc: 0.937 | val loss: 1.1982, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [38/40]: 100%|██████████████████████████████████| 391/391 [02:58<00:00,  2.19it/s, loss=0.265]\n",
            "Val   [38/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=0.713]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 38/40 | train loss: 0.1550, train acc: 0.945 | val loss: 1.2343, val acc: 0.705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [39/40]: 100%|██████████████████████████████████| 391/391 [03:00<00:00,  2.17it/s, loss=0.177]\n",
            "Val   [39/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.654]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 39/40 | train loss: 0.1474, train acc: 0.948 | val loss: 1.2036, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [40/40]: 100%|█████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=0.0997]\n",
            "Val   [40/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.684]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 40/40 | train loss: 0.1423, train acc: 0.950 | val loss: 1.2200, val acc: 0.708\n",
            "\n",
            "-------------------- [cifar10] Experiment: NonlinearTPA_HW_KV_shared --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.65]\n",
            "Val   [1/40]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=1.31]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 1/40 | train loss: 1.8303, train acc: 0.312 | val loss: 1.6514, val acc: 0.381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.15it/s, loss=1.46]\n",
            "Val   [2/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=1.11]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 2/40 | train loss: 1.5216, train acc: 0.441 | val loss: 1.4924, val acc: 0.452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.15it/s, loss=1.37]\n",
            "Val   [3/40]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=1.12]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 3/40 | train loss: 1.3677, train acc: 0.503 | val loss: 1.3722, val acc: 0.507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/40]: 100%|████████████████████████████████████| 391/391 [03:01<00:00,  2.15it/s, loss=1.16]\n",
            "Val   [4/40]: 100%|█████████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 4/40 | train loss: 1.2844, train acc: 0.535 | val loss: 1.2659, val acc: 0.552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/40]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.967]\n",
            "Val   [5/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.853]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 5/40 | train loss: 1.2019, train acc: 0.564 | val loss: 1.1843, val acc: 0.572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/40]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.25]\n",
            "Val   [6/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.844]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 6/40 | train loss: 1.1360, train acc: 0.591 | val loss: 1.1166, val acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/40]: 100%|███████████████████████████████████| 391/391 [03:01<00:00,  2.15it/s, loss=0.957]\n",
            "Val   [7/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=0.805]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 7/40 | train loss: 1.0721, train acc: 0.613 | val loss: 1.0939, val acc: 0.613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/40]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.947]\n",
            "Val   [8/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=0.902]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 8/40 | train loss: 1.0181, train acc: 0.634 | val loss: 1.0375, val acc: 0.627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/40]: 100%|███████████████████████████████████| 391/391 [03:01<00:00,  2.15it/s, loss=0.833]\n",
            "Val   [9/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=0.835]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 9/40 | train loss: 0.9571, train acc: 0.657 | val loss: 1.0504, val acc: 0.625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.938]\n",
            "Val   [10/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.969]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 10/40 | train loss: 0.9169, train acc: 0.671 | val loss: 1.0157, val acc: 0.641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/40]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=1.01]\n",
            "Val   [11/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.706]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 11/40 | train loss: 0.8677, train acc: 0.689 | val loss: 0.9443, val acc: 0.665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.812]\n",
            "Val   [12/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=0.63]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 12/40 | train loss: 0.8263, train acc: 0.707 | val loss: 0.9112, val acc: 0.674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.801]\n",
            "Val   [13/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=0.606]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 13/40 | train loss: 0.7894, train acc: 0.719 | val loss: 0.9008, val acc: 0.677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.901]\n",
            "Val   [14/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.727]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 14/40 | train loss: 0.7457, train acc: 0.735 | val loss: 0.8925, val acc: 0.692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.655]\n",
            "Val   [15/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.581]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 15/40 | train loss: 0.7158, train acc: 0.745 | val loss: 0.9304, val acc: 0.678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/40]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.85]\n",
            "Val   [16/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=1.02]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 16/40 | train loss: 0.6896, train acc: 0.755 | val loss: 0.9081, val acc: 0.687\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.656]\n",
            "Val   [17/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.543]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 17/40 | train loss: 0.6448, train acc: 0.769 | val loss: 0.8665, val acc: 0.698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.564]\n",
            "Val   [18/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=0.892]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 18/40 | train loss: 0.6195, train acc: 0.779 | val loss: 0.8870, val acc: 0.697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.533]\n",
            "Val   [19/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.09it/s, loss=0.75]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 19/40 | train loss: 0.5954, train acc: 0.788 | val loss: 0.8653, val acc: 0.701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.494]\n",
            "Val   [20/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=0.619]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 20/40 | train loss: 0.5522, train acc: 0.804 | val loss: 0.8658, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [21/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.447]\n",
            "Val   [21/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.691]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 21/40 | train loss: 0.5299, train acc: 0.810 | val loss: 0.9354, val acc: 0.693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [22/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.612]\n",
            "Val   [22/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.785]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 22/40 | train loss: 0.4908, train acc: 0.824 | val loss: 0.8846, val acc: 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [23/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.714]\n",
            "Val   [23/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.92]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 23/40 | train loss: 0.4641, train acc: 0.833 | val loss: 0.8890, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [24/40]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.49]\n",
            "Val   [24/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.492]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 24/40 | train loss: 0.4341, train acc: 0.845 | val loss: 0.8922, val acc: 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [25/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.547]\n",
            "Val   [25/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.755]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 25/40 | train loss: 0.4024, train acc: 0.856 | val loss: 0.9549, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [26/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.387]\n",
            "Val   [26/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.711]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 26/40 | train loss: 0.3780, train acc: 0.864 | val loss: 0.9379, val acc: 0.715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [27/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.441]\n",
            "Val   [27/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.869]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 27/40 | train loss: 0.3489, train acc: 0.875 | val loss: 0.9976, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [28/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.283]\n",
            "Val   [28/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.783]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 28/40 | train loss: 0.3324, train acc: 0.880 | val loss: 1.0133, val acc: 0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [29/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.414]\n",
            "Val   [29/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.868]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 29/40 | train loss: 0.2979, train acc: 0.895 | val loss: 1.0169, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [30/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.324]\n",
            "Val   [30/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.705]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 30/40 | train loss: 0.2733, train acc: 0.902 | val loss: 0.9914, val acc: 0.716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [31/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.339]\n",
            "Val   [31/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=1.16]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 31/40 | train loss: 0.2602, train acc: 0.907 | val loss: 1.0351, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [32/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.297]\n",
            "Val   [32/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=1.31]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 32/40 | train loss: 0.2373, train acc: 0.915 | val loss: 1.0838, val acc: 0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [33/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.277]\n",
            "Val   [33/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=1.35]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 33/40 | train loss: 0.2207, train acc: 0.921 | val loss: 1.1428, val acc: 0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [34/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.276]\n",
            "Val   [34/40]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=1.32]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 34/40 | train loss: 0.2088, train acc: 0.926 | val loss: 1.1269, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [35/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.268]\n",
            "Val   [35/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=1.34]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 35/40 | train loss: 0.1825, train acc: 0.935 | val loss: 1.1287, val acc: 0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [36/40]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=0.208]\n",
            "Val   [36/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.918]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 36/40 | train loss: 0.1786, train acc: 0.936 | val loss: 1.1939, val acc: 0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [37/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.193]\n",
            "Val   [37/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=1.03]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 37/40 | train loss: 0.1613, train acc: 0.943 | val loss: 1.2213, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [38/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.192]\n",
            "Val   [38/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=1.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 38/40 | train loss: 0.1612, train acc: 0.943 | val loss: 1.1845, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [39/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.199]\n",
            "Val   [39/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.944]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 39/40 | train loss: 0.1527, train acc: 0.946 | val loss: 1.2479, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [40/40]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.144]\n",
            "Val   [40/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=1.09]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 40/40 | train loss: 0.1404, train acc: 0.951 | val loss: 1.2340, val acc: 0.711\n",
            "\n",
            "-------------------- [cifar10] Experiment: NonlinearTPA_QKV --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/40]: 100%|████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=1.64]\n",
            "Val   [1/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=1.55]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/40 | train loss: 1.8285, train acc: 0.310 | val loss: 1.6434, val acc: 0.380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/40]: 100%|████████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=1.31]\n",
            "Val   [2/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=1.47]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/40 | train loss: 1.5219, train acc: 0.443 | val loss: 1.4304, val acc: 0.486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/40]: 100%|█████████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=1.5]\n",
            "Val   [3/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=1.12]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/40 | train loss: 1.3598, train acc: 0.506 | val loss: 1.3175, val acc: 0.521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/40]: 100%|████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=1.28]\n",
            "Val   [4/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.953]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/40 | train loss: 1.2625, train acc: 0.543 | val loss: 1.2354, val acc: 0.549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/40]: 100%|████████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=1.23]\n",
            "Val   [5/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=1.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/40 | train loss: 1.1865, train acc: 0.569 | val loss: 1.2382, val acc: 0.555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/40]: 100%|████████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=1.25]\n",
            "Val   [6/40]: 100%|███████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=1.2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/40 | train loss: 1.1255, train acc: 0.592 | val loss: 1.1744, val acc: 0.584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/40]: 100%|████████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=1.25]\n",
            "Val   [7/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=1.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/40 | train loss: 1.0675, train acc: 0.615 | val loss: 1.1478, val acc: 0.591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/40]: 100%|███████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.887]\n",
            "Val   [8/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.908]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/40 | train loss: 1.0235, train acc: 0.631 | val loss: 1.0595, val acc: 0.614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/40]: 100%|████████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=1.08]\n",
            "Val   [9/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.684]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/40 | train loss: 0.9727, train acc: 0.651 | val loss: 1.0207, val acc: 0.633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.873]\n",
            "Val   [10/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.793]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/40 | train loss: 0.9271, train acc: 0.668 | val loss: 1.0216, val acc: 0.635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.29it/s, loss=0.954]\n",
            "Val   [11/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=0.955]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/40 | train loss: 0.8883, train acc: 0.681 | val loss: 0.9688, val acc: 0.653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.782]\n",
            "Val   [12/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=0.798]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/40 | train loss: 0.8524, train acc: 0.694 | val loss: 0.9824, val acc: 0.651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.29it/s, loss=0.947]\n",
            "Val   [13/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.724]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/40 | train loss: 0.8214, train acc: 0.704 | val loss: 0.9207, val acc: 0.674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.851]\n",
            "Val   [14/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.686]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/40 | train loss: 0.7834, train acc: 0.719 | val loss: 0.8879, val acc: 0.689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/40]: 100%|███████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.74]\n",
            "Val   [15/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.787]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/40 | train loss: 0.7492, train acc: 0.731 | val loss: 0.9301, val acc: 0.671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/40]: 100%|███████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.84]\n",
            "Val   [16/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.16it/s, loss=0.696]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/40 | train loss: 0.7189, train acc: 0.742 | val loss: 0.8946, val acc: 0.683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.839]\n",
            "Val   [17/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.712]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/40 | train loss: 0.6905, train acc: 0.752 | val loss: 0.9120, val acc: 0.679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.614]\n",
            "Val   [18/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.625]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/40 | train loss: 0.6571, train acc: 0.764 | val loss: 0.8758, val acc: 0.691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/40]: 100%|████████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.6]\n",
            "Val   [19/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.581]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/40 | train loss: 0.6226, train acc: 0.776 | val loss: 0.8534, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.29it/s, loss=0.415]\n",
            "Val   [20/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.693]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/40 | train loss: 0.5906, train acc: 0.788 | val loss: 0.8578, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [21/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.527]\n",
            "Val   [21/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.48]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 21/40 | train loss: 0.5591, train acc: 0.801 | val loss: 0.8807, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [22/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.524]\n",
            "Val   [22/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.473]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 22/40 | train loss: 0.5355, train acc: 0.808 | val loss: 0.8685, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [23/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.535]\n",
            "Val   [23/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.561]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 23/40 | train loss: 0.4996, train acc: 0.820 | val loss: 0.8725, val acc: 0.716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [24/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.383]\n",
            "Val   [24/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.77]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 24/40 | train loss: 0.4714, train acc: 0.832 | val loss: 0.8579, val acc: 0.717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [25/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.559]\n",
            "Val   [25/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.527]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 25/40 | train loss: 0.4428, train acc: 0.842 | val loss: 0.8676, val acc: 0.720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [26/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.584]\n",
            "Val   [26/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.514]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 26/40 | train loss: 0.4130, train acc: 0.852 | val loss: 0.9378, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [27/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.351]\n",
            "Val   [27/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=0.604]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 27/40 | train loss: 0.3842, train acc: 0.861 | val loss: 0.9087, val acc: 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [28/40]: 100%|██████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=0.607]\n",
            "Val   [28/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=0.503]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 28/40 | train loss: 0.3594, train acc: 0.871 | val loss: 0.9464, val acc: 0.705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [29/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.415]\n",
            "Val   [29/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=0.888]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 29/40 | train loss: 0.3334, train acc: 0.879 | val loss: 0.9702, val acc: 0.717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [30/40]: 100%|██████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=0.229]\n",
            "Val   [30/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.16it/s, loss=0.788]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 30/40 | train loss: 0.3020, train acc: 0.892 | val loss: 0.9902, val acc: 0.715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [31/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.253]\n",
            "Val   [31/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.802]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 31/40 | train loss: 0.2872, train acc: 0.897 | val loss: 1.0038, val acc: 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [32/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.315]\n",
            "Val   [32/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=0.764]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 32/40 | train loss: 0.2675, train acc: 0.904 | val loss: 0.9794, val acc: 0.719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [33/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.256]\n",
            "Val   [33/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=1.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 33/40 | train loss: 0.2473, train acc: 0.911 | val loss: 1.0721, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [34/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.238]\n",
            "Val   [34/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.585]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 34/40 | train loss: 0.2320, train acc: 0.917 | val loss: 1.0845, val acc: 0.720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [35/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.166]\n",
            "Val   [35/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=0.699]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 35/40 | train loss: 0.2123, train acc: 0.925 | val loss: 1.0979, val acc: 0.718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [36/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.313]\n",
            "Val   [36/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.446]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 36/40 | train loss: 0.1894, train acc: 0.932 | val loss: 1.1062, val acc: 0.718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [37/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.179]\n",
            "Val   [37/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.348]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 37/40 | train loss: 0.1854, train acc: 0.934 | val loss: 1.1454, val acc: 0.722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [38/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.131]\n",
            "Val   [38/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=0.67]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 38/40 | train loss: 0.1695, train acc: 0.940 | val loss: 1.2423, val acc: 0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [39/40]: 100%|███████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.22]\n",
            "Val   [39/40]: 100%|████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=0.544]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 39/40 | train loss: 0.1602, train acc: 0.944 | val loss: 1.1822, val acc: 0.715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [40/40]: 100%|██████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=0.207]\n",
            "Val   [40/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=0.423]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 40/40 | train loss: 0.1531, train acc: 0.946 | val loss: 1.2086, val acc: 0.708\n",
            "\n",
            "-------------------- [cifar10] Experiment: NonlinearTPA_Q --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.63]\n",
            "Val   [1/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=1.39]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/40 | train loss: 1.7419, train acc: 0.352 | val loss: 1.5654, val acc: 0.430\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.52]\n",
            "Val   [2/40]: 100%|███████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=1.3]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/40 | train loss: 1.4645, train acc: 0.466 | val loss: 1.4690, val acc: 0.460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.25]\n",
            "Val   [3/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/40 | train loss: 1.3262, train acc: 0.520 | val loss: 1.2707, val acc: 0.550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.13]\n",
            "Val   [4/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.14]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/40 | train loss: 1.2187, train acc: 0.558 | val loss: 1.1938, val acc: 0.570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.903]\n",
            "Val   [5/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=1.14]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/40 | train loss: 1.1321, train acc: 0.595 | val loss: 1.1329, val acc: 0.592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.04]\n",
            "Val   [6/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.998]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/40 | train loss: 1.0565, train acc: 0.620 | val loss: 1.0715, val acc: 0.617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.16]\n",
            "Val   [7/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.906]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/40 | train loss: 0.9899, train acc: 0.645 | val loss: 0.9984, val acc: 0.646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.871]\n",
            "Val   [8/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.948]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/40 | train loss: 0.9326, train acc: 0.666 | val loss: 1.0032, val acc: 0.643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.787]\n",
            "Val   [9/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.755]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/40 | train loss: 0.8821, train acc: 0.685 | val loss: 0.9815, val acc: 0.644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.01]\n",
            "Val   [10/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.86]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/40 | train loss: 0.8389, train acc: 0.700 | val loss: 0.9407, val acc: 0.671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.743]\n",
            "Val   [11/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.865]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/40 | train loss: 0.7930, train acc: 0.716 | val loss: 0.9338, val acc: 0.675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.697]\n",
            "Val   [12/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.901]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/40 | train loss: 0.7565, train acc: 0.731 | val loss: 0.9045, val acc: 0.680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.543]\n",
            "Val   [13/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.941]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/40 | train loss: 0.7147, train acc: 0.744 | val loss: 0.8726, val acc: 0.694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.561]\n",
            "Val   [14/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.795]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/40 | train loss: 0.6823, train acc: 0.757 | val loss: 0.8505, val acc: 0.699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.596]\n",
            "Val   [15/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.646]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/40 | train loss: 0.6368, train acc: 0.773 | val loss: 0.8860, val acc: 0.693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.715]\n",
            "Val   [16/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.25it/s, loss=0.656]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/40 | train loss: 0.5988, train acc: 0.787 | val loss: 0.8625, val acc: 0.704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.605]\n",
            "Val   [17/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.663]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/40 | train loss: 0.5752, train acc: 0.795 | val loss: 0.8870, val acc: 0.699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.594]\n",
            "Val   [18/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.797]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/40 | train loss: 0.5257, train acc: 0.814 | val loss: 0.9256, val acc: 0.693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.57]\n",
            "Val   [19/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.678]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/40 | train loss: 0.4922, train acc: 0.825 | val loss: 0.9064, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.669]\n",
            "Val   [20/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.556]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/40 | train loss: 0.4626, train acc: 0.834 | val loss: 0.9191, val acc: 0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [21/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.597]\n",
            "Val   [21/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.474]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 21/40 | train loss: 0.4215, train acc: 0.848 | val loss: 0.8896, val acc: 0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [22/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.489]\n",
            "Val   [22/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.866]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 22/40 | train loss: 0.3876, train acc: 0.862 | val loss: 0.9435, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [23/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.375]\n",
            "Val   [23/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.683]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 23/40 | train loss: 0.3495, train acc: 0.875 | val loss: 0.9867, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [24/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.474]\n",
            "Val   [24/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.598]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 24/40 | train loss: 0.3198, train acc: 0.884 | val loss: 0.9954, val acc: 0.705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [25/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.388]\n",
            "Val   [25/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.776]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 25/40 | train loss: 0.2921, train acc: 0.896 | val loss: 1.0467, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [26/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.332]\n",
            "Val   [26/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.915]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 26/40 | train loss: 0.2578, train acc: 0.908 | val loss: 1.0559, val acc: 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [27/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.311]\n",
            "Val   [27/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.578]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 27/40 | train loss: 0.2509, train acc: 0.910 | val loss: 1.0673, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [28/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.203]\n",
            "Val   [28/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.669]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 28/40 | train loss: 0.2252, train acc: 0.919 | val loss: 1.1076, val acc: 0.701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [29/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.355]\n",
            "Val   [29/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.839]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 29/40 | train loss: 0.2020, train acc: 0.927 | val loss: 1.1364, val acc: 0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [30/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.182]\n",
            "Val   [30/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.488]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 30/40 | train loss: 0.1872, train acc: 0.933 | val loss: 1.1405, val acc: 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [31/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.303]\n",
            "Val   [31/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.537]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 31/40 | train loss: 0.1679, train acc: 0.941 | val loss: 1.2045, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [32/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.338]\n",
            "Val   [32/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.695]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 32/40 | train loss: 0.1628, train acc: 0.943 | val loss: 1.2396, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [33/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.181]\n",
            "Val   [33/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.561]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 33/40 | train loss: 0.1558, train acc: 0.944 | val loss: 1.2523, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [34/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.186]\n",
            "Val   [34/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.848]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 34/40 | train loss: 0.1518, train acc: 0.948 | val loss: 1.2100, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [35/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.112]\n",
            "Val   [35/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.933]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 35/40 | train loss: 0.1280, train acc: 0.955 | val loss: 1.2418, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [36/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.228]\n",
            "Val   [36/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.23]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 36/40 | train loss: 0.1276, train acc: 0.956 | val loss: 1.2913, val acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [37/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.109]\n",
            "Val   [37/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.603]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 37/40 | train loss: 0.1123, train acc: 0.960 | val loss: 1.3115, val acc: 0.715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [38/40]: 100%|█████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.0777]\n",
            "Val   [38/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.443]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 38/40 | train loss: 0.1221, train acc: 0.956 | val loss: 1.2975, val acc: 0.704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [39/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.15]\n",
            "Val   [39/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.835]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 39/40 | train loss: 0.1096, train acc: 0.961 | val loss: 1.3367, val acc: 0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [40/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.171]\n",
            "Val   [40/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.766]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 40/40 | train loss: 0.1151, train acc: 0.959 | val loss: 1.3505, val acc: 0.714\n",
            "\n",
            "-------------------- [cifar10] Experiment: NonlinearTPA_K --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/40]: 100%|█████████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=1.4]\n",
            "Val   [1/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=1.45]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/40 | train loss: 1.7571, train acc: 0.342 | val loss: 1.5801, val acc: 0.423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=1.48]\n",
            "Val   [2/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.27]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/40 | train loss: 1.4870, train acc: 0.457 | val loss: 1.4041, val acc: 0.493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=1.48]\n",
            "Val   [3/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=1.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/40 | train loss: 1.3467, train acc: 0.510 | val loss: 1.3414, val acc: 0.517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/40]: 100%|████████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=1.21]\n",
            "Val   [4/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.29]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/40 | train loss: 1.2489, train acc: 0.548 | val loss: 1.2673, val acc: 0.543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.889]\n",
            "Val   [5/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.16]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/40 | train loss: 1.1735, train acc: 0.576 | val loss: 1.1984, val acc: 0.568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/40]: 100%|███████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.927]\n",
            "Val   [6/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.847]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/40 | train loss: 1.0957, train acc: 0.607 | val loss: 1.0985, val acc: 0.612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.879]\n",
            "Val   [7/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/40 | train loss: 1.0318, train acc: 0.631 | val loss: 1.0854, val acc: 0.610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.88]\n",
            "Val   [8/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.807]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/40 | train loss: 0.9759, train acc: 0.650 | val loss: 1.0129, val acc: 0.639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.885]\n",
            "Val   [9/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.675]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/40 | train loss: 0.9295, train acc: 0.668 | val loss: 0.9725, val acc: 0.650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.92]\n",
            "Val   [10/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.948]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/40 | train loss: 0.8892, train acc: 0.682 | val loss: 0.9723, val acc: 0.648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.789]\n",
            "Val   [11/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.679]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/40 | train loss: 0.8419, train acc: 0.697 | val loss: 0.9567, val acc: 0.662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.709]\n",
            "Val   [12/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.649]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/40 | train loss: 0.8000, train acc: 0.715 | val loss: 0.9160, val acc: 0.680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.601]\n",
            "Val   [13/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.68]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/40 | train loss: 0.7631, train acc: 0.729 | val loss: 0.9181, val acc: 0.683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.608]\n",
            "Val   [14/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.739]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/40 | train loss: 0.7271, train acc: 0.741 | val loss: 0.9330, val acc: 0.678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.831]\n",
            "Val   [15/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.678]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/40 | train loss: 0.6923, train acc: 0.753 | val loss: 0.9308, val acc: 0.675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.852]\n",
            "Val   [16/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.825]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/40 | train loss: 0.6617, train acc: 0.765 | val loss: 0.8944, val acc: 0.690\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.508]\n",
            "Val   [17/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.483]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/40 | train loss: 0.6188, train acc: 0.779 | val loss: 0.9016, val acc: 0.693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.574]\n",
            "Val   [18/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.603]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/40 | train loss: 0.5920, train acc: 0.790 | val loss: 0.8678, val acc: 0.702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.565]\n",
            "Val   [19/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.728]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/40 | train loss: 0.5599, train acc: 0.799 | val loss: 0.8353, val acc: 0.716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.691]\n",
            "Val   [20/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.636]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/40 | train loss: 0.5256, train acc: 0.812 | val loss: 0.8885, val acc: 0.705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [21/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.495]\n",
            "Val   [21/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.575]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 21/40 | train loss: 0.4912, train acc: 0.826 | val loss: 0.8743, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [22/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.406]\n",
            "Val   [22/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.499]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 22/40 | train loss: 0.4619, train acc: 0.835 | val loss: 0.8908, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [23/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.506]\n",
            "Val   [23/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.749]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 23/40 | train loss: 0.4323, train acc: 0.847 | val loss: 0.9520, val acc: 0.698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [24/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.421]\n",
            "Val   [24/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.537]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 24/40 | train loss: 0.4078, train acc: 0.854 | val loss: 0.9356, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [25/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.472]\n",
            "Val   [25/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.892]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 25/40 | train loss: 0.3745, train acc: 0.865 | val loss: 0.9272, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [26/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.415]\n",
            "Val   [26/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.567]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 26/40 | train loss: 0.3388, train acc: 0.880 | val loss: 0.9827, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [27/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.359]\n",
            "Val   [27/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.675]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 27/40 | train loss: 0.3206, train acc: 0.885 | val loss: 0.9940, val acc: 0.714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [28/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.381]\n",
            "Val   [28/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.45]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 28/40 | train loss: 0.2939, train acc: 0.894 | val loss: 0.9942, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [29/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.346]\n",
            "Val   [29/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.579]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 29/40 | train loss: 0.2655, train acc: 0.905 | val loss: 1.0615, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [30/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.218]\n",
            "Val   [30/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.44]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 30/40 | train loss: 0.2491, train acc: 0.912 | val loss: 1.0272, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [31/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.174]\n",
            "Val   [31/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.512]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 31/40 | train loss: 0.2344, train acc: 0.917 | val loss: 1.0881, val acc: 0.710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [32/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.325]\n",
            "Val   [32/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.913]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 32/40 | train loss: 0.2094, train acc: 0.925 | val loss: 1.1318, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [33/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.291]\n",
            "Val   [33/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.937]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 33/40 | train loss: 0.1949, train acc: 0.931 | val loss: 1.1503, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [34/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.29]\n",
            "Val   [34/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.914]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 34/40 | train loss: 0.1856, train acc: 0.934 | val loss: 1.1875, val acc: 0.713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [35/40]: 100%|██████████████████████████████████| 391/391 [02:47<00:00,  2.34it/s, loss=0.178]\n",
            "Val   [35/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.755]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 35/40 | train loss: 0.1752, train acc: 0.936 | val loss: 1.1923, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [36/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.214]\n",
            "Val   [36/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.614]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 36/40 | train loss: 0.1586, train acc: 0.944 | val loss: 1.1979, val acc: 0.717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [37/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.142]\n",
            "Val   [37/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.319]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 37/40 | train loss: 0.1516, train acc: 0.947 | val loss: 1.2514, val acc: 0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [38/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.132]\n",
            "Val   [38/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.831]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 38/40 | train loss: 0.1506, train acc: 0.948 | val loss: 1.2601, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [39/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.202]\n",
            "Val   [39/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=1.05]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 39/40 | train loss: 0.1368, train acc: 0.951 | val loss: 1.2262, val acc: 0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [40/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.237]\n",
            "Val   [40/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.601]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 40/40 | train loss: 0.1355, train acc: 0.952 | val loss: 1.2645, val acc: 0.706\n",
            "\n",
            "-------------------- [cifar10] Experiment: NonlinearTPA_V --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.62]\n",
            "Val   [1/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=1.27]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/40 | train loss: 1.7810, train acc: 0.332 | val loss: 1.5638, val acc: 0.419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.51]\n",
            "Val   [2/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=1.34]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/40 | train loss: 1.4755, train acc: 0.460 | val loss: 1.4235, val acc: 0.491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.27]\n",
            "Val   [3/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=1.21]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/40 | train loss: 1.3512, train acc: 0.510 | val loss: 1.3180, val acc: 0.524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.16]\n",
            "Val   [4/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/40 | train loss: 1.2605, train acc: 0.545 | val loss: 1.2404, val acc: 0.554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.35]\n",
            "Val   [5/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.703]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/40 | train loss: 1.1717, train acc: 0.581 | val loss: 1.1794, val acc: 0.572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.07]\n",
            "Val   [6/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.934]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/40 | train loss: 1.0996, train acc: 0.605 | val loss: 1.1207, val acc: 0.602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.09]\n",
            "Val   [7/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.731]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/40 | train loss: 1.0419, train acc: 0.625 | val loss: 1.0770, val acc: 0.616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.09]\n",
            "Val   [8/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.737]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/40 | train loss: 0.9827, train acc: 0.648 | val loss: 1.0224, val acc: 0.631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/40]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.02]\n",
            "Val   [9/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.781]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/40 | train loss: 0.9370, train acc: 0.665 | val loss: 0.9962, val acc: 0.641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.03]\n",
            "Val   [10/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.657]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/40 | train loss: 0.8938, train acc: 0.680 | val loss: 0.9613, val acc: 0.656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.95]\n",
            "Val   [11/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.775]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/40 | train loss: 0.8500, train acc: 0.696 | val loss: 0.9365, val acc: 0.665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.718]\n",
            "Val   [12/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.927]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/40 | train loss: 0.8083, train acc: 0.711 | val loss: 0.9381, val acc: 0.661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.766]\n",
            "Val   [13/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.689]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/40 | train loss: 0.7829, train acc: 0.721 | val loss: 0.9397, val acc: 0.663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.564]\n",
            "Val   [14/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=0.798]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/40 | train loss: 0.7428, train acc: 0.735 | val loss: 0.9009, val acc: 0.678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.632]\n",
            "Val   [15/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.25it/s, loss=0.653]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/40 | train loss: 0.7078, train acc: 0.748 | val loss: 0.9300, val acc: 0.674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.73]\n",
            "Val   [16/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.441]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/40 | train loss: 0.6730, train acc: 0.761 | val loss: 0.8906, val acc: 0.687\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.662]\n",
            "Val   [17/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.833]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/40 | train loss: 0.6454, train acc: 0.768 | val loss: 0.9293, val acc: 0.678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.761]\n",
            "Val   [18/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.646]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/40 | train loss: 0.6077, train acc: 0.784 | val loss: 0.8909, val acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.545]\n",
            "Val   [19/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.961]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/40 | train loss: 0.5772, train acc: 0.793 | val loss: 0.9148, val acc: 0.692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=0.536]\n",
            "Val   [20/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.687]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/40 | train loss: 0.5450, train acc: 0.807 | val loss: 0.9206, val acc: 0.698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [21/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.374]\n",
            "Val   [21/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.882]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 21/40 | train loss: 0.5099, train acc: 0.817 | val loss: 0.8887, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [22/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.57]\n",
            "Val   [22/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.584]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 22/40 | train loss: 0.4769, train acc: 0.829 | val loss: 0.9055, val acc: 0.709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [23/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.574]\n",
            "Val   [23/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.679]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 23/40 | train loss: 0.4446, train acc: 0.842 | val loss: 0.9422, val acc: 0.701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [24/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.403]\n",
            "Val   [24/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.604]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 24/40 | train loss: 0.4114, train acc: 0.855 | val loss: 0.9165, val acc: 0.713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [25/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.493]\n",
            "Val   [25/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.786]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 25/40 | train loss: 0.3773, train acc: 0.868 | val loss: 0.9708, val acc: 0.701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [26/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.437]\n",
            "Val   [26/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.627]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 26/40 | train loss: 0.3532, train acc: 0.873 | val loss: 0.9631, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [27/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.392]\n",
            "Val   [27/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.778]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 27/40 | train loss: 0.3319, train acc: 0.882 | val loss: 1.0065, val acc: 0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [28/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.385]\n",
            "Val   [28/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=0.753]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 28/40 | train loss: 0.3034, train acc: 0.891 | val loss: 1.0494, val acc: 0.702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [29/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.16]\n",
            "Val   [29/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=0.638]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 29/40 | train loss: 0.2797, train acc: 0.899 | val loss: 1.0692, val acc: 0.705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [30/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.37]\n",
            "Val   [30/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 30/40 | train loss: 0.2650, train acc: 0.906 | val loss: 1.0764, val acc: 0.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [31/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.359]\n",
            "Val   [31/40]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.7]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 31/40 | train loss: 0.2378, train acc: 0.914 | val loss: 1.1389, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [32/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.354]\n",
            "Val   [32/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.918]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 32/40 | train loss: 0.2240, train acc: 0.920 | val loss: 1.1642, val acc: 0.696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [33/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.186]\n",
            "Val   [33/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.901]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 33/40 | train loss: 0.2132, train acc: 0.924 | val loss: 1.1590, val acc: 0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [34/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.251]\n",
            "Val   [34/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.22]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 34/40 | train loss: 0.1890, train acc: 0.933 | val loss: 1.2036, val acc: 0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [35/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.259]\n",
            "Val   [35/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.25]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 35/40 | train loss: 0.1892, train acc: 0.933 | val loss: 1.2215, val acc: 0.704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [36/40]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.16]\n",
            "Val   [36/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.21]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 36/40 | train loss: 0.1682, train acc: 0.941 | val loss: 1.2379, val acc: 0.705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [37/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.192]\n",
            "Val   [37/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.893]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 37/40 | train loss: 0.1653, train acc: 0.941 | val loss: 1.2614, val acc: 0.694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [38/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.141]\n",
            "Val   [38/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=1.62]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 38/40 | train loss: 0.1565, train acc: 0.944 | val loss: 1.2733, val acc: 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [39/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.219]\n",
            "Val   [39/40]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.25it/s, loss=1.66]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 39/40 | train loss: 0.1381, train acc: 0.951 | val loss: 1.3532, val acc: 0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [40/40]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.168]\n",
            "Val   [40/40]: 100%|████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=0.683]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 40/40 | train loss: 0.1405, train acc: 0.949 | val loss: 1.2685, val acc: 0.707\n",
            "\n",
            "\n",
            "==================== DATASET: cifar100 (epochs=20) ====================\n",
            "[Info] Resolved MHA attn_type = mha\n",
            "\n",
            "-------------------- [cifar100] Experiment: MHA_baseline --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/20]: 100%|████████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=3.47]\n",
            "Val   [1/20]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.68it/s, loss=3.62]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 1/20 | train loss: 4.0273, train acc: 0.080 | val loss: 3.7114, val acc: 0.124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/20]: 100%|████████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=3.38]\n",
            "Val   [2/20]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.58it/s, loss=3.34]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 2/20 | train loss: 3.5347, train acc: 0.154 | val loss: 3.3815, val acc: 0.186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/20]: 100%|████████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=3.21]\n",
            "Val   [3/20]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.69it/s, loss=3.16]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 3/20 | train loss: 3.2327, train acc: 0.207 | val loss: 3.1042, val acc: 0.235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/20]: 100%|████████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=2.82]\n",
            "Val   [4/20]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.68it/s, loss=2.74]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 4/20 | train loss: 2.9714, train acc: 0.257 | val loss: 2.9345, val acc: 0.270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/20]: 100%|████████████████████████████████████| 391/391 [01:31<00:00,  4.30it/s, loss=2.83]\n",
            "Val   [5/20]: 100%|███████████████████████████████████████| 79/79 [00:10<00:00,  7.67it/s, loss=2.7]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 5/20 | train loss: 2.7556, train acc: 0.298 | val loss: 2.7184, val acc: 0.304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/20]: 100%|████████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=2.59]\n",
            "Val   [6/20]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.66it/s, loss=2.53]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 6/20 | train loss: 2.5914, train acc: 0.332 | val loss: 2.6115, val acc: 0.334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/20]: 100%|████████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=2.24]\n",
            "Val   [7/20]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.62it/s, loss=2.61]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 7/20 | train loss: 2.4410, train acc: 0.364 | val loss: 2.5188, val acc: 0.347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/20]: 100%|████████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=2.48]\n",
            "Val   [8/20]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.67it/s, loss=2.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 8/20 | train loss: 2.2989, train acc: 0.394 | val loss: 2.3738, val acc: 0.385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/20]: 100%|████████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=1.99]\n",
            "Val   [9/20]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.63it/s, loss=2.13]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 9/20 | train loss: 2.1806, train acc: 0.419 | val loss: 2.3736, val acc: 0.384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/20]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=1.81]\n",
            "Val   [10/20]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.67it/s, loss=2.17]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 10/20 | train loss: 2.0611, train acc: 0.444 | val loss: 2.3174, val acc: 0.399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/20]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=1.95]\n",
            "Val   [11/20]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.61it/s, loss=1.98]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 11/20 | train loss: 1.9445, train acc: 0.469 | val loss: 2.2967, val acc: 0.400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/20]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=1.73]\n",
            "Val   [12/20]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.69it/s, loss=2.12]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 12/20 | train loss: 1.8078, train acc: 0.502 | val loss: 2.2254, val acc: 0.426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/20]: 100%|████████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=1.5]\n",
            "Val   [13/20]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.68it/s, loss=1.77]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 13/20 | train loss: 1.6770, train acc: 0.533 | val loss: 2.2249, val acc: 0.415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/20]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=1.48]\n",
            "Val   [14/20]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.66it/s, loss=1.92]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 14/20 | train loss: 1.5501, train acc: 0.562 | val loss: 2.2213, val acc: 0.431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/20]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.28it/s, loss=1.39]\n",
            "Val   [15/20]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.67it/s, loss=1.66]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 15/20 | train loss: 1.4082, train acc: 0.597 | val loss: 2.2593, val acc: 0.430\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/20]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=1.55]\n",
            "Val   [16/20]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.66it/s, loss=1.57]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 16/20 | train loss: 1.2562, train acc: 0.635 | val loss: 2.2198, val acc: 0.454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/20]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=1.14]\n",
            "Val   [17/20]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.68it/s, loss=2.02]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 17/20 | train loss: 1.0853, train acc: 0.679 | val loss: 2.3288, val acc: 0.435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/20]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=1.09]\n",
            "Val   [18/20]: 100%|██████████████████████████████████████| 79/79 [00:10<00:00,  7.66it/s, loss=1.7]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 18/20 | train loss: 0.9332, train acc: 0.724 | val loss: 2.3765, val acc: 0.437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/20]: 100%|███████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=1.28]\n",
            "Val   [19/20]: 100%|█████████████████████████████████████| 79/79 [00:10<00:00,  7.64it/s, loss=1.47]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 19/20 | train loss: 0.7680, train acc: 0.771 | val loss: 2.3989, val acc: 0.447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/20]: 100%|██████████████████████████████████| 391/391 [01:31<00:00,  4.29it/s, loss=0.541]\n",
            "Val   [20/20]: 100%|████████████████████████████████████████| 79/79 [00:10<00:00,  7.67it/s, loss=2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mha] Epoch 20/20 | train loss: 0.6016, train acc: 0.819 | val loss: 2.5758, val acc: 0.434\n",
            "\n",
            "-------------------- [cifar100] Experiment: TPA_r1622 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/20]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.62it/s, loss=3.63]\n",
            "Val   [1/20]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=3.49]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 1/20 | train loss: 3.8945, train acc: 0.106 | val loss: 3.5531, val acc: 0.160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/20]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=3.21]\n",
            "Val   [2/20]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=3.32]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 2/20 | train loss: 3.3647, train acc: 0.190 | val loss: 3.2058, val acc: 0.223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/20]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=2.89]\n",
            "Val   [3/20]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.52it/s, loss=2.79]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 3/20 | train loss: 3.0654, train acc: 0.243 | val loss: 2.9772, val acc: 0.272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/20]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=2.85]\n",
            "Val   [4/20]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=2.51]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 4/20 | train loss: 2.8446, train acc: 0.283 | val loss: 2.8082, val acc: 0.300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/20]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=2.53]\n",
            "Val   [5/20]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.53it/s, loss=2.29]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 5/20 | train loss: 2.6346, train acc: 0.325 | val loss: 2.6767, val acc: 0.319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/20]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=2.41]\n",
            "Val   [6/20]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=2.35]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 6/20 | train loss: 2.4680, train acc: 0.358 | val loss: 2.5850, val acc: 0.345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/20]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=2.42]\n",
            "Val   [7/20]: 100%|███████████████████████████████████████| 79/79 [00:17<00:00,  4.53it/s, loss=2.2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 7/20 | train loss: 2.3150, train acc: 0.389 | val loss: 2.5131, val acc: 0.357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/20]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=2.15]\n",
            "Val   [8/20]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.54it/s, loss=2.41]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 8/20 | train loss: 2.1639, train acc: 0.423 | val loss: 2.4909, val acc: 0.367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/20]: 100%|████████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=2.21]\n",
            "Val   [9/20]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.53it/s, loss=1.88]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 9/20 | train loss: 2.0260, train acc: 0.451 | val loss: 2.4039, val acc: 0.385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/20]: 100%|███████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=1.94]\n",
            "Val   [10/20]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=2.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 10/20 | train loss: 1.8809, train acc: 0.487 | val loss: 2.4492, val acc: 0.381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/20]: 100%|███████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=2.21]\n",
            "Val   [11/20]: 100%|██████████████████████████████████████| 79/79 [00:17<00:00,  4.53it/s, loss=1.9]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 11/20 | train loss: 1.7238, train acc: 0.522 | val loss: 2.5022, val acc: 0.380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/20]: 100%|███████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=1.86]\n",
            "Val   [12/20]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.52it/s, loss=1.94]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 12/20 | train loss: 1.5666, train acc: 0.557 | val loss: 2.4439, val acc: 0.388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/20]: 100%|███████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=1.44]\n",
            "Val   [13/20]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=2.21]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 13/20 | train loss: 1.3834, train acc: 0.608 | val loss: 2.4730, val acc: 0.400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/20]: 100%|███████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=1.16]\n",
            "Val   [14/20]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.52it/s, loss=2.43]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 14/20 | train loss: 1.2049, train acc: 0.653 | val loss: 2.5521, val acc: 0.392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/20]: 100%|███████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=1.21]\n",
            "Val   [15/20]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.50it/s, loss=2.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 15/20 | train loss: 1.0423, train acc: 0.693 | val loss: 2.7073, val acc: 0.381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/20]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.793]\n",
            "Val   [16/20]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=2.11]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 16/20 | train loss: 0.8576, train acc: 0.748 | val loss: 2.7269, val acc: 0.389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/20]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.827]\n",
            "Val   [17/20]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=2.25]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 17/20 | train loss: 0.6977, train acc: 0.792 | val loss: 2.8811, val acc: 0.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/20]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.712]\n",
            "Val   [18/20]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.50it/s, loss=2.78]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 18/20 | train loss: 0.5556, train acc: 0.838 | val loss: 3.0665, val acc: 0.374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/20]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.548]\n",
            "Val   [19/20]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=2.36]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 19/20 | train loss: 0.4285, train acc: 0.874 | val loss: 3.1458, val acc: 0.385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/20]: 100%|██████████████████████████████████| 391/391 [02:29<00:00,  2.61it/s, loss=0.338]\n",
            "Val   [20/20]: 100%|█████████████████████████████████████| 79/79 [00:17<00:00,  4.51it/s, loss=3.07]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tpa] Epoch 20/20 | train loss: 0.3548, train acc: 0.895 | val loss: 3.3161, val acc: 0.381\n",
            "\n",
            "-------------------- [cifar100] Experiment: NonlinearTPA_KV --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/20]: 100%|████████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=3.55]\n",
            "Val   [1/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=3.61]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/20 | train loss: 3.9854, train acc: 0.089 | val loss: 3.6425, val acc: 0.136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/20]: 100%|████████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=3.47]\n",
            "Val   [2/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=3.33]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/20 | train loss: 3.4576, train acc: 0.169 | val loss: 3.3508, val acc: 0.196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/20]: 100%|████████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=3.15]\n",
            "Val   [3/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=3.11]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/20 | train loss: 3.1766, train acc: 0.219 | val loss: 3.0874, val acc: 0.241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/20]: 100%|█████████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=2.9]\n",
            "Val   [4/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=2.66]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/20 | train loss: 2.9211, train acc: 0.268 | val loss: 2.8589, val acc: 0.287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/20]: 100%|████████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=2.74]\n",
            "Val   [5/20]: 100%|███████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=2.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/20 | train loss: 2.7185, train acc: 0.307 | val loss: 2.7381, val acc: 0.313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/20]: 100%|████████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=2.54]\n",
            "Val   [6/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/20 | train loss: 2.5556, train acc: 0.340 | val loss: 2.5971, val acc: 0.335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/20]: 100%|█████████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=2.4]\n",
            "Val   [7/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=2.38]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/20 | train loss: 2.4234, train acc: 0.368 | val loss: 2.5251, val acc: 0.354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/20]: 100%|████████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=2.06]\n",
            "Val   [8/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.31]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/20 | train loss: 2.2981, train acc: 0.392 | val loss: 2.4188, val acc: 0.376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/20]: 100%|████████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=1.95]\n",
            "Val   [9/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=2.26]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/20 | train loss: 2.1660, train acc: 0.419 | val loss: 2.3876, val acc: 0.383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/20]: 100%|███████████████████████████████████| 391/391 [02:48<00:00,  2.33it/s, loss=1.83]\n",
            "Val   [10/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=1.96]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/20 | train loss: 2.0566, train acc: 0.443 | val loss: 2.3409, val acc: 0.388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/20]: 100%|███████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=1.94]\n",
            "Val   [11/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.92]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/20 | train loss: 1.9356, train acc: 0.473 | val loss: 2.3416, val acc: 0.392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/20]: 100%|███████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=2.14]\n",
            "Val   [12/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=2.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/20 | train loss: 1.8187, train acc: 0.499 | val loss: 2.3110, val acc: 0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/20]: 100%|███████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=1.58]\n",
            "Val   [13/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=2.12]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/20 | train loss: 1.6856, train acc: 0.530 | val loss: 2.3024, val acc: 0.411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/20]: 100%|███████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=1.43]\n",
            "Val   [14/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=1.74]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/20 | train loss: 1.5607, train acc: 0.559 | val loss: 2.3097, val acc: 0.417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/20]: 100%|███████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=1.63]\n",
            "Val   [15/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=1.61]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/20 | train loss: 1.4049, train acc: 0.601 | val loss: 2.3671, val acc: 0.410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/20]: 100%|███████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=1.33]\n",
            "Val   [16/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=2.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/20 | train loss: 1.2476, train acc: 0.638 | val loss: 2.4142, val acc: 0.416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/20]: 100%|███████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=1.32]\n",
            "Val   [17/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=2.14]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/20 | train loss: 1.0944, train acc: 0.678 | val loss: 2.4496, val acc: 0.417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/20]: 100%|███████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=1.09]\n",
            "Val   [18/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=1.82]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/20 | train loss: 0.9202, train acc: 0.727 | val loss: 2.5886, val acc: 0.408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/20]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.918]\n",
            "Val   [19/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=1.68]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/20 | train loss: 0.7734, train acc: 0.767 | val loss: 2.6579, val acc: 0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/20]: 100%|██████████████████████████████████| 391/391 [02:48<00:00,  2.32it/s, loss=0.582]\n",
            "Val   [20/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=2.08]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/20 | train loss: 0.6268, train acc: 0.811 | val loss: 2.7350, val acc: 0.417\n",
            "\n",
            "-------------------- [cifar100] Experiment: NonlinearTPA_KV_shared --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=3.68]\n",
            "Val   [1/20]: 100%|███████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=3.7]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/20 | train loss: 4.0021, train acc: 0.087 | val loss: 3.6820, val acc: 0.130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/20]: 100%|█████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.9]\n",
            "Val   [2/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=3.48]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/20 | train loss: 3.4853, train acc: 0.164 | val loss: 3.3531, val acc: 0.186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.97]\n",
            "Val   [3/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=3.17]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/20 | train loss: 3.1738, train acc: 0.220 | val loss: 3.0920, val acc: 0.240\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.64]\n",
            "Val   [4/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=2.71]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/20 | train loss: 2.9149, train acc: 0.268 | val loss: 2.8712, val acc: 0.279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.79]\n",
            "Val   [5/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=2.61]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/20 | train loss: 2.7240, train acc: 0.306 | val loss: 2.6960, val acc: 0.313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.98]\n",
            "Val   [6/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.01it/s, loss=2.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/20 | train loss: 2.5608, train acc: 0.339 | val loss: 2.6370, val acc: 0.326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.44]\n",
            "Val   [7/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.00it/s, loss=2.42]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/20 | train loss: 2.4225, train acc: 0.368 | val loss: 2.5660, val acc: 0.341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.31]\n",
            "Val   [8/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  3.99it/s, loss=2.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/20 | train loss: 2.2901, train acc: 0.395 | val loss: 2.4445, val acc: 0.367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.14it/s, loss=2.14]\n",
            "Val   [9/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  3.99it/s, loss=2.25]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/20 | train loss: 2.1837, train acc: 0.417 | val loss: 2.4603, val acc: 0.365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.3]\n",
            "Val   [10/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.00it/s, loss=2.41]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/20 | train loss: 2.0482, train acc: 0.446 | val loss: 2.3961, val acc: 0.387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.67]\n",
            "Val   [11/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.99it/s, loss=2.21]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/20 | train loss: 1.9315, train acc: 0.475 | val loss: 2.3615, val acc: 0.391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.08]\n",
            "Val   [12/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.99it/s, loss=1.98]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/20 | train loss: 1.8060, train acc: 0.504 | val loss: 2.3537, val acc: 0.398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.64]\n",
            "Val   [13/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=1.99]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/20 | train loss: 1.6880, train acc: 0.532 | val loss: 2.3120, val acc: 0.413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.87]\n",
            "Val   [14/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.00it/s, loss=1.79]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/20 | train loss: 1.5475, train acc: 0.566 | val loss: 2.3375, val acc: 0.410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.47]\n",
            "Val   [15/20]: 100%|█████████████████████████████████████| 79/79 [00:20<00:00,  3.86it/s, loss=2.04]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/20 | train loss: 1.4010, train acc: 0.601 | val loss: 2.4316, val acc: 0.401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.67]\n",
            "Val   [16/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.97it/s, loss=2.34]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/20 | train loss: 1.2491, train acc: 0.639 | val loss: 2.5211, val acc: 0.398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.31]\n",
            "Val   [17/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=2.24]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/20 | train loss: 1.0908, train acc: 0.681 | val loss: 2.5393, val acc: 0.410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.26]\n",
            "Val   [18/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.99it/s, loss=2.36]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/20 | train loss: 0.9231, train acc: 0.726 | val loss: 2.6393, val acc: 0.404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/20]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.763]\n",
            "Val   [19/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=2.38]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/20 | train loss: 0.7837, train acc: 0.766 | val loss: 2.7022, val acc: 0.411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/20]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.778]\n",
            "Val   [20/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  3.98it/s, loss=2.81]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/20 | train loss: 0.6227, train acc: 0.812 | val loss: 2.8056, val acc: 0.410\n",
            "\n",
            "-------------------- [cifar100] Experiment: NonlinearTPA_HW_KV --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=3.72]\n",
            "Val   [1/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=3.78]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 1/20 | train loss: 4.0307, train acc: 0.080 | val loss: 3.7232, val acc: 0.114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=3.34]\n",
            "Val   [2/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=3.37]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 2/20 | train loss: 3.5016, train acc: 0.161 | val loss: 3.3193, val acc: 0.196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=3.04]\n",
            "Val   [3/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=3.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 3/20 | train loss: 3.2000, train acc: 0.215 | val loss: 3.0573, val acc: 0.243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.72]\n",
            "Val   [4/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=2.83]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 4/20 | train loss: 2.9264, train acc: 0.267 | val loss: 2.8491, val acc: 0.287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.65]\n",
            "Val   [5/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=2.68]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 5/20 | train loss: 2.7109, train acc: 0.308 | val loss: 2.6934, val acc: 0.315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.47]\n",
            "Val   [6/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=2.36]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 6/20 | train loss: 2.5518, train acc: 0.341 | val loss: 2.5513, val acc: 0.343\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.46]\n",
            "Val   [7/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=2.45]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 7/20 | train loss: 2.4198, train acc: 0.367 | val loss: 2.5461, val acc: 0.348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.13]\n",
            "Val   [8/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=2.32]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 8/20 | train loss: 2.2977, train acc: 0.394 | val loss: 2.4326, val acc: 0.371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=2.19]\n",
            "Val   [9/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=2.33]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 9/20 | train loss: 2.1712, train acc: 0.422 | val loss: 2.4057, val acc: 0.377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/20]: 100%|████████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.9]\n",
            "Val   [10/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=2.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 10/20 | train loss: 2.0542, train acc: 0.447 | val loss: 2.3679, val acc: 0.385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.86]\n",
            "Val   [11/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=2.31]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 11/20 | train loss: 1.9363, train acc: 0.471 | val loss: 2.3577, val acc: 0.391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.95]\n",
            "Val   [12/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=2.39]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 12/20 | train loss: 1.8124, train acc: 0.501 | val loss: 2.3073, val acc: 0.402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.59]\n",
            "Val   [13/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=2.11]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 13/20 | train loss: 1.6815, train acc: 0.531 | val loss: 2.3139, val acc: 0.411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.62]\n",
            "Val   [14/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.12it/s, loss=2.11]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 14/20 | train loss: 1.5373, train acc: 0.564 | val loss: 2.3262, val acc: 0.413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.56]\n",
            "Val   [15/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=2.79]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 15/20 | train loss: 1.3808, train acc: 0.605 | val loss: 2.3712, val acc: 0.416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.44]\n",
            "Val   [16/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=2.18]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 16/20 | train loss: 1.2275, train acc: 0.644 | val loss: 2.4443, val acc: 0.412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.02]\n",
            "Val   [17/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=2.44]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 17/20 | train loss: 1.0504, train acc: 0.691 | val loss: 2.5160, val acc: 0.413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/20]: 100%|███████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=1.18]\n",
            "Val   [18/20]: 100%|██████████████████████████████████████| 79/79 [00:19<00:00,  4.15it/s, loss=2.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 18/20 | train loss: 0.8909, train acc: 0.734 | val loss: 2.5744, val acc: 0.419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/20]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.721]\n",
            "Val   [19/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=2.24]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 19/20 | train loss: 0.7045, train acc: 0.789 | val loss: 2.7120, val acc: 0.414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/20]: 100%|██████████████████████████████████| 391/391 [03:03<00:00,  2.13it/s, loss=0.618]\n",
            "Val   [20/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.14it/s, loss=2.49]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 20/20 | train loss: 0.5605, train acc: 0.833 | val loss: 2.7930, val acc: 0.417\n",
            "\n",
            "-------------------- [cifar100] Experiment: NonlinearTPA_HW_KV --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/20]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=3.55]\n",
            "Val   [1/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=3.58]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 1/20 | train loss: 4.0312, train acc: 0.082 | val loss: 3.6850, val acc: 0.134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/20]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=3.05]\n",
            "Val   [2/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=3.36]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 2/20 | train loss: 3.4667, train acc: 0.167 | val loss: 3.3290, val acc: 0.195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/20]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=2.77]\n",
            "Val   [3/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=3.23]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 3/20 | train loss: 3.1733, train acc: 0.219 | val loss: 3.0819, val acc: 0.236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/20]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=2.64]\n",
            "Val   [4/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=2.86]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 4/20 | train loss: 2.9289, train acc: 0.266 | val loss: 2.8689, val acc: 0.283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/20]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=2.58]\n",
            "Val   [5/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=2.71]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 5/20 | train loss: 2.7355, train acc: 0.304 | val loss: 2.7253, val acc: 0.311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/20]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=2.69]\n",
            "Val   [6/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=2.44]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 6/20 | train loss: 2.5840, train acc: 0.334 | val loss: 2.6598, val acc: 0.325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/20]: 100%|█████████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=2.3]\n",
            "Val   [7/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=2.69]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 7/20 | train loss: 2.4411, train acc: 0.364 | val loss: 2.6441, val acc: 0.328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/20]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=1.93]\n",
            "Val   [8/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=2.85]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 8/20 | train loss: 2.3142, train acc: 0.389 | val loss: 2.5606, val acc: 0.348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/20]: 100%|█████████████████████████████████████| 391/391 [03:00<00:00,  2.17it/s, loss=2.3]\n",
            "Val   [9/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=2.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 9/20 | train loss: 2.2018, train acc: 0.413 | val loss: 2.4928, val acc: 0.362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/20]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=1.8]\n",
            "Val   [10/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=2.32]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 10/20 | train loss: 2.0803, train acc: 0.441 | val loss: 2.3736, val acc: 0.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/20]: 100%|███████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=2.01]\n",
            "Val   [11/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=2.56]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 11/20 | train loss: 1.9553, train acc: 0.469 | val loss: 2.3993, val acc: 0.392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/20]: 100%|███████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=1.72]\n",
            "Val   [12/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=2.27]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 12/20 | train loss: 1.8229, train acc: 0.498 | val loss: 2.3320, val acc: 0.406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/20]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=1.8]\n",
            "Val   [13/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=2.33]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 13/20 | train loss: 1.6893, train acc: 0.532 | val loss: 2.3690, val acc: 0.404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/20]: 100%|████████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=1.7]\n",
            "Val   [14/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=2.69]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 14/20 | train loss: 1.5476, train acc: 0.563 | val loss: 2.4290, val acc: 0.401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/20]: 100%|███████████████████████████████████| 391/391 [02:59<00:00,  2.18it/s, loss=1.37]\n",
            "Val   [15/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=2.62]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 15/20 | train loss: 1.3925, train acc: 0.601 | val loss: 2.4365, val acc: 0.410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/20]: 100%|███████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=1.03]\n",
            "Val   [16/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=2.57]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 16/20 | train loss: 1.2307, train acc: 0.644 | val loss: 2.5189, val acc: 0.402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/20]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=0.969]\n",
            "Val   [17/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=2.33]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 17/20 | train loss: 1.0716, train acc: 0.682 | val loss: 2.6130, val acc: 0.402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/20]: 100%|███████████████████████████████████| 391/391 [03:00<00:00,  2.17it/s, loss=1.12]\n",
            "Val   [18/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=2.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 18/20 | train loss: 0.8990, train acc: 0.736 | val loss: 2.6616, val acc: 0.405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/20]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=0.923]\n",
            "Val   [19/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=2.9]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 19/20 | train loss: 0.7491, train acc: 0.776 | val loss: 2.8037, val acc: 0.395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/20]: 100%|██████████████████████████████████| 391/391 [02:59<00:00,  2.17it/s, loss=0.555]\n",
            "Val   [20/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=3.04]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 20/20 | train loss: 0.5910, train acc: 0.824 | val loss: 2.9265, val acc: 0.398\n",
            "\n",
            "-------------------- [cifar100] Experiment: NonlinearTPA_HW_KV_shared --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/20]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=3.67]\n",
            "Val   [1/20]: 100%|███████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=3.6]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 1/20 | train loss: 4.0204, train acc: 0.084 | val loss: 3.6758, val acc: 0.132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/20]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=3.43]\n",
            "Val   [2/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=3.36]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 2/20 | train loss: 3.4971, train acc: 0.163 | val loss: 3.3427, val acc: 0.195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/20]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=3.47]\n",
            "Val   [3/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=3.52]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 3/20 | train loss: 3.2082, train acc: 0.214 | val loss: 3.1625, val acc: 0.224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/20]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=2.74]\n",
            "Val   [4/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.74]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 4/20 | train loss: 2.9670, train acc: 0.260 | val loss: 2.9014, val acc: 0.275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/20]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=2.52]\n",
            "Val   [5/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.57]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 5/20 | train loss: 2.7633, train acc: 0.296 | val loss: 2.7234, val acc: 0.314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/20]: 100%|█████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=2.2]\n",
            "Val   [6/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=2.45]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 6/20 | train loss: 2.5885, train acc: 0.331 | val loss: 2.6232, val acc: 0.329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/20]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=2.22]\n",
            "Val   [7/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=2.51]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 7/20 | train loss: 2.4471, train acc: 0.361 | val loss: 2.5775, val acc: 0.346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/20]: 100%|████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=2.12]\n",
            "Val   [8/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.20it/s, loss=1.99]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 8/20 | train loss: 2.3128, train acc: 0.389 | val loss: 2.4757, val acc: 0.357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/20]: 100%|█████████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=2.5]\n",
            "Val   [9/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.18]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 9/20 | train loss: 2.1876, train acc: 0.415 | val loss: 2.4118, val acc: 0.378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/20]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.84]\n",
            "Val   [10/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 10/20 | train loss: 2.0652, train acc: 0.443 | val loss: 2.3927, val acc: 0.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/20]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.91]\n",
            "Val   [11/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=2.37]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 11/20 | train loss: 1.9385, train acc: 0.473 | val loss: 2.3446, val acc: 0.395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/20]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=2.12]\n",
            "Val   [12/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=2.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 12/20 | train loss: 1.8071, train acc: 0.503 | val loss: 2.3814, val acc: 0.396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/20]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.74]\n",
            "Val   [13/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=1.94]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 13/20 | train loss: 1.6762, train acc: 0.532 | val loss: 2.3621, val acc: 0.402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/20]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.59]\n",
            "Val   [14/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.35]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 14/20 | train loss: 1.5351, train acc: 0.564 | val loss: 2.3620, val acc: 0.411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/20]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.91]\n",
            "Val   [15/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.65]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 15/20 | train loss: 1.3881, train acc: 0.601 | val loss: 2.3776, val acc: 0.411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/20]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.29]\n",
            "Val   [16/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.16]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 16/20 | train loss: 1.2348, train acc: 0.642 | val loss: 2.4528, val acc: 0.411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/20]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.11]\n",
            "Val   [17/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=2.59]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 17/20 | train loss: 1.0666, train acc: 0.686 | val loss: 2.5375, val acc: 0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/20]: 100%|███████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=1.13]\n",
            "Val   [18/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=2.69]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 18/20 | train loss: 0.9048, train acc: 0.730 | val loss: 2.6134, val acc: 0.407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/20]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.748]\n",
            "Val   [19/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=2.61]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 19/20 | train loss: 0.7444, train acc: 0.776 | val loss: 2.7174, val acc: 0.408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/20]: 100%|██████████████████████████████████| 391/391 [03:02<00:00,  2.14it/s, loss=0.721]\n",
            "Val   [20/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.3]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[headwise_nonlinear_tpa] Epoch 20/20 | train loss: 0.5989, train acc: 0.820 | val loss: 2.8484, val acc: 0.409\n",
            "\n",
            "-------------------- [cifar100] Experiment: NonlinearTPA_QKV --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/20]: 100%|████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=3.52]\n",
            "Val   [1/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=3.71]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/20 | train loss: 4.0331, train acc: 0.082 | val loss: 3.6597, val acc: 0.135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/20]: 100%|████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=3.21]\n",
            "Val   [2/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=3.24]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/20 | train loss: 3.4920, train acc: 0.166 | val loss: 3.3724, val acc: 0.187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/20]: 100%|████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=3.09]\n",
            "Val   [3/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=3.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/20 | train loss: 3.1931, train acc: 0.219 | val loss: 3.0907, val acc: 0.241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/20]: 100%|████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=3.01]\n",
            "Val   [4/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=2.83]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/20 | train loss: 2.9521, train acc: 0.264 | val loss: 2.9001, val acc: 0.274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/20]: 100%|████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=2.32]\n",
            "Val   [5/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=2.74]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/20 | train loss: 2.7670, train acc: 0.297 | val loss: 2.7569, val acc: 0.309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/20]: 100%|████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=2.63]\n",
            "Val   [6/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=2.45]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/20 | train loss: 2.5995, train acc: 0.330 | val loss: 2.6684, val acc: 0.317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/20]: 100%|████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=2.19]\n",
            "Val   [7/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=2.31]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/20 | train loss: 2.4588, train acc: 0.360 | val loss: 2.5391, val acc: 0.345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/20]: 100%|████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=2.67]\n",
            "Val   [8/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.16it/s, loss=2.36]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/20 | train loss: 2.3369, train acc: 0.386 | val loss: 2.4945, val acc: 0.355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/20]: 100%|████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=2.33]\n",
            "Val   [9/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.19it/s, loss=2.35]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/20 | train loss: 2.2162, train acc: 0.409 | val loss: 2.3914, val acc: 0.384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/20]: 100%|███████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=2.22]\n",
            "Val   [10/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=2.16]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/20 | train loss: 2.0852, train acc: 0.439 | val loss: 2.3964, val acc: 0.383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/20]: 100%|███████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=1.84]\n",
            "Val   [11/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.16it/s, loss=1.86]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/20 | train loss: 1.9715, train acc: 0.463 | val loss: 2.3656, val acc: 0.382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/20]: 100%|██████████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=2]\n",
            "Val   [12/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=2.26]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/20 | train loss: 1.8399, train acc: 0.495 | val loss: 2.3148, val acc: 0.406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/20]: 100%|███████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=1.67]\n",
            "Val   [13/20]: 100%|█████████████████████████████████████| 79/79 [00:19<00:00,  4.13it/s, loss=1.93]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/20 | train loss: 1.7058, train acc: 0.525 | val loss: 2.3538, val acc: 0.399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/20]: 100%|███████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=1.77]\n",
            "Val   [14/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.17it/s, loss=2.05]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/20 | train loss: 1.5607, train acc: 0.559 | val loss: 2.3586, val acc: 0.405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/20]: 100%|███████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=1.64]\n",
            "Val   [15/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.29]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/20 | train loss: 1.4031, train acc: 0.599 | val loss: 2.3708, val acc: 0.415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/20]: 100%|███████████████████████████████████| 391/391 [02:50<00:00,  2.30it/s, loss=1.44]\n",
            "Val   [16/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.33]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/20 | train loss: 1.2376, train acc: 0.642 | val loss: 2.4507, val acc: 0.409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/20]: 100%|███████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=1.51]\n",
            "Val   [17/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.08]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/20 | train loss: 1.0625, train acc: 0.687 | val loss: 2.5159, val acc: 0.410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/20]: 100%|███████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=0.82]\n",
            "Val   [18/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=1.99]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/20 | train loss: 0.8796, train acc: 0.738 | val loss: 2.6119, val acc: 0.407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/20]: 100%|██████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=0.719]\n",
            "Val   [19/20]: 100%|████████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/20 | train loss: 0.6942, train acc: 0.792 | val loss: 2.7544, val acc: 0.399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/20]: 100%|██████████████████████████████████| 391/391 [02:49<00:00,  2.30it/s, loss=0.662]\n",
            "Val   [20/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.18it/s, loss=2.38]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/20 | train loss: 0.5520, train acc: 0.835 | val loss: 2.8719, val acc: 0.403\n",
            "\n",
            "-------------------- [cifar100] Experiment: NonlinearTPA_Q --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=3.68]\n",
            "Val   [1/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=3.73]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/20 | train loss: 3.8931, train acc: 0.105 | val loss: 3.5973, val acc: 0.149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/20]: 100%|████████████████████████████████████| 391/391 [02:45<00:00,  2.36it/s, loss=2.92]\n",
            "Val   [2/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=3.37]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/20 | train loss: 3.3744, train acc: 0.188 | val loss: 3.2804, val acc: 0.203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=3.04]\n",
            "Val   [3/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=3.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/20 | train loss: 3.0975, train acc: 0.237 | val loss: 3.0056, val acc: 0.261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/20]: 100%|████████████████████████████████████| 391/391 [02:45<00:00,  2.36it/s, loss=2.93]\n",
            "Val   [4/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.78]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/20 | train loss: 2.8469, train acc: 0.283 | val loss: 2.8074, val acc: 0.299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.63]\n",
            "Val   [5/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.58]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/20 | train loss: 2.6388, train acc: 0.324 | val loss: 2.6774, val acc: 0.317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.37]\n",
            "Val   [6/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.31]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/20 | train loss: 2.4682, train acc: 0.357 | val loss: 2.5503, val acc: 0.343\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/20]: 100%|█████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.6]\n",
            "Val   [7/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.49]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/20 | train loss: 2.3198, train acc: 0.388 | val loss: 2.5130, val acc: 0.357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.23]\n",
            "Val   [8/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.28]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/20 | train loss: 2.1816, train acc: 0.416 | val loss: 2.4242, val acc: 0.378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.72]\n",
            "Val   [9/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.25it/s, loss=2.17]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/20 | train loss: 2.0491, train acc: 0.448 | val loss: 2.3924, val acc: 0.385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.87]\n",
            "Val   [10/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.51]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/20 | train loss: 1.9083, train acc: 0.479 | val loss: 2.3942, val acc: 0.387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.85]\n",
            "Val   [11/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.25]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/20 | train loss: 1.7793, train acc: 0.509 | val loss: 2.3755, val acc: 0.398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.66]\n",
            "Val   [12/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.44]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/20 | train loss: 1.6288, train acc: 0.547 | val loss: 2.4173, val acc: 0.397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.78]\n",
            "Val   [13/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.5]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/20 | train loss: 1.4795, train acc: 0.585 | val loss: 2.4122, val acc: 0.407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.15]\n",
            "Val   [14/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.09]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/20 | train loss: 1.3283, train acc: 0.619 | val loss: 2.4869, val acc: 0.399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.16]\n",
            "Val   [15/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.42]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/20 | train loss: 1.1617, train acc: 0.665 | val loss: 2.5184, val acc: 0.404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.06]\n",
            "Val   [16/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.25it/s, loss=2.13]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/20 | train loss: 1.0016, train acc: 0.707 | val loss: 2.5999, val acc: 0.405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/20]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.742]\n",
            "Val   [17/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.49]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/20 | train loss: 0.8285, train acc: 0.755 | val loss: 2.6900, val acc: 0.403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/20]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.698]\n",
            "Val   [18/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.47]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/20 | train loss: 0.6943, train acc: 0.794 | val loss: 2.7947, val acc: 0.402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/20]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.768]\n",
            "Val   [19/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.64]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/20 | train loss: 0.5469, train acc: 0.838 | val loss: 2.9558, val acc: 0.388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/20]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.432]\n",
            "Val   [20/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=3.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/20 | train loss: 0.4347, train acc: 0.873 | val loss: 3.0438, val acc: 0.396\n",
            "\n",
            "-------------------- [cifar100] Experiment: NonlinearTPA_K --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=3.46]\n",
            "Val   [1/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=3.56]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/20 | train loss: 3.9049, train acc: 0.104 | val loss: 3.5674, val acc: 0.156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=3.37]\n",
            "Val   [2/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=3.26]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/20 | train loss: 3.3861, train acc: 0.185 | val loss: 3.2702, val acc: 0.209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.93]\n",
            "Val   [3/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=3.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/20 | train loss: 3.0846, train acc: 0.239 | val loss: 3.0235, val acc: 0.257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.64]\n",
            "Val   [4/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.25it/s, loss=3.08]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/20 | train loss: 2.8456, train acc: 0.281 | val loss: 2.8357, val acc: 0.294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.59]\n",
            "Val   [5/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=2.63]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/20 | train loss: 2.6552, train acc: 0.319 | val loss: 2.7412, val acc: 0.309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.41]\n",
            "Val   [6/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.62]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/20 | train loss: 2.4867, train acc: 0.355 | val loss: 2.5728, val acc: 0.341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/20]: 100%|█████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.6]\n",
            "Val   [7/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.25it/s, loss=2.67]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/20 | train loss: 2.3458, train acc: 0.384 | val loss: 2.5388, val acc: 0.351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.01]\n",
            "Val   [8/20]: 100%|███████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.6]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/20 | train loss: 2.2042, train acc: 0.415 | val loss: 2.5354, val acc: 0.353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.21]\n",
            "Val   [9/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.25it/s, loss=2.25]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/20 | train loss: 2.0758, train acc: 0.442 | val loss: 2.4451, val acc: 0.374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.06]\n",
            "Val   [10/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=2.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/20 | train loss: 1.9397, train acc: 0.471 | val loss: 2.4444, val acc: 0.380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.34it/s, loss=1.82]\n",
            "Val   [11/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.21]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/20 | train loss: 1.8098, train acc: 0.504 | val loss: 2.4373, val acc: 0.380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.7]\n",
            "Val   [12/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.39]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/20 | train loss: 1.6654, train acc: 0.535 | val loss: 2.3930, val acc: 0.401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.51]\n",
            "Val   [13/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=2.11]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/20 | train loss: 1.5129, train acc: 0.572 | val loss: 2.4550, val acc: 0.394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.51]\n",
            "Val   [14/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=1.97]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/20 | train loss: 1.3633, train acc: 0.610 | val loss: 2.4886, val acc: 0.395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.29]\n",
            "Val   [15/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=1.75]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/20 | train loss: 1.2008, train acc: 0.653 | val loss: 2.5428, val acc: 0.393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.33]\n",
            "Val   [16/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.21]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/20 | train loss: 1.0454, train acc: 0.694 | val loss: 2.6135, val acc: 0.393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.02]\n",
            "Val   [17/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=1.38]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/20 | train loss: 0.8631, train acc: 0.746 | val loss: 2.7241, val acc: 0.391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/20]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.855]\n",
            "Val   [18/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/20 | train loss: 0.7033, train acc: 0.792 | val loss: 2.8105, val acc: 0.402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.94]\n",
            "Val   [19/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=1.99]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/20 | train loss: 0.5738, train acc: 0.831 | val loss: 3.0088, val acc: 0.383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/20]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.801]\n",
            "Val   [20/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.21it/s, loss=2.03]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/20 | train loss: 0.4722, train acc: 0.860 | val loss: 3.1157, val acc: 0.391\n",
            "\n",
            "-------------------- [cifar100] Experiment: NonlinearTPA_V --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [1/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=3.59]\n",
            "Val   [1/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=3.74]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 1/20 | train loss: 3.9856, train acc: 0.090 | val loss: 3.6581, val acc: 0.139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [2/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=3.04]\n",
            "Val   [2/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=3.45]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 2/20 | train loss: 3.4666, train acc: 0.168 | val loss: 3.3087, val acc: 0.201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [3/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.89]\n",
            "Val   [3/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.25it/s, loss=3.14]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 3/20 | train loss: 3.1839, train acc: 0.220 | val loss: 3.0729, val acc: 0.241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [4/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.82]\n",
            "Val   [4/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.62]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 4/20 | train loss: 2.9514, train acc: 0.262 | val loss: 2.8821, val acc: 0.280\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [5/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.29]\n",
            "Val   [5/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.59]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 5/20 | train loss: 2.7475, train acc: 0.301 | val loss: 2.7643, val acc: 0.303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [6/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.61]\n",
            "Val   [6/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.68]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 6/20 | train loss: 2.5747, train acc: 0.335 | val loss: 2.6599, val acc: 0.316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [7/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.41]\n",
            "Val   [7/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=2.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 7/20 | train loss: 2.4269, train acc: 0.365 | val loss: 2.5273, val acc: 0.348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [8/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.33]\n",
            "Val   [8/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.28]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 8/20 | train loss: 2.2978, train acc: 0.394 | val loss: 2.4965, val acc: 0.358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [9/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=2.22]\n",
            "Val   [9/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.31]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 9/20 | train loss: 2.1816, train acc: 0.418 | val loss: 2.4532, val acc: 0.369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [10/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.98]\n",
            "Val   [10/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=2.09]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 10/20 | train loss: 2.0488, train acc: 0.447 | val loss: 2.3719, val acc: 0.389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [11/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.81]\n",
            "Val   [11/20]: 100%|██████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 11/20 | train loss: 1.9309, train acc: 0.474 | val loss: 2.3679, val acc: 0.394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [12/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.74]\n",
            "Val   [12/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.22]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 12/20 | train loss: 1.7999, train acc: 0.503 | val loss: 2.3967, val acc: 0.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [13/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.32]\n",
            "Val   [13/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=1.85]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 13/20 | train loss: 1.6625, train acc: 0.535 | val loss: 2.3502, val acc: 0.407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [14/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.82]\n",
            "Val   [14/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.02]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 14/20 | train loss: 1.5281, train acc: 0.568 | val loss: 2.3854, val acc: 0.406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [15/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.44]\n",
            "Val   [15/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.25it/s, loss=1.93]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 15/20 | train loss: 1.3753, train acc: 0.607 | val loss: 2.3872, val acc: 0.415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [16/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.34]\n",
            "Val   [16/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.13]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 16/20 | train loss: 1.2331, train acc: 0.644 | val loss: 2.4264, val acc: 0.415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [17/20]: 100%|████████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.1]\n",
            "Val   [17/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2.38]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 17/20 | train loss: 1.0789, train acc: 0.683 | val loss: 2.5136, val acc: 0.412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [18/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.15]\n",
            "Val   [18/20]: 100%|████████████████████████████████████████| 79/79 [00:18<00:00,  4.24it/s, loss=2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 18/20 | train loss: 0.9090, train acc: 0.731 | val loss: 2.5957, val acc: 0.416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [19/20]: 100%|███████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=1.04]\n",
            "Val   [19/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.23it/s, loss=2.18]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 19/20 | train loss: 0.7692, train acc: 0.770 | val loss: 2.7115, val acc: 0.406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train [20/20]: 100%|██████████████████████████████████| 391/391 [02:46<00:00,  2.35it/s, loss=0.797]\n",
            "Val   [20/20]: 100%|█████████████████████████████████████| 79/79 [00:18<00:00,  4.22it/s, loss=1.97]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nonlinear_tpa] Epoch 20/20 | train loss: 0.6333, train acc: 0.809 | val loss: 2.7883, val acc: 0.414\n"
          ]
        }
      ],
      "source": [
        "# ========= Multi-dataset ablation: CIFAR10 -> CIFAR100 =========\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# ------------------ safety: keep deterministic-ish (if you already have set_global_seed) ------------------\n",
        "try:\n",
        "    set_global_seed(GLOBAL_SEED)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ===================== 通用配置 =====================\n",
        "data_dir = \"./data\"\n",
        "img_size = 224\n",
        "num_workers = 2\n",
        "weight_decay = 0.05\n",
        "pretrained = False\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "use_amp = False  # 保持你之前的设置\n",
        "\n",
        "# 模型\n",
        "model_tag  = \"tiny\"\n",
        "model_name = \"vit_tiny_patch16_224\"\n",
        "\n",
        "# 优化\n",
        "batch_size = 128\n",
        "lr = 3e-4\n",
        "\n",
        "# ===== epoch & rank（按你要求固定）=====\n",
        "rank_q, rank_k, rank_v = 16, 2, 2\n",
        "\n",
        "# ===== 你要求的 ratio 配置（修正 RATIO_MAP）=====\n",
        "#   KV (indep): 1.5\n",
        "#   KV_shared: 3.0\n",
        "#   QKV: 1.0\n",
        "#   Q/K/V 单独：3.0\n",
        "RATIO_MAP = {\n",
        "    \"q\": 3.0,\n",
        "    \"k\": 3.0,\n",
        "    \"v\": 3.0,\n",
        "    \"kv\": 1.5,\n",
        "    \"kv_shared\": 3.0,\n",
        "    \"qkv\": 1.0,\n",
        "\n",
        "    # NEW: head-wise\n",
        "    \"hw_kv\": 0.5,\n",
        "    \"hw_kv_shared\": 1.0,\n",
        "    \"hw_qkv\": 0.33,\n",
        "}\n",
        "\n",
        "DATASETS = [\"cifar10\", \"cifar100\"]\n",
        "\n",
        "# ===== 每个数据集的 epoch 数（按你要求：CIFAR10=40, CIFAR100=20）=====\n",
        "DATASET_EPOCHS = {\n",
        "    \"cifar10\": 40,\n",
        "    \"cifar100\": 20,\n",
        "}\n",
        "\n",
        "# ===== 实验列表（两套数据集一致，按你指定顺序）=====\n",
        "# 注意：MHA 的 attn_type 这里先写占位符 \"__MHA__\"，下面会自动探测实际字符串\n",
        "EXPERIMENT_LIST = [\n",
        "    {\"name\": \"MHA_baseline\",   \"attn_type\": \"__MHA__\",         \"mlp_on\": \"none\",      \"mlp_ratio\": 0.0},\n",
        "    {\"name\": \"TPA_r1622\",      \"attn_type\": \"tpa\",             \"mlp_on\": \"none\",      \"mlp_ratio\": 0.0},\n",
        "\n",
        "    {\"name\": \"NonlinearTPA_KV\",        \"attn_type\": \"nonlinear_tpa\", \"mlp_on\": \"kv\",        \"mlp_ratio\": RATIO_MAP[\"kv\"]},\n",
        "    {\"name\": \"NonlinearTPA_KV_shared\", \"attn_type\": \"nonlinear_tpa\", \"mlp_on\": \"kv_shared\", \"mlp_ratio\": RATIO_MAP[\"kv_shared\"]},\n",
        "\n",
        "    # NEW: head-wise KV variants\n",
        "    {\"name\": \"NonlinearTPA_HW_KV\",        \"attn_type\": \"headwise_nonlinear_tpa\", \"mlp_on\": \"qkv\",        \"mlp_ratio\": RATIO_MAP[\"hw_qkv\"]},\n",
        "    {\"name\": \"NonlinearTPA_HW_KV\",        \"attn_type\": \"headwise_nonlinear_tpa\", \"mlp_on\": \"kv\",        \"mlp_ratio\": RATIO_MAP[\"hw_kv\"]},\n",
        "    {\"name\": \"NonlinearTPA_HW_KV_shared\", \"attn_type\": \"headwise_nonlinear_tpa\", \"mlp_on\": \"kv_shared\", \"mlp_ratio\": RATIO_MAP[\"hw_kv_shared\"]},\n",
        "\n",
        "    {\"name\": \"NonlinearTPA_QKV\",       \"attn_type\": \"nonlinear_tpa\", \"mlp_on\": \"qkv\",       \"mlp_ratio\": RATIO_MAP[\"qkv\"]},\n",
        "\n",
        "    {\"name\": \"NonlinearTPA_Q\",         \"attn_type\": \"nonlinear_tpa\", \"mlp_on\": \"q\",         \"mlp_ratio\": RATIO_MAP[\"q\"]},\n",
        "    {\"name\": \"NonlinearTPA_K\",         \"attn_type\": \"nonlinear_tpa\", \"mlp_on\": \"k\",         \"mlp_ratio\": RATIO_MAP[\"k\"]},\n",
        "    {\"name\": \"NonlinearTPA_V\",         \"attn_type\": \"nonlinear_tpa\", \"mlp_on\": \"v\",         \"mlp_ratio\": RATIO_MAP[\"v\"]},\n",
        "]\n",
        "\n",
        "EXPERIMENTS = {\n",
        "    \"cifar10\":  EXPERIMENT_LIST,\n",
        "    \"cifar100\": EXPERIMENT_LIST,\n",
        "}\n",
        "\n",
        "# ------------------ helper: top-k val accuracy (for table) ------------------\n",
        "@torch.no_grad()\n",
        "def compute_val_topk_acc(model: nn.Module, loader, device: str, k: int = 5) -> float:\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, targets in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "        logits = model(images)\n",
        "        _, pred = logits.topk(k, dim=1, largest=True, sorted=True)  # (B,k)\n",
        "        correct += pred.eq(targets.view(-1, 1)).any(dim=1).sum().item()\n",
        "        total += targets.numel()\n",
        "    return correct / max(total, 1)\n",
        "\n",
        "def _ensure_dir(path: str):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    return path\n",
        "\n",
        "def _write_json(path: str, obj):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, indent=2)\n",
        "\n",
        "def _save_table_csv_md(df: pd.DataFrame, csv_path: str, md_path: str):\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(df.to_markdown(index=False))\n",
        "\n",
        "def _make_results_table(rows: list, params_tpa_ref: int):\n",
        "    out = []\n",
        "    for r in rows:\n",
        "        params_m = r[\"params\"] / 1e6\n",
        "        delta_m  = (r[\"params\"] - params_tpa_ref) / 1e6\n",
        "        out.append({\n",
        "            \"Dataset\": r[\"dataset\"],\n",
        "            \"Method\":  r[\"name\"],\n",
        "            \"Attn\":    r[\"attn_type\"],\n",
        "            \"MLP_on\":  r.get(\"mlp_on\", \"none\"),\n",
        "            \"MLP_ratio\": r.get(\"mlp_ratio\", None),\n",
        "            \"MLP_hidden\": r.get(\"mlp_hidden_dim\", None),\n",
        "            \"Params(M)\": round(params_m, 3),\n",
        "            \"ΔParams vs TPA(M)\": round(delta_m, 3),\n",
        "            \"Best epoch\": int(r[\"best_epoch\"] + 1),\n",
        "            \"Top-1 Val Acc (best)\": round(float(r[\"best_val_acc\"]), 4),\n",
        "            \"Top-5 Val Acc (final)\": (None if r.get(\"val_top5_acc_final\") is None else round(float(r[\"val_top5_acc_final\"]), 4)),\n",
        "        })\n",
        "    return pd.DataFrame(out)\n",
        "\n",
        "def _plot_combined_curves(dataset_dir: str, dataset_name: str, rows: list):\n",
        "    # 1) val acc\n",
        "    plt.figure()\n",
        "    for r in rows:\n",
        "        epochs_range = range(1, len(r[\"val_acc_curve\"]) + 1)\n",
        "        plt.plot(epochs_range, r[\"val_acc_curve\"], label=r[\"name\"])\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Val accuracy\")\n",
        "    plt.title(f\"{dataset_name} - {model_tag}: Val accuracy comparison\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(dataset_dir, \"combined_val_acc.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # 2) val loss\n",
        "    plt.figure()\n",
        "    for r in rows:\n",
        "        epochs_range = range(1, len(r[\"val_loss_curve\"]) + 1)\n",
        "        plt.plot(epochs_range, r[\"val_loss_curve\"], label=r[\"name\"])\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Val loss\")\n",
        "    plt.title(f\"{dataset_name} - {model_tag}: Val loss comparison\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(dataset_dir, \"combined_val_loss.png\"))\n",
        "    plt.close()\n",
        "\n",
        "# ===== 解析 GLOBAL_SEED（用于 run 文件夹命名 & ckpt）=====\n",
        "try:\n",
        "    _SEED_TAG = int(GLOBAL_SEED)\n",
        "except Exception:\n",
        "    _SEED_TAG = \"NA\"\n",
        "\n",
        "# ===== 自动探测 MHA 的 attn_type 字符串（避免你项目里命名不一致导致崩）=====\n",
        "def _resolve_mha_attn_type(num_classes: int):\n",
        "    # 你项目里常见命名候选（如不匹配，你可以把你项目里实际用的字符串加到这里）\n",
        "    candidates = [\"mha\", \"mhsa\", \"vanilla\", \"baseline\", \"standard\", \"attn\"]\n",
        "    for cand in candidates:\n",
        "        try:\n",
        "            m = ViTClassifier(\n",
        "                num_classes=num_classes,\n",
        "                model_name=model_name,\n",
        "                pretrained=pretrained,\n",
        "                attn_type=cand,\n",
        "                rank_q=rank_q, rank_k=rank_k, rank_v=rank_v,\n",
        "            ).to(device)\n",
        "            del m\n",
        "            if device == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "            return cand\n",
        "        except Exception:\n",
        "            continue\n",
        "    raise RuntimeError(\n",
        "        \"Cannot resolve MHA attn_type. Please add the correct string to candidates in _resolve_mha_attn_type().\"\n",
        "    )\n",
        "\n",
        "# ===================== result 目录 / run 文件夹 =====================\n",
        "_ensure_dir(\"result\")\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_name = (\n",
        "    f\"ablation_seed{_SEED_TAG}_{timestamp}_\"\n",
        "    f\"{model_tag}_{model_name}_\"\n",
        "    f\"EpC10{DATASET_EPOCHS['cifar10']}_C100{DATASET_EPOCHS['cifar100']}_\"\n",
        "    f\"bs{batch_size}_lr{lr}_wd{weight_decay}_\"\n",
        "    f\"rq{rank_q}_rk{rank_k}_rv{rank_v}_\"\n",
        "    f\"ratios_QKV{RATIO_MAP['qkv']}_KV{RATIO_MAP['kv']}_KVsh{RATIO_MAP['kv_shared']}_single{RATIO_MAP['q']}\"\n",
        ")\n",
        "run_dir = _ensure_dir(os.path.join(\"result\", run_name))\n",
        "checkpoints_root = _ensure_dir(os.path.join(run_dir, \"checkpoints\"))\n",
        "print(f\"\\n\\n######################## Run dir: {run_dir} ########################\")\n",
        "\n",
        "hparams = {\n",
        "    \"datasets\": DATASETS,\n",
        "    \"dataset_epochs\": DATASET_EPOCHS,\n",
        "    \"model_tag\": model_tag,\n",
        "    \"model_name\": model_name,\n",
        "    \"img_size\": img_size,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"lr\": lr,\n",
        "    \"weight_decay\": weight_decay,\n",
        "    \"pretrained\": pretrained,\n",
        "    \"rank_q\": rank_q,\n",
        "    \"rank_k\": rank_k,\n",
        "    \"rank_v\": rank_v,\n",
        "    \"ratio_map\": RATIO_MAP,\n",
        "    \"experiments\": EXPERIMENTS,\n",
        "    \"timestamp\": timestamp,\n",
        "    \"GLOBAL_SEED\": _SEED_TAG,\n",
        "}\n",
        "_write_json(os.path.join(run_dir, \"hparams.json\"), hparams)\n",
        "\n",
        "global_rows = []\n",
        "\n",
        "# ===================== 主循环：dataset × experiment =====================\n",
        "for dataset_name in DATASETS:\n",
        "    total_epochs = DATASET_EPOCHS[dataset_name]\n",
        "    print(f\"\\n\\n==================== DATASET: {dataset_name} (epochs={total_epochs}) ====================\")\n",
        "\n",
        "    dataset_dir = _ensure_dir(os.path.join(run_dir, dataset_name))\n",
        "    _write_json(os.path.join(dataset_dir, \"hparams.json\"), {**hparams, \"dataset_name\": dataset_name, \"total_epochs\": total_epochs})\n",
        "\n",
        "    # 先拿 num_classes\n",
        "    train_loader, val_loader, num_classes = get_loaders(\n",
        "        dataset_name=dataset_name,\n",
        "        data_dir=data_dir,\n",
        "        batch_size=batch_size,\n",
        "        img_size=img_size,\n",
        "        num_workers=num_workers,\n",
        "    )\n",
        "\n",
        "    # 解析 MHA 的 attn_type（只做一次）\n",
        "    mha_attn_type = _resolve_mha_attn_type(num_classes)\n",
        "    print(f\"[Info] Resolved MHA attn_type = {mha_attn_type}\")\n",
        "\n",
        "    # baseline TPA params (per dataset：因为 num_classes 会影响分类头参数)\n",
        "    tpa_ref_model = ViTClassifier(\n",
        "        num_classes=num_classes,\n",
        "        model_name=model_name,\n",
        "        pretrained=pretrained,\n",
        "        attn_type=\"tpa\",\n",
        "        rank_q=rank_q,\n",
        "        rank_k=rank_k,\n",
        "        rank_v=rank_v,\n",
        "    ).to(device)\n",
        "    params_tpa_ref = sum(p.numel() for p in tpa_ref_model.parameters())\n",
        "    del tpa_ref_model\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    dataset_rows = []\n",
        "\n",
        "    for exp in EXPERIMENTS[dataset_name]:\n",
        "        exp_name  = exp[\"name\"]\n",
        "        attn_type = exp[\"attn_type\"]\n",
        "        mlp_on    = exp[\"mlp_on\"]\n",
        "        mlp_ratio = exp[\"mlp_ratio\"]\n",
        "\n",
        "        # 替换 MHA 占位符\n",
        "        if attn_type == \"__MHA__\":\n",
        "            attn_type = mha_attn_type\n",
        "\n",
        "        print(f\"\\n-------------------- [{dataset_name}] Experiment: {exp_name} --------------------\")\n",
        "        exp_dir = _ensure_dir(os.path.join(dataset_dir, exp_name))\n",
        "        exp_ckpt_dir = _ensure_dir(os.path.join(exp_dir, \"checkpoints\"))\n",
        "\n",
        "        # 训练（严格保持你现成的 run_small_spectrum_experiment 调用方式）\n",
        "        model, hist = run_small_spectrum_experiment(\n",
        "            dataset_name=dataset_name,\n",
        "            num_workers=2,\n",
        "            model_name=model_name,\n",
        "            data_dir=data_dir,\n",
        "            batch_size=batch_size,\n",
        "            img_size=img_size,\n",
        "            lr=lr,\n",
        "            weight_decay=weight_decay,\n",
        "\n",
        "            device=device,\n",
        "            attn_type=attn_type,\n",
        "            total_epochs=total_epochs,\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            mlp_ratio=mlp_ratio,\n",
        "            mlp_on=mlp_on,\n",
        "            block_idx=5,\n",
        "            top_k=8,\n",
        "            num_batches_spec=1,\n",
        "        )\n",
        "\n",
        "        # final top-5\n",
        "        try:\n",
        "            val_top5 = compute_val_topk_acc(model, val_loader, device=device, k=5)\n",
        "        except Exception:\n",
        "            val_top5 = None\n",
        "\n",
        "        train_loss_curve = hist[\"train_loss_curve\"]\n",
        "        val_loss_curve   = hist[\"val_loss_curve\"]\n",
        "        train_acc_curve  = hist[\"train_acc_curve\"]\n",
        "        val_acc_curve    = hist[\"val_acc_curve\"]\n",
        "        best_val_acc     = float(hist[\"best_val_acc\"])\n",
        "        best_epoch       = int(np.argmax(val_acc_curve))\n",
        "\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        first_attn = model.vit.blocks[0].attn\n",
        "        dim_attn = getattr(first_attn, \"dim\", None) or first_attn.qkv.in_features\n",
        "        num_heads_attn = first_attn.num_heads\n",
        "        head_dim_attn = dim_attn // num_heads_attn\n",
        "\n",
        "        # 只有 nonlinear_tpa 才有 mlp_hidden_dim\n",
        "        mlp_hidden_dim = None\n",
        "        if attn_type == \"nonlinear_tpa\":\n",
        "            try:\n",
        "                mlp_hidden_dim = int(head_dim_attn * float(mlp_ratio))\n",
        "            except Exception:\n",
        "                mlp_hidden_dim = None\n",
        "\n",
        "        # log\n",
        "        log_lines = []\n",
        "        for ep in range(total_epochs):\n",
        "            log_lines.append(\n",
        "                f\"Epoch {ep+1}/{total_epochs} | \"\n",
        "                f\"train loss: {train_loss_curve[ep]:.4f}, train acc: {train_acc_curve[ep]:.3f} | \"\n",
        "                f\"val loss: {val_loss_curve[ep]:.4f}, val acc: {val_acc_curve[ep]:.3f}\"\n",
        "            )\n",
        "        with open(os.path.join(exp_dir, \"log.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"\\n\".join(log_lines))\n",
        "\n",
        "        # ===== checkpoint：保存尽可能完整的状态，支持“等价续训” =====\n",
        "        ckpt = {\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"optimizer_state\": hist.get(\"optimizer_state\", None),\n",
        "            \"scheduler_state\": hist.get(\"scheduler_state\", None),  # 如果你的训练函数有返回就会存\n",
        "            \"amp_scaler_state\": hist.get(\"amp_scaler_state\", None),  # use_amp=False 时一般为 None\n",
        "\n",
        "            \"last_epoch\": hist.get(\"last_epoch\", None),\n",
        "            \"dataset\": dataset_name,\n",
        "            \"attn_type\": attn_type,\n",
        "            \"exp_name\": exp_name,\n",
        "            \"rank_q\": rank_q, \"rank_k\": rank_k, \"rank_v\": rank_v,\n",
        "            \"mlp_on\": mlp_on,\n",
        "            \"mlp_ratio\": mlp_ratio,\n",
        "            \"total_epochs\": total_epochs,\n",
        "            \"GLOBAL_SEED\": _SEED_TAG,\n",
        "\n",
        "            # RNG states（尽量保证 resume “工程等价”）\n",
        "            \"numpy_rng_state\": np.random.get_state(),\n",
        "            \"torch_rng_state\": torch.get_rng_state(),\n",
        "            \"cuda_rng_state\": (torch.cuda.get_rng_state_all() if torch.cuda.is_available() else None),\n",
        "\n",
        "            # metrics/history\n",
        "            \"best_val_acc\": best_val_acc,\n",
        "            \"train_loss_curve\": train_loss_curve,\n",
        "            \"val_loss_curve\": val_loss_curve,\n",
        "            \"train_acc_curve\": train_acc_curve,\n",
        "            \"val_acc_curve\": val_acc_curve,\n",
        "            \"val_top5_acc_final\": val_top5,\n",
        "            \"hparams\": hparams,\n",
        "\n",
        "            # 方便复现实验/续训时重建同构调用\n",
        "            \"train_call_kwargs\": {\n",
        "                \"dataset_name\": dataset_name,\n",
        "                \"num_workers\": 2,\n",
        "                \"model_name\": model_name,\n",
        "                \"data_dir\": data_dir,\n",
        "                \"batch_size\": batch_size,\n",
        "                \"img_size\": img_size,\n",
        "                \"lr\": lr,\n",
        "                \"weight_decay\": weight_decay,\n",
        "                \"device\": device,\n",
        "                \"attn_type\": attn_type,\n",
        "                \"total_epochs\": total_epochs,\n",
        "                \"rank_q\": rank_q,\n",
        "                \"rank_k\": rank_k,\n",
        "                \"rank_v\": rank_v,\n",
        "                \"mlp_ratio\": mlp_ratio,\n",
        "                \"mlp_on\": mlp_on,\n",
        "                \"block_idx\": 5,\n",
        "                \"top_k\": 8,\n",
        "                \"num_batches_spec\": 1,\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # 1) 保持你原逻辑：exp_dir/ckpt.pt\n",
        "        torch.save(ckpt, os.path.join(exp_dir, \"ckpt.pt\"))\n",
        "        # 2) 按你要求：全部也落在 checkpoints 目录里（每个 exp 一份）\n",
        "        torch.save(ckpt, os.path.join(exp_ckpt_dir, \"ckpt.pt\"))\n",
        "        # 3) run 级别汇总 checkpoints（便于你后续脚本统一读取）\n",
        "        torch.save(ckpt, os.path.join(checkpoints_root, f\"{dataset_name}__{exp_name}__seed{_SEED_TAG}.pt\"))\n",
        "\n",
        "        # plots（保持原有逻辑）\n",
        "        epochs_range = range(1, total_epochs + 1)\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(epochs_range, train_loss_curve, label=\"train loss\")\n",
        "        plt.plot(epochs_range, val_loss_curve, label=\"val loss\")\n",
        "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "        plt.title(f\"{dataset_name} - {model_tag} - {exp_name}: loss convergence\")\n",
        "        plt.grid(True); plt.legend(); plt.tight_layout()\n",
        "        plt.savefig(os.path.join(exp_dir, \"loss_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(epochs_range, val_acc_curve, label=f\"{exp_name} val acc\")\n",
        "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Val accuracy\")\n",
        "        plt.title(f\"{dataset_name} - {model_tag} - {exp_name}: val acc\")\n",
        "        plt.grid(True); plt.legend(); plt.tight_layout()\n",
        "        plt.savefig(os.path.join(exp_dir, \"val_acc_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # update rows\n",
        "        row = {\n",
        "            \"dataset\": dataset_name,\n",
        "            \"name\": exp_name,\n",
        "            \"attn_type\": attn_type,\n",
        "            \"mlp_on\": mlp_on,\n",
        "            \"mlp_ratio\": (None if attn_type != \"nonlinear_tpa\" else float(mlp_ratio)),\n",
        "            \"mlp_hidden_dim\": mlp_hidden_dim,\n",
        "            \"params\": total_params,\n",
        "            \"params_vs_tpa\": total_params - params_tpa_ref,\n",
        "            \"best_val_acc\": best_val_acc,\n",
        "            \"best_epoch\": best_epoch,\n",
        "            \"val_top5_acc_final\": val_top5,\n",
        "            \"train_loss_curve\": train_loss_curve,\n",
        "            \"val_loss_curve\": val_loss_curve,\n",
        "            \"train_acc_curve\": train_acc_curve,\n",
        "            \"val_acc_curve\": val_acc_curve,\n",
        "            \"GLOBAL_SEED\": _SEED_TAG,\n",
        "        }\n",
        "        dataset_rows.append(row)\n",
        "        global_rows.append(row)\n",
        "\n",
        "        # dataset summary/table/combined plots（每个 experiment 完成就刷新一次，防中途挂）\n",
        "        dataset_summary = []\n",
        "        for r in dataset_rows:\n",
        "            dataset_summary.append({\n",
        "                k: r[k] for k in [\n",
        "                    \"dataset\",\"name\",\"attn_type\",\"mlp_on\",\"mlp_ratio\",\"mlp_hidden_dim\",\n",
        "                    \"params\",\"params_vs_tpa\",\"best_val_acc\",\"best_epoch\",\"val_top5_acc_final\",\n",
        "                    \"train_loss_curve\",\"val_loss_curve\",\"train_acc_curve\",\"val_acc_curve\",\"GLOBAL_SEED\"\n",
        "                ]\n",
        "            })\n",
        "        _write_json(os.path.join(dataset_dir, \"summary.json\"), dataset_summary)\n",
        "\n",
        "        df_dataset = _make_results_table(dataset_rows, params_tpa_ref=params_tpa_ref)\n",
        "        _save_table_csv_md(\n",
        "            df_dataset,\n",
        "            csv_path=os.path.join(dataset_dir, \"results_table.csv\"),\n",
        "            md_path=os.path.join(dataset_dir, \"results_table.md\"),\n",
        "        )\n",
        "        _plot_combined_curves(dataset_dir, dataset_name, dataset_rows)\n",
        "\n",
        "        # global 同步写一份（同样防 crash）\n",
        "        global_summary = []\n",
        "        for r in global_rows:\n",
        "            global_summary.append({\n",
        "                k: r[k] for k in [\n",
        "                    \"dataset\",\"name\",\"attn_type\",\"mlp_on\",\"mlp_ratio\",\"mlp_hidden_dim\",\n",
        "                    \"params\",\"params_vs_tpa\",\"best_val_acc\",\"best_epoch\",\"val_top5_acc_final\",\n",
        "                    \"train_loss_curve\",\"val_loss_curve\",\"train_acc_curve\",\"val_acc_curve\",\"GLOBAL_SEED\"\n",
        "                ]\n",
        "            })\n",
        "        _write_json(os.path.join(run_dir, \"summary.json\"), global_summary)\n",
        "\n",
        "        pd.DataFrame([{\n",
        "            \"Dataset\": r[\"dataset\"],\n",
        "            \"Method\": r[\"name\"],\n",
        "            \"Attn\": r[\"attn_type\"],\n",
        "            \"MLP_on\": r.get(\"mlp_on\",\"none\"),\n",
        "            \"MLP_ratio\": r.get(\"mlp_ratio\", None),\n",
        "            \"MLP_hidden\": r.get(\"mlp_hidden_dim\", None),\n",
        "            \"Params(M)\": round(r[\"params\"]/1e6, 3),\n",
        "            \"Top-1 Val Acc (best)\": round(float(r[\"best_val_acc\"]), 4),\n",
        "            \"Best epoch\": int(r[\"best_epoch\"] + 1),\n",
        "            \"Top-5 Val Acc (final)\": (None if r.get(\"val_top5_acc_final\") is None else round(float(r[\"val_top5_acc_final\"]), 4)),\n",
        "            \"GLOBAL_SEED\": r.get(\"GLOBAL_SEED\", None),\n",
        "        } for r in global_rows]).to_csv(os.path.join(run_dir, \"results_table.csv\"), index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "7SoA0zMLpWCd",
        "outputId": "5a0ca2a9-ea05-4861-d1b0-d510ccc1fb8a"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# ==== 通用配置 ====\n",
        "data_dir = \"./data\"\n",
        "img_size = 224\n",
        "num_workers = 8\n",
        "weight_decay = 0.05\n",
        "pretrained = False\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "use_amp = False      # 先关 AMP，等结构都稳定后再考虑开\n",
        "\n",
        "# 数据集 & 模型\n",
        "dataset_name = \"cifar100\"     # 换数据集只改这里\n",
        "model_tag   = \"tiny\"\n",
        "model_name  = \"vit_tiny_patch16_224\"\n",
        "batch_size  = 128\n",
        "lr          = 3e-4\n",
        "\n",
        "# ====== epoch 设置 ======\n",
        "epochs_base         = 30   # TPA / NonlinearTPA / SinterTPA 的总 epoch\n",
        "epochs_mha          = 100  # MHA 的总 epoch\n",
        "tucker_ab_epochs    = 11   # TuckerTPA 阶段 1：训练 A/B 的 epoch 数\n",
        "tucker_total_epochs = 20   # TuckerTPA 总 epoch\n",
        "\n",
        "# ====== rank 设置：共享单一 R ======\n",
        "R_shared = 16\n",
        "tucker_rank_head    = R_shared\n",
        "tucker_rank_channel = R_shared\n",
        "\n",
        "# TPA / NonlinearTPA / SinterTPA 的 rank 设置\n",
        "rank_q = 16\n",
        "rank_k = 2\n",
        "rank_v = 2\n",
        "\n",
        "# ====== Sinter 超参数（扰动） ======\n",
        "sinter_A = 5e-5\n",
        "sinter_omega = 1e4\n",
        "\n",
        "# ====== 实验列表 ======\n",
        "# 顺序：\n",
        "#   1) SinterTPA (ratio=1.0, 30ep)\n",
        "#   2) NonlinearTPA (ratio=1.0, 30ep)\n",
        "#   3) MHA (100ep)\n",
        "#   4) SinterTPA (ratio=2.0, 30ep)\n",
        "#   5) NonlinearTPA (ratio=2.0, 30ep)\n",
        "#   6) SinterTPA (ratio=3.0, 30ep)\n",
        "#   7) NonlinearTPA (ratio=3.0, 30ep)\n",
        "experiments = [\n",
        "    {\n",
        "        \"name\": \"SinterTPA_ratio1.0\",\n",
        "        \"attn_type\": \"sinter_tpa\",\n",
        "        \"total_epochs\": epochs_base,\n",
        "        \"mlp_ratio\": 1.0,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"NonlinearTPA_ratio1.0\",\n",
        "        \"attn_type\": \"nonlinear_tpa\",\n",
        "        \"total_epochs\": epochs_base,\n",
        "        \"mlp_ratio\": 1.0,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"MHA\",\n",
        "        \"attn_type\": \"mha\",\n",
        "        \"total_epochs\": epochs_mha,\n",
        "        \"mlp_ratio\": None,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"SinterTPA_ratio2.0\",\n",
        "        \"attn_type\": \"sinter_tpa\",\n",
        "        \"total_epochs\": epochs_base,\n",
        "        \"mlp_ratio\": 2.0,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"NonlinearTPA_ratio2.0\",\n",
        "        \"attn_type\": \"nonlinear_tpa\",\n",
        "        \"total_epochs\": epochs_base,\n",
        "        \"mlp_ratio\": 2.0,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"SinterTPA_ratio3.0\",\n",
        "        \"attn_type\": \"sinter_tpa\",\n",
        "        \"total_epochs\": epochs_base,\n",
        "        \"mlp_ratio\": 3.0,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"NonlinearTPA_ratio3.0\",\n",
        "        \"attn_type\": \"nonlinear_tpa\",\n",
        "        \"total_epochs\": epochs_base,\n",
        "        \"mlp_ratio\": 3.0,\n",
        "    },\n",
        "]\n",
        "\n",
        "# ============== 准备 result 目录和本次 run 的文件夹 ==============\n",
        "\n",
        "os.makedirs(\"result\", exist_ok=True)\n",
        "\n",
        "run_name = (\n",
        "    f\"{dataset_name}_{model_tag}_{model_name}\"\n",
        "    f\"_BaseEp{epochs_base}_MHAEp{epochs_mha}\"\n",
        "    f\"_bs{batch_size}_lr{lr}_wd{weight_decay}\"\n",
        "    f\"_rq{rank_q}_rk{rank_k}_rv{rank_v}\"\n",
        "    f\"_attns_SinterTPA_NonlinearTPA_MHA\"\n",
        ")\n",
        "\n",
        "run_dir = os.path.join(\"result\", run_name)\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "print(f\"\\n\\n######################## Run dir: {run_dir} ########################\")\n",
        "\n",
        "# 把本次实验的超参数也存一个 json 方便以后查\n",
        "tested_mlp_ratios = sorted(\n",
        "    {e[\"mlp_ratio\"] for e in experiments if e.get(\"mlp_ratio\") is not None}\n",
        ")\n",
        "\n",
        "hparams = {\n",
        "    \"dataset_name\": dataset_name,\n",
        "    \"model_tag\": model_tag,\n",
        "    \"model_name\": model_name,\n",
        "    \"epochs_base\": epochs_base,\n",
        "    \"epochs_mha\": epochs_mha,\n",
        "    \"tucker_total_epochs\": tucker_total_epochs,\n",
        "    \"tucker_ab_epochs\": tucker_ab_epochs,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"lr\": lr,\n",
        "    \"weight_decay\": weight_decay,\n",
        "    \"R_shared\": R_shared,\n",
        "    \"rank_q\": rank_q,\n",
        "    \"rank_k\": rank_k,\n",
        "    \"rank_v\": rank_v,\n",
        "    \"tucker_rank_head\": tucker_rank_head,\n",
        "    \"tucker_rank_channel\": tucker_rank_channel,\n",
        "    \"sinter_A\": sinter_A,\n",
        "    \"sinter_omega\": sinter_omega,\n",
        "    \"nonlinear_mlp_hidden_ratios\": tested_mlp_ratios,\n",
        "    \"experiments\": [e[\"name\"] for e in experiments],\n",
        "    \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "}\n",
        "\n",
        "with open(os.path.join(run_dir, \"hparams.json\"), \"w\") as f:\n",
        "    json.dump(hparams, f, indent=2)\n",
        "\n",
        "# ============== 数据加载 ==============\n",
        "\n",
        "print(f\"\\n\\n######################## Experiments on {model_tag} ({model_name}) / {dataset_name} ########################\")\n",
        "\n",
        "train_loader, val_loader, num_classes = get_loaders(\n",
        "    dataset_name=dataset_name,\n",
        "    data_dir=data_dir,\n",
        "    batch_size=batch_size,\n",
        "    img_size=img_size,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "# ============== 1) Baseline MHA 参数量 / 维度信息 ==============\n",
        "\n",
        "print(\"\\n==================== Baseline MHA model ====================\")\n",
        "baseline_model = ViTClassifier(\n",
        "    num_classes=num_classes,\n",
        "    model_name=model_name,\n",
        "    pretrained=pretrained,\n",
        "    attn_type=\"mha\",\n",
        ").to(device)\n",
        "\n",
        "baseline_params = sum(p.numel() for p in baseline_model.parameters())\n",
        "print(f\"[{model_tag}] Baseline MHA params: {baseline_params / 1e6:.2f}M\")\n",
        "\n",
        "first_attn_baseline = baseline_model.vit.blocks[0].attn\n",
        "if hasattr(first_attn_baseline, \"dim\"):\n",
        "    dim = first_attn_baseline.dim\n",
        "else:\n",
        "    dim = first_attn_baseline.qkv.in_features\n",
        "\n",
        "num_heads = first_attn_baseline.num_heads\n",
        "head_dim = dim // num_heads\n",
        "print(f\"[{model_tag}] dim={dim}, num_heads={num_heads}, head_dim={head_dim}\")\n",
        "\n",
        "del baseline_model\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# ============== 2) 依次跑多个实验 ==============\n",
        "\n",
        "results_all = []      # 用来存最后总曲线图的信息\n",
        "\n",
        "for exp in experiments:\n",
        "    exp_name     = exp[\"name\"]\n",
        "    attn_type    = exp[\"attn_type\"]\n",
        "    total_epochs = exp[\"total_epochs\"]\n",
        "    mlp_ratio    = exp.get(\"mlp_ratio\", None)\n",
        "\n",
        "    print(f\"\\n==================== Experiment: {model_tag}-{exp_name} ====================\")\n",
        "\n",
        "    # 为当前实验建一个子目录\n",
        "    exp_dir = os.path.join(run_dir, exp_name)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "\n",
        "    # ---------- 构建模型 ----------\n",
        "    if attn_type == \"mha\":\n",
        "        model = ViTClassifier(\n",
        "            num_classes=num_classes,\n",
        "            model_name=model_name,\n",
        "            pretrained=pretrained,\n",
        "            attn_type=\"mha\",\n",
        "        ).to(device)\n",
        "\n",
        "    elif attn_type == \"tpa\":\n",
        "        # True TPA（A/B 都 contextual）\n",
        "        model = ViTClassifier(\n",
        "            num_classes=num_classes,\n",
        "            model_name=model_name,\n",
        "            pretrained=pretrained,\n",
        "            attn_type=\"tpa\",\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "        ).to(device)\n",
        "\n",
        "    elif attn_type == \"nonlinear_tpa\":\n",
        "        # 非线性 TPA：Q = MLP(1/R * A^T B)\n",
        "        model = ViTClassifier(\n",
        "            num_classes=num_classes,\n",
        "            model_name=model_name,\n",
        "            pretrained=pretrained,\n",
        "            attn_type=\"nonlinear_tpa\",\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            nonlinear_mlp_hidden_ratio=mlp_ratio if mlp_ratio is not None else 1.0,\n",
        "        ).to(device)\n",
        "\n",
        "    elif attn_type == \"sinter_tpa\":\n",
        "        # Sinter TPA：Q = MLP_Sinter(1/R * A^T B)\n",
        "        model = ViTClassifier(\n",
        "            num_classes=num_classes,\n",
        "            model_name=model_name,\n",
        "            pretrained=pretrained,\n",
        "            attn_type=\"sinter_tpa\",\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "            nonlinear_mlp_hidden_ratio=mlp_ratio if mlp_ratio is not None else 1.0,\n",
        "            sinter_A=sinter_A,\n",
        "            sinter_omega=sinter_omega,\n",
        "        ).to(device)\n",
        "\n",
        "    elif attn_type == \"tucker_tpa\":\n",
        "        model = ViTClassifier(\n",
        "            num_classes=num_classes,\n",
        "            model_name=model_name,\n",
        "            pretrained=pretrained,\n",
        "            attn_type=\"tucker_tpa\",\n",
        "            rank_q=rank_q,\n",
        "            rank_k=rank_k,\n",
        "            rank_v=rank_v,\n",
        "        ).to(device)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected attn_type: {attn_type}\")\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(\n",
        "        f\"[{model_tag}-{exp_name}] Total params: {total_params / 1e6:.2f}M \"\n",
        "        f\"(diff vs MHA: {(total_params - baseline_params)/1e6:.3f}M)\"\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    if use_amp and device == \"cuda\":\n",
        "        scaler = torch.cuda.amp.GradScaler()\n",
        "    else:\n",
        "        scaler = None\n",
        "\n",
        "    # ---------- 调用对应的训练函数 ----------\n",
        "    if attn_type == \"tucker_tpa\":\n",
        "        history = train_model_two_stage_tucker(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            total_epochs=total_epochs,\n",
        "            ab_epochs=tucker_ab_epochs,\n",
        "            scaler=scaler,\n",
        "            is_tucker_model=True,\n",
        "        )\n",
        "\n",
        "    elif attn_type == \"tpa\":\n",
        "        history = train_model_TPA(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            total_epochs=total_epochs,\n",
        "            scaler=scaler,\n",
        "        )\n",
        "\n",
        "    elif attn_type == \"nonlinear_tpa\":\n",
        "        history = train_model_nonlinear_TPA(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            total_epochs=total_epochs,\n",
        "            scaler=scaler,\n",
        "        )\n",
        "\n",
        "    elif attn_type == \"sinter_tpa\":\n",
        "        history = train_model_sinter_TPA(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            total_epochs=total_epochs,\n",
        "            scaler=scaler,\n",
        "        )\n",
        "\n",
        "    elif attn_type == \"mha\":\n",
        "        history = train_model_MHA(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            total_epochs=total_epochs,\n",
        "            scaler=scaler,\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown attn_type: {attn_type}\")\n",
        "\n",
        "    train_loss_curve = history[\"train_loss_curve\"]\n",
        "    val_loss_curve   = history[\"val_loss_curve\"]\n",
        "    train_acc_curve  = history[\"train_acc_curve\"]\n",
        "    val_acc_curve    = history[\"val_acc_curve\"]\n",
        "    best_val_acc     = history[\"best_val_acc\"]\n",
        "\n",
        "    print(f\">>> [{model_tag}-{exp_name}] best val acc: {best_val_acc:.4f}\")\n",
        "\n",
        "    # ---------- KV cost 简易估算 ----------\n",
        "    first_attn = model.vit.blocks[0].attn\n",
        "    if hasattr(first_attn, \"dim\"):\n",
        "        dim_attn = first_attn.dim\n",
        "    else:\n",
        "        dim_attn = first_attn.qkv.in_features\n",
        "    num_heads_attn = first_attn.num_heads\n",
        "    head_dim_attn = dim_attn // num_heads_attn\n",
        "\n",
        "    kv_mha = 2 * num_heads_attn * head_dim_attn  # = 2 * dim\n",
        "\n",
        "    if attn_type == \"mha\":\n",
        "        normalized_kv_cost = 1.0\n",
        "    elif attn_type in (\"tpa\", \"nonlinear_tpa\", \"sinter_tpa\"):\n",
        "        kv_tpa = (rank_k + rank_v) * (num_heads_attn + head_dim_attn)\n",
        "        normalized_kv_cost = kv_tpa / kv_mha\n",
        "    elif attn_type == \"tucker_tpa\":\n",
        "        normalized_kv_cost = 1.0\n",
        "    else:\n",
        "        normalized_kv_cost = 1.0\n",
        "\n",
        "    # ---------- 把当前实验结果存起来 ----------\n",
        "    results_all.append(\n",
        "        {\n",
        "            \"name\": exp_name,\n",
        "            \"attn_type\": attn_type,\n",
        "            \"mlp_ratio\": mlp_ratio,\n",
        "            \"params\": total_params,\n",
        "            \"best_val_acc\": best_val_acc,\n",
        "            \"train_loss_curve\": train_loss_curve,\n",
        "            \"val_loss_curve\": val_loss_curve,\n",
        "            \"train_acc_curve\": train_acc_curve,\n",
        "            \"val_acc_curve\": val_acc_curve,\n",
        "            \"kv_cost\": normalized_kv_cost,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # ---------- 写 log ----------\n",
        "    log_lines = []\n",
        "    # 第一行：模型参数量信息\n",
        "    log_lines.append(\n",
        "        f\"Total params: {total_params} ({total_params/1e6:.2f}M), \"\n",
        "        f\"diff vs baseline MHA: {total_params - baseline_params} \"\n",
        "        f\"({(total_params - baseline_params)/1e6:.3f}M)\"\n",
        "    )\n",
        "    if mlp_ratio is not None:\n",
        "        log_lines.append(f\"nonlinear_mlp_hidden_ratio: {mlp_ratio}\")\n",
        "    log_lines.append(f\"attn_type: {attn_type}\")\n",
        "    log_lines.append(f\"kv_cost (normalized to MHA=1): {normalized_kv_cost:.4f}\")\n",
        "    log_lines.append(\"\")  # 空行分隔\n",
        "\n",
        "    for ep in range(total_epochs):\n",
        "        log_lines.append(\n",
        "            f\"Epoch {ep+1}/{total_epochs} | \"\n",
        "            f\"train loss: {train_loss_curve[ep]:.4f}, train acc: {train_acc_curve[ep]:.3f} | \"\n",
        "            f\"val loss: {val_loss_curve[ep]:.4f}, val acc: {val_acc_curve[ep]:.3f}\"\n",
        "        )\n",
        "\n",
        "    exp_log_path = os.path.join(\n",
        "        exp_dir,\n",
        "        f\"log_{dataset_name}_{model_tag}_{exp_name}_totEp{total_epochs}_lr{lr}_R{R_shared}_rq{rank_q}_rh{tucker_rank_head}_rd{tucker_rank_channel}.txt\",\n",
        "    )\n",
        "    with open(exp_log_path, \"w\") as f:\n",
        "        f.write(\"\\n\".join(log_lines))\n",
        "\n",
        "    # ---------- 保存最终 checkpoint（最新一版） ----------\n",
        "    ckpt_name = (\n",
        "        f\"ckpt_{dataset_name}_{model_tag}_{exp_name}\"\n",
        "        f\"_totEp{total_epochs}_lr{lr}_R{R_shared}_rq{rank_q}_rh{tucker_rank_head}_rd{tucker_rank_channel}.pt\"\n",
        "    )\n",
        "    ckpt_path = os.path.join(exp_dir, ckpt_name)\n",
        "\n",
        "    torch.save(\n",
        "        {\n",
        "            \"attn_type\": attn_type,\n",
        "            \"total_epochs\": total_epochs,\n",
        "            \"mlp_ratio\": mlp_ratio,\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"optimizer_state\": optimizer.state_dict(),\n",
        "            \"best_val_acc\": best_val_acc,\n",
        "            \"train_loss_curve\": train_loss_curve,\n",
        "            \"val_loss_curve\": val_loss_curve,\n",
        "            \"train_acc_curve\": train_acc_curve,\n",
        "            \"val_acc_curve\": val_acc_curve,\n",
        "            \"hparams\": hparams,\n",
        "        },\n",
        "        ckpt_path,\n",
        "    )\n",
        "\n",
        "    # ---------- 画当前实验的 loss 收敛图 ----------\n",
        "    epochs_range = range(1, total_epochs + 1)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, train_loss_curve, label=\"train loss\")\n",
        "    plt.plot(epochs_range, val_loss_curve, label=\"val loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"{dataset_name} - {model_tag} - {exp_name}: loss convergence\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    loss_fig_path = os.path.join(\n",
        "        exp_dir,\n",
        "        f\"loss_curve_{dataset_name}_{model_tag}_{exp_name}_totEp{total_epochs}.png\",\n",
        "    )\n",
        "    plt.savefig(loss_fig_path)\n",
        "    plt.show()\n",
        "\n",
        "    # ---------- 当前实验的 val acc 曲线 ----------\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_range, val_acc_curve, label=f\"{exp_name} val acc\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Val accuracy\")\n",
        "    plt.title(f\"{dataset_name} - {model_tag} - {exp_name}: val acc\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    acc_fig_path = os.path.join(\n",
        "        exp_dir,\n",
        "        f\"val_acc_curve_{dataset_name}_{model_tag}_{exp_name}_totEp{total_epochs}.png\",\n",
        "    )\n",
        "    plt.savefig(acc_fig_path)\n",
        "    plt.show()\n",
        "\n",
        "    # ---------- 截至当前 experiment 的所有实验对比图（val acc & val loss） ----------\n",
        "    # Val accuracy comparison\n",
        "    plt.figure()\n",
        "    for res in results_all:\n",
        "        total_epochs_exp = len(res[\"val_acc_curve\"])\n",
        "        epochs_range_all = range(1, total_epochs_exp + 1)\n",
        "        label = res[\"name\"]\n",
        "        if res.get(\"mlp_ratio\") is not None:\n",
        "            label += f\" (ratio={res['mlp_ratio']})\"\n",
        "        label += f\" (KV={res['kv_cost']:.2f})\"\n",
        "        plt.plot(epochs_range_all, res[\"val_acc_curve\"], label=label)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Val accuracy\")\n",
        "    plt.title(f\"{dataset_name} - {model_tag}: Val acc comparison (up to {exp_name})\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    combined_acc_path = os.path.join(\n",
        "        run_dir,\n",
        "        f\"combined_val_acc_upto_{exp_name}_BaseEp{epochs_base}_MHAEp{epochs_mha}_R{R_shared}.png\",\n",
        "    )\n",
        "    plt.savefig(combined_acc_path)\n",
        "    plt.show()\n",
        "\n",
        "    # Val loss comparison\n",
        "    plt.figure()\n",
        "    for res in results_all:\n",
        "        total_epochs_exp = len(res[\"val_loss_curve\"])\n",
        "        epochs_range_all = range(1, total_epochs_exp + 1)\n",
        "        label = res[\"name\"]\n",
        "        if res.get(\"mlp_ratio\") is not None:\n",
        "            label += f\" (ratio={res['mlp_ratio']})\"\n",
        "        label += f\" (KV={res['kv_cost']:.2f})\"\n",
        "        plt.plot(epochs_range_all, res[\"val_loss_curve\"], label=label)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Val loss\")\n",
        "    plt.title(f\"{dataset_name} - {model_tag}: Val loss comparison (up to {exp_name})\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    combined_loss_path = os.path.join(\n",
        "        run_dir,\n",
        "        f\"combined_val_loss_upto_{exp_name}_BaseEp{epochs_base}_MHAEp{epochs_mha}_R{R_shared}.png\",\n",
        "    )\n",
        "    plt.savefig(combined_loss_path)\n",
        "    plt.show()\n",
        "\n",
        "    del model\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# ============== 3) 写 summary.json ==============\n",
        "\n",
        "summary = []\n",
        "for res in results_all:\n",
        "    summary.append(\n",
        "        {\n",
        "            \"name\": res[\"name\"],\n",
        "            \"attn_type\": res[\"attn_type\"],\n",
        "            \"mlp_ratio\": res[\"mlp_ratio\"],\n",
        "            \"params_million\": res[\"params\"] / 1e6,\n",
        "            \"best_val_acc\": float(res[\"best_val_acc\"]),\n",
        "            \"kv_cost\": float(res[\"kv_cost\"]),\n",
        "            \"epochs\": len(res[\"val_acc_curve\"]),\n",
        "        }\n",
        "    )\n",
        "\n",
        "with open(os.path.join(run_dir, \"summary.json\"), \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yu0Gu6EJd131"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38GQPmQyd3Jg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QYD3ByOfEJF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
